{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc874b9-9637-4847-806b-03a78bc5945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1e8b7-b828-4d51-ad25-7395a0b33052",
   "metadata": {},
   "source": [
    "**CLASSIFICATION**\n",
    "\n",
    "Touching onto classification means that there involves deciding whether this or that. It basically boils down onto classifying an output. It is either this or it's not that. It's one thing or another. However, there are different problem types for classification but it does boil down into the following:\n",
    "\n",
    "1. *Binary Classification* - As the name suggests, this decides whether this or that. It's 1 or 0. The target can be one of two options. An example of this would be identifying if this is a number or not. Is this a letter or not. If someone has a heart disease based on a certain parameter. It's yes or no.\n",
    "\n",
    "2. *Multi-class Classification* - Target can be one of two or more options. There are more options to choose when it comes to this. So it can check if a bear is a brown, grizzly, or a black bear. So it's akin to Binary classification but there are a lot more options to choose.\n",
    "\n",
    "3. *Multi-label Classification* - As opposed to the previous two this classification is quite the opposite. Instead of assigning the target to only one label or option. The target here can be assigned multiple labels or multiple options. So it is akin to a movie (target) having multiple categories (labels/options).\n",
    "\n",
    "Remember how we dealt with predicting a number in *01-Workflow Fundamentals*? That was a regression task. This time, we're going to deal with classification. Regression and Classification are two of the most common types of machine learning problems.\n",
    "\n",
    "This time, we're going to go through differentt classification problems in PyTorch. Basically, we will be receiving a set of inputs and then predicting what class those set of inputs belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183d571-ce42-4bb6-901e-1b9fdfad29bb",
   "metadata": {},
   "source": [
    "![Display](images/02-different-classification-problems.png \"Basic Descriptions of Classification Problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89b375-6376-4576-a154-a306701859c6",
   "metadata": {},
   "source": [
    "**COVERAGE**\n",
    "\n",
    "So in this chapter we'll be tackling classification but for the most part we'll retain the PyTorch Workflow that we originally used in the previous chapter which can be easily summarized into this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f3c81-157c-4ab2-b94a-379fd300af57",
   "metadata": {},
   "source": [
    "![Display](images/01-pytorch-workflow.png \"Basic PyTorch Workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f740340-10c0-4d27-95e6-4f1de53c2cbe",
   "metadata": {},
   "source": [
    "There is only one difference in this. We're going to work with a classification problem and not a linear problem that we did before, which was simply just predicting a straight line. So, the chapter goes as follows:\n",
    "\n",
    "1. __Architecture of a Classification Neural Network__ - Neural networks can be in any shape or size but there is always a typica floor plan.\n",
    "   \n",
    "2. __Getting Binary Classification Ready__ -  Data can be anything that can be converted but to start, we'll be using a simple binary classification dataset.\n",
    "\n",
    "3. __Building a PyTorch Classification Mode__ - In this section we will start creating the model to learn the patterns of the data. Choosing a *loss_function*, *optimizer*, and create a *training loop* to deal with classificatin.\n",
    "\n",
    "4. __Fitting Model To Data__ - Since we've created our model already and the training loop, we need to start predicting and letting the model find patterns in the *training* data.\n",
    "\n",
    "5. __Making Predictions & Evaluating Model__ - Once the model has checked for patters in the data, we need to make sure that the patterns it has detected fits the actual *testing* data that we have. Metrics such as accuracy is a good start.\n",
    "\n",
    "6. __Improving Models: Stepping Weights__ - We have evaluated the performance of our model and we need to make some changes to ensure that it is being improved. Basically, we need to start updating/stepping the weights. Or do other changes such as on the learning rate, etc.\n",
    "\n",
    "7. __Adding Non-Linearity__ - Linearity is pretty boring. Straight line's just doesn't cover enough ground for all possibilities such as non-linear problems. We need to make sure that the model can tackle non-linearity (non-straight lines). Using an activation function that covers nonlinearity such as *ReLU* is a good idea.\n",
    "\n",
    "8. __Replicating Non-Linear Functions__ - We used non-linear functions such as *ReLU* to deal with non-inear data but what do these actually look like? We'll take a look.\n",
    "\n",
    "9. __Combining Everything For Multi-class Classification__ - Once done with everything in creating binary classifaction, we'll be assembling everything together again with a multi-class classification problem. The reason that we're starting with binary classification is because it'll be easier to move on to multi-class classification afterward. It's akin to starting with two which are the basics and then just adding ontop of that. Afterall, binary and multi-class are both classifications at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ffa8c-7b52-4600-b0ca-c6d69426114a",
   "metadata": {},
   "source": [
    "**Architecture of a Classification Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff2b03-7b7d-4d18-8362-ffbe1b09c6d9",
   "metadata": {},
   "source": [
    "Before we get started with writing a classification neural network, we need to first be introduced with it's architecture to fully understand where we're going with this.\n",
    "\n",
    "We're going to talk about *Hyperparameters* and what they are for both binary and multiclass classifications.\n",
    "\n",
    "1. *Input Layer Shapes* / *in_features* -\n",
    "\n",
    "Binary: It would be the same for the number of features. If we had 5 features then the input layers would also be 5. Example: We have age, sex, height, weight, and smoking status for prediccting a person with heard disese. There are 5 features that we specified (these are the age, sex, etc). \n",
    "\n",
    "Multiclass: Same as binary. \n",
    "\n",
    "2. *Hidden Layer(s)* -\n",
    "\n",
    "Binary: This can be dependent on the problem. However the minimum would always be 1 while there is no limit to the maximum number of hidden layers.\n",
    "\n",
    "Multiclass: Same as binary.\n",
    "\n",
    "3. *Neurons per Hidden Layer* -\n",
    "\n",
    "Binary: Also dependent on the problem. Generally this ranges from 10 to 512.\n",
    "\n",
    "Multiclass: Same as binary.\n",
    "\n",
    "4. *Output Layer Shape* / *out_features* -\n",
    "\n",
    "Binary: 1 (it is either 1 or 0 or it is either this or that).\n",
    "\n",
    "Multiclass: 1 per class specified. For example, it would be 3 if there are three classes. For example, if there are three bear types: black, brown, or grizzly. There would be 3 *out_features*.\n",
    "\n",
    "5. *Hidden Layer Activation* -\n",
    "\n",
    "Binary: Primarily ReLU (rectified linear unit) but there are plenty of different activation functions that can be used.\n",
    "\n",
    "Multiclass: Same as binary.\n",
    "\n",
    "6. *Output Activation* -\n",
    "\n",
    "Binary: Sigmoid: *(torch.sigmoid)* / ReLU *(torch.ReLU)* \n",
    "\n",
    "Multiclass: Softmax *(torch.softmax)*\n",
    "\n",
    "7. *Loss Function* -\n",
    "\n",
    "Binary: Binary Cross Entropy *(torch.nn.BCELoss)*\n",
    "\n",
    "Multiclass: Cross Entropy *(torch.nn.CrossEntropyLoss)* \n",
    "\n",
    "8. *Optimizer* -\n",
    "\n",
    "Binary: SGD (Stochastic Gradient Descent) / Adam / etc. More on *torch.optim*\n",
    "\n",
    "Multiclass: Same as binary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7fa4b-c2b4-4f74-bef0-93b55d912765",
   "metadata": {},
   "source": [
    "This is just akin to a simple ingredients list of a very diverse recipe that has many implementations and versions depending on the problem. The neural network components presented here can vary on the problem that is needed to be solved. \n",
    "\n",
    "But neverthless, this is enough to get our foot in the door and get started. \n",
    "\n",
    "Time to get coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8be04a-fd34-4065-b9fd-e5b17796c420",
   "metadata": {},
   "source": [
    "**Make Classification Data + Readying It**\n",
    "\n",
    "First, we need to make some data for a problem so that we can solve it. We'll be utilizing a new function from a different library to generate two circles with different colored dots. *make_circles()* from *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740fcfe6-e1b7-4d6c-93d1-3f877c0d89d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_circles\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Make 1000 samples\u001b[39;00m\n\u001b[0;32m      4\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Make 1000 samples\n",
    "n_samples = 1000\n",
    "\n",
    "# Create circles with samples\n",
    "X, y = make_circles(n_samples,\n",
    "                   noise=0.03, # Adding noise to the dots make them vary\n",
    "                   random_state=42 # Keep random state/seed so we get the same values always\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1277cc-a1af-4664-9155-f91d1cd7ff97",
   "metadata": {},
   "source": [
    "Let's start viewing the first 5 X and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c9509-f47f-421c-93d1-3db4688d70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First 5 X Features:\\n{X[:5]}\")\n",
    "print(f\"\\nFirst 5 y Labels:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8fe74-a24e-41d8-a61e-030b4708c17c",
   "metadata": {},
   "source": [
    "We can see here that each match there are two X's for each Y labels. Remember that one of the best ways to understand things is to -! Visualize Visualize Visualize !-\n",
    "So let's do just that and put these into a *pandas DataFrame* - another library for visualization of data. Basically makes them a lot neater to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc438c7-b688-4362-a412-0691750c4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "circles = pd.DataFrame({\n",
    "    \"X1\": X[:, 0],\n",
    "    \"X2\": X[:, 1],\n",
    "    \"label\": y\n",
    "})\n",
    "circles.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673da16-2a11-4878-ad2d-7470edfc4ab3",
   "metadata": {},
   "source": [
    "With this it looks like for each X feature (X1 & X2) has a corresponding label (y) that has a value of either 1 or 0. \n",
    "\n",
    "This tells us that our probem is just **binary classification** because there are only two labels or two options which are either 1 or 0. \n",
    "\n",
    "Let's take a look as to how many values of each class is there. Basically, we're asking how many 1's and 0's are there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707caa55-42dc-4224-b49c-270fec283246",
   "metadata": {},
   "outputs": [],
   "source": [
    "circles.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807e9a8-5498-4168-b021-39fa4f087c1a",
   "metadata": {},
   "source": [
    "We can see that that they are perfectly balanced, with each label having 500 values.\n",
    "\n",
    "Let's start plotting them so that we can visualize it even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88dcc85-0cec-4760-bb87-13aa0e4f35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=X[:, 0],\n",
    "            y=X[:, 1],\n",
    "            c=y,\n",
    "            cmap=plt.cm.RdYlBu\n",
    "           );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438f1f1-ced9-4961-9884-3d41c868849d",
   "metadata": {},
   "source": [
    "There are two circles in the visualization but remember that these two circles are just from *X - (X1 & X2)*. The *c=y* is the one that gives color to X features that are 1 or 0. Remember how each X feature has a corresponding Y label?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8544c8-b6a8-45f4-a3e9-b1d69948339a",
   "metadata": {},
   "source": [
    "Now we have a problem to solve. Let's create a PyTorch neural network that is able to classify dots into either red (0) or blue (1).\n",
    "\n",
    "**Segway:** This type of dataset is often considered as a toy problem because it is a problem that is used to try and test things in machine learning. \n",
    "\n",
    "This is a great example of how to learn classification because this presents us data that is represented as numerical values and we'd want to build a model that is able to classify these dots and seperate them into red or blue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5d2d6-7370-47f5-862d-31073c1286e8",
   "metadata": {},
   "source": [
    "**Input & Output Shapes**\n",
    "\n",
    "One of the more common errors when dealing with deep learning is shape erros with data. Mismatching shapes of tensors and when conducting tensor operations result in errors with the models. \n",
    "\n",
    "It's fine to see these throughout the course because each time you succesfuly deal with one means that you've learned to something valuable to use down the line. This is helpful because there is no guaranteed way to avoid these. THEY WILL HAPPEN!\n",
    "\n",
    "One of the best things to equip yourself is to always be familiar with the shapes of the data that you are going to work with. VISUALIZE VISUALIZE VISUALIZE.\n",
    "\n",
    "You can easily ask yourself the simple question:\n",
    "\n",
    "\"What shapes are my inputs and what shapes are the outputs?\"\n",
    "\n",
    "Let's start answerin these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8007f2c-2863-4121-8ba0-20c585deede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X.ndim, y.shape, y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18318274-17c2-4000-b219-eed99284f5a6",
   "metadata": {},
   "source": [
    "Our first dimension seems to be matching well since we have 1000 *X* and also 1000 *y*. But that still leaves us the question what to do with the second dimension of X? What is even in it? \n",
    "\n",
    "Viewing the values and shapes of a single sample (features & labels) is quite helpful since this gives you more information. Asking questions is never bad. Doing this will lead you to knowing more about your input and output shapes that you would expect from the model that you'll be making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdba448-b4f5-490d-a69d-a11c0537c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first example of features and labels\n",
    "X_sample = X[0]\n",
    "y_sample = y[0]\n",
    "print(f\"Values for one sample of X: {X_sample} and the same for y: {y_sample}\"),\n",
    "print(f\"Shapes for one sample of X: {X_sample.shape} and the same for y: {y_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1e589-9966-482a-bcb6-f72e4579612a",
   "metadata": {},
   "source": [
    "Remember when we created our X values that we had *X1* and *X2*? Doing the code above tells us that our X contains two values again. It reminds us that we are working with both X1 and X2 or two values for X_sample while for y_sample, we're dealing with only y. Just one value.\n",
    "\n",
    "In machine learning terms, X_sample is a vector (Rank-1) while y_sample is a scalar (Rank-0).\n",
    "\n",
    "**IMPORTANT:** Don't get confused with X_sample and X OR y_sample and y. \n",
    "\n",
    "X is a 2D array (Rank-2) because we have 1000's of these X_sample vectors. When we say X_sample we are referring to the 2nd dimension of the X matrix. SO basically, X is a 2D array (Rank-2) that contains a vector (Rank-1) in it's 2nd dimension.\n",
    "\n",
    "y is a vector (Rank-1) because we have 1000's of these scalar values (rank-0).\n",
    "\n",
    "There are a lot of points for error here because it can get a bit confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951300f7-e2b2-4327-9cb0-8d6a8dcd20d6",
   "metadata": {},
   "source": [
    "**Turn Data To Tensors + Create Train & Test Splits**\n",
    "\n",
    "We've looked into the input (X) and output (y) shapes of our data and now we can prepare for it's use with PyTorch for modelling. Turning this into steps:\n",
    "\n",
    "1. Turn data into tensors (currently, our data is in NumPy arrays and we need to convert these into PyTorch tensors).\n",
    "\n",
    "2. Split the data into training and test sets (we use the training set to train the model to learn the patters between X and y then we evaluate those learned patters on the test dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf17a1-1cfd-4273-b26e-804cab9dcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn data into PyTorch tensors\n",
    "\n",
    "import torch\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "# View the first five samples\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83eee94-1542-4047-99a6-4bb61da20149",
   "metadata": {},
   "source": [
    "Now that we have it in tensor format, let's start splitting it into training and testing datasets. We can do this much easier by utilizing *train_test_split()* from *Scikit-Learn*. We can do this manually but we've already done that before.\n",
    "\n",
    "We'll set the *test_size=0.2* so that basically means we'll grab 20% for testing and the rest of the 80% would be for training. The splitting is random but we can set the seed as always so it won't be too random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade745b-cc96-4e68-84dd-c6cb5781d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data to train & test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb8ed5-1127-44b1-ac00-45ab3260af74",
   "metadata": {},
   "source": [
    "We've split it up to 800 training and 200 testing. Looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0582419-baa4-4fcf-8801-b967369357c2",
   "metadata": {},
   "source": [
    "**Building The Model**\n",
    "\n",
    "We've already prepared our data so we start moving towards creating the model itself. We'll break this section down to different parts:\n",
    "\n",
    "1. Setting up the device agnostic code - CPU / GPU.\n",
    "2. Constructing a model by subclassing *nn.Module*.\n",
    "3. Defining a loss function and optimizer.\n",
    "4. Creating a training loop. - Next Section\n",
    "\n",
    "Luckily, we've been through this already so it's not going to be a big jump in terms of what we'll be working on. The only thing changing is that we're going to work with a classification dataset. \n",
    "\n",
    "However, we'll be starting off with importing PyTorch and *torch.nn* for setting up the device agnostic code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63536283-c6d3-4eaa-a326-8561ce34b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d870bed-14c6-45e0-b23e-963ba5f9e011",
   "metadata": {},
   "source": [
    "We've got the device portion setup and we can use it now for any data or models that we'll be making. PyTorch will automatically handle it on the CPU by default else in the GPU if it is available. \n",
    "\n",
    "Let's start working on the model.\n",
    "\n",
    "We want a model that is capable of handling the *X* data as inputs and then produce the outputs in the same shape as the *y* data. \n",
    "\n",
    "Basically we want our model to perform as given with *X* (features) to predict *y* (labels). This setup where we have features and labels is referred to as **supervised learning**. This is because your data is telling the model what the outputs should be when given with a certain input.\n",
    "\n",
    "When creating a model that does supervised learning, we'll need to handle the input and output shapes of *X* and *y*. \n",
    "\n",
    "We'll see why the input and output shapes are critical:\n",
    "\n",
    "Creating a model class that:\n",
    "\n",
    "1. Subclasses *nn.Module* (almost all PyTorch models are subclasses of *nn.Module*)\n",
    "   \n",
    "2. Creates 2 *nn.Linear* layers in the constructor capable of handling the input and output shapes of *X* and *y*.\n",
    "   \n",
    "3. Defines a *forward()* method containing the forward pass computation for the model.\n",
    "\n",
    "4. Instantiates the model class and sends it to the appropriate target *device*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619973b0-5d25-42d3-9339-5432d1c3c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Construct a model class that subclasses nn.Module\n",
    "class CircleModelV0(nn.Module): \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        #2. Create 2 nn.Linear Layers capable of handling X and y inputs.\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=5) \n",
    "        # X contains a vector (two values) so the in_features is 2.\n",
    "        # This produces 5 features.\n",
    "        self.layer_2 = nn.Linear(in_features=5, out_features=1)\n",
    "        # This takes the out_features of layer_1 and \n",
    "        # since y contains a scalar - 1 value then the this produces 1 feature.\n",
    "\n",
    "    #3. Define a forward method containing the forward pass computation \n",
    "    def forward(self, x):\n",
    "        # Return the output of layer_2, a single feature, the same shape as y\n",
    "        return self.layer_2(self.layer_1(x))\n",
    "\n",
    "#4. Create an instance of the model alongside settng it to the target device\n",
    "model_0 = CircleModelV0().to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f93a2-96a0-4e22-9668-bd71067e7a3e",
   "metadata": {},
   "source": [
    "Everything with the model's creation is pretty familiar except for just a major change in what is happening between *self.layer_1* and *self.layer_2*\n",
    "\n",
    "*self.layer_1* takes 2 input features with the parameter *in_features* and produces 5 output features with the parameter *out_features*.\n",
    "\n",
    "This is also known as having 5 **hidden units** / **neurons**\n",
    "\n",
    "The layer turns the input data from having 2 features to 5 features.\n",
    "\n",
    "Why is this important? Why even do this?\n",
    "\n",
    "The reason for that is this because this is because this allows the model to learn the patterns from 5 numbers rather than just 2 meaning that it can *potentially* lead to better outputs and results. \n",
    "\n",
    "It's not guaranteed however. \n",
    "\n",
    "The number of hidden units that you can use in a neural network layer is a **hyperparameter** essentially meaning that it is a value that you can set by yourself and there is no *set in stone* value that you are required to use.\n",
    "\n",
    "Just follow the simple rule that moderation is key. More hidden layers is good but too much can have it's drawbacks. The amount that you decide to use is dependent on the model type and the dataset that you are working on.\n",
    "\n",
    "Since the dataset that we are currently working isn't that big and it's quite simple. we'll just put our hyperparameter value for neurons on the lower end. \n",
    "\n",
    "The **ONLY** rule that is required for hidden units is that in the subsequent layer, in our case, self.layer_2 has to take the same *in_features* as the previous *out_features*.\n",
    "\n",
    "This is the reason why *self.layer_2* has 5 for it's *in_features*. It takes these from the *out_features* from *self.layer_1* and then performs linear computation on them turning these into 1 *out_features* which is the same shape as our *y*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b30a0f-9a95-4aa3-8440-eb7a83e403d7",
   "metadata": {},
   "source": [
    "![Display](images/02-tensorflow-playground-linear-activation.png \"Visualization of How Neurons Work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13bc3d-9a35-4455-b288-25e1dd6a0930",
   "metadata": {},
   "source": [
    "This is what a similiar classification neural network would look like just like what we have done. It's a pretty good visualization ofw whatever is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fa1fb-4aed-4ed4-9418-d938e70c2f8e",
   "metadata": {},
   "source": [
    "We can do the same thing as above utilizing *nn.Sequential*.\n",
    "\n",
    "*nn.Sequential* performs a forward pass computation on the input data through the layers in the order that we place them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a375d-d6ff-466b-b835-077be97c62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replciating CircleModelV0 with nn.Sequential \n",
    "model_0 = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=5),\n",
    "    nn.Linear(in_features=5, out_features=1)\n",
    ").to(device)\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681645d0-44e7-4a0f-b6f3-6ec4861ef15d",
   "metadata": {},
   "source": [
    "That's a lot easier and convenient to do rather than working with *nn.Module*. Not only that but *nn.Sequential* also automatically defines the forwardpass for you. \n",
    "\n",
    "It is a fact that *nn.Sequential* is absolutely great when working with straight-forward computations, however, as the namespace gives off, it will ALWAYS run in sequential order. \n",
    "\n",
    "So, in the case that you want something else to happen rather than just going straight for sequential computation, you'll want to define your own custom *nn.Module* subclass.\n",
    "\n",
    "\n",
    "Now that we have our model, let's try passing some data through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b6ffb-86ea-4714-92b3-2c983cbd7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the model\n",
    "untrained_preds = model_0(X_test.to(device))\n",
    "print(f\"Length of Predictions: {len(untrained_preds)}, Shape:{untrained_preds.shape}\")\n",
    "print(f\"Length of Test Samples: {len(y_test)}, Shape: {y_test.shape}\")\n",
    "print(f\"\\nFirst 10 Predictions:\\n{untrained_preds[:10]}\")\n",
    "print(f\"\\nFirst 10 Labels:\\n{y_test[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c201fe-e37e-454b-a41d-03ceade36db8",
   "metadata": {},
   "source": [
    "We have the same number of predictions for the test samples so that's great! However, our predictions don't look like to be in the same shape or form as our test labels. \n",
    "\n",
    "Basically our test labels are 1 or 0. But none of our predictions resemble that. Our predictions should also be 1 or 0. \n",
    "\n",
    "Luckily, there's a fix for this and we'll get into that in a bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d365c-72f4-4c26-8be3-53f6ad6ca20a",
   "metadata": {},
   "source": [
    "**Setting Up Loss Function & Optimizer**\n",
    "\n",
    "We've already created a loss function as well as a optimizer in the previous chapter so it's all the same. The issue that we have right now is that our problem requires a different loss function. \n",
    "\n",
    "Recall that our previous chapter worked with a problem dealing with regression / predicting a number. In that case, we would typically use mean absolute loss or *MAE* loss and it would work. However, this is a different case since we're now dealing with classification.\n",
    "\n",
    "For binary classification such as ours, we'll often have to use *binary cross entropy* as the loss function.\n",
    "\n",
    "In the case for our optimizer, we can still use the same one. Previously, we used *stochastic gradient descent* / *SGD* (*torch.optim.SGD()*) and we can still use it for this classification problems as well. \n",
    "\n",
    "It can carry over in a wide range of problems and the same case can be said for the *Adam* optimizer (*torch.optim.Adam()*).\n",
    "\n",
    "Let's take a look at some loss functions and optimizers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddeddf0-6322-4690-8c29-f833a028b8f0",
   "metadata": {},
   "source": [
    "1. *Stochastic Graient Descent (SGD) Optimizer* - Works with regression, classification, and many other types. *torch.optim.SGD()*\n",
    "\n",
    "2. *Adam Optimizer* - Works with regression, classification, and many other types. *torch.optim.Adam()*\n",
    "\n",
    "3. *Binary Cross Entropy Loss* - Binary classification. *torch.nn.BCEWithLogitsLoss()* or *torch.nn.BCELoss*.\n",
    "\n",
    "4. *Cross Entropy Loss* - Multi-class classification. *torch.nn.CrossEntropyLoss*\n",
    "\n",
    "5. *Mean Absolute Error (MAE) / L1 Loss* - Regression *torch.nn.L1Loss*\n",
    "\n",
    "6. *Mean Squared ERror (MSE) / L2 Loss* - Regression *torch.nn.MSELoss*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7e779-da6f-400c-865d-b9c1bceebd63",
   "metadata": {},
   "source": [
    "Since we're working with a binary classification problem, let's work with *Binary Cross Entropy Loss*. Remember that a loss function measures how *wrong* the model is so the higher the loss, the worse the model. \n",
    "\n",
    "In addition, PyTorch often refers to loss functions as \"loss criterion\" or \"criterion\". There are many different means of describing these so just be a look out or else you might get confused. \n",
    "\n",
    "There are two binary cross entropy implementations that we can utilize:\n",
    "\n",
    "1. *torch.nn.BCELoss()* - This creates a loss function that measures binary cross entropy between the target (label / y) and input (feature / X).\n",
    "   \n",
    "2. *torch.nnBCEWithLogitsLoss()* - This is exactly as above except for the fact that it also contains a sigmoid layer (*nn.Sigmoid*) built-in. More about this soon.\n",
    "\n",
    "So with these two in mind, what are we supposed to use?\n",
    "\n",
    "If we would take a look at the documentation for *torch.nnBCEWithLogitsLoss()*, it states that this is more *numerically* stable than using *torch.nn.BCELoss* after a *nn.Sigmoid* layer. \n",
    "\n",
    "So plainly speaking, implementation 2 is better. However, the downside for this is that you would want to seperate the *nn.Sigmoid* layer from *torch.nn.BCELoss()* when it comes to advanced and more complex usage. But, that's not the case for now and that is beyond the scope of this section.\n",
    "\n",
    "With this in mind, it's time to create a loss function and an optimizer.\n",
    "\n",
    "Since *SGD* is something that we are more familiar with since we've been dealing with it before and the fact that it is very capable for both regression and classification tasks, we'll be using this as our optimizer. \n",
    "\n",
    "Optimizer = *torch.nn.SGD()* combined with a learning rate of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbad6b-41dc-4f87-9151-bd6ebc2a0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loss function with built-in Sigmoid\n",
    "loss_fn = nn.BCEWithLogitsLoss() \n",
    "\n",
    "#Creating an optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9aa5a-20c7-4e20-91d1-02f1b7044642",
   "metadata": {},
   "source": [
    "In addition, we're also going to create an **evaluation metric**.\n",
    "\n",
    "This can be used as an additional perspective to how the model is progressing. If a loss function is a number to measure how 'wrong' a model's predictions are then the evaluation metric is a means of measuring how 'right' it is. \n",
    "\n",
    "So a loss is suited for the model's interpretation while an evaluation metric is better meant for human consumption. We create metrics for both the model and us. \n",
    "\n",
    "At the end of the day, they both do the same thing of measuring the model but an evaluation metric is important for an additional perspective which goes well for visualization as a core concept of deep learning.\n",
    "\n",
    "Just think about it as dealing with shapes (which we are), it's always better to look at shapes from different angles to get a better grasp on it's structure. \n",
    "\n",
    "There are many different types of evaluation metrics to choose from and each one has a problem that it is best suited for, in our case we can start with an **accuracy** metric. \n",
    "\n",
    "Accuracy can be easily measured by simply dividing the total number of correct predictions over the total number of prediction made.\n",
    "\n",
    "In other words, if we have a model that makes 99 correct predictions out of 100 then that would be an accuracy of 100%. Quite simple!\n",
    "\n",
    "Let's make an accuracy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53755f2d-bb80-4096-a376-8f2bdcd424a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy - Classification Metric\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    # Calculates where two tensors are equal\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8897511-efc2-4302-8d31-72030e383f18",
   "metadata": {},
   "source": [
    "**Train Model**\n",
    "\n",
    "We have our data, loss function, and optimizer ready. Let's start training a model.\n",
    "\n",
    "First, we have to create a PyTorch training loop. But before that we'll do a quick segway first.\n",
    "\n",
    "**Going From Raw Model Outputs To Predicted Labels (Logits -> Prediction Probabilities -> prediction Labels)**\n",
    "\n",
    "Let's take a look first as to what actually comes out of the model during the forward pass. In other words, let's take a look at the output of the forward() method. \n",
    "\n",
    "Try passing some data through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29974c-63c7-4dc1-81f0-efdc6b219ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b7ad2-769d-4f47-9506-bceba68cc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the first 5 outputs of the forward pass on the test data\n",
    "y_logits = model_0(X_test.to(device)[:5])\n",
    "y_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c441b-ef27-470f-976f-b7af45339a04",
   "metadata": {},
   "source": [
    "Since the models are basically untrained with random weights at the start then these are just random values. But that doesn't answer the question of *what are they?*. \n",
    "\n",
    "The answer is that they're just the outputs for the *forward()* method that implemeneted two layers of *nn.Linear()* which just does the formula: \n",
    "\n",
    "y = x * weights^T + bias.\n",
    "\n",
    "These are *raw* outputs (unmodified) from the equation above (y) and in turn the raw outputs of the model are often referred to as the **logits**.\n",
    "\n",
    "Logits is the output of the model above when it is fed with the input data, in this case the X_test. However, there is one small issue with logits. It's had to interpret.\n",
    "\n",
    "We'd much prefer if the numbers that we get are comparable to the truth labels or y which are basically just 1 and 0. Remember that we mentioned *Sigmoid* earlier? \n",
    "\n",
    "This is where it starts to play it's part. In order to conbert the model's raw outputs (logits) into a much more readable form, we use the *Sigmoid activation function*.\n",
    "\n",
    "Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1cad3-7af8-4511-a062-b846c6f7aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing Sigmoid on Model Logits\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659c117-88be-42c8-9cba-82bbedc401a5",
   "metadata": {},
   "source": [
    "Our outputs are now a lot more consistent. They're all in a much closer distance with each other as compared to before. Although they are still random. \n",
    "\n",
    "Due to the conversion with *sigmoid* these former logits are now called **prediction probabilities** or usually referred to as *y_pred_probs*. In other words, the values are now how much the model thinks that the data belongs to one class or another. \n",
    "\n",
    "Remember that our ideal outputs are 1 to 0 because we're dealing with binary classifications. So we can say that there is a decision boundary that can be placed with these prediction probabilities that we have.\n",
    "\n",
    "The closer to 0 then that means the more the model thinks that the sample belongs to 0 and the same can be said for 1. If the values are closer to 1 then the more the model thinks that it belongs to 1. From this we can say:\n",
    "\n",
    "If *y_pred_probs* >= 0.5 then y=1 (class 1)\n",
    "If *y_pred_probs* < 0.5 then y=0 (class 0)\n",
    "\n",
    "Notice that we're just primarily rounding them? That's what we're going to do. We turn the prediction probabilities into our exact prediction labels (y) by rounding the outputs of the sigmoid function.\n",
    "\n",
    "**NOTE:** The decision boundary can be value that we want but in our case now, it's best if it's just between in the middle so 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835ae5a-40b2-4fe1-b176-abdc9180518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the predicted labels - rounding the prediction probabilities\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "\n",
    "# In full - Meaning that we do everything that we did before in one go!\n",
    "y_pred_labels = torch.round(torch.sigmoid((model_0(X_test.to(device))[:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d36dff-ce05-4688-ad47-545b4bf00214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_pred_labels, y_preds.shape, y_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d04e3-bdaa-4589-b5e5-38480ea50d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equality - Checking accuracy \n",
    "\n",
    "# We check that our manual way of doing things before and the all-in-one go that we did are equal. Meaning that they\n",
    "# outputted the same exact thing. We do .squeeze() because we have an extra dimension that we aren't necessarily using\n",
    "# but this is also important later on when we use these with the loss function\n",
    "\n",
    "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
    "y_preds.squeeze(), y_pred_labels.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3ca61-db40-4a0a-ba5b-a128000b540f",
   "metadata": {},
   "source": [
    "We can now see that our predictions match our prediction labels. That means our predictions can now be easily compared to our labels and used to see if they match them or not. So if our prediction output a False and our truth labels for that specific target is True. Then these won't match meaning a decrease in accuracy. \n",
    "\n",
    "Going back, we converted our model's raw outputs which came out as logits into prediction probabilities then applying sigmoid activation function to narrow this down into the range between 0 and 1. Afterwards, we set a decision line to round the numbers into either 1 or 0 - our classes. \n",
    "\n",
    "**NOTE:** Sigmoid function is typically only applied to Binary Classification logits. Because, it functions well due to the fact that it goes between 1 - 0. If we were working with multi-class classification then we'd need to use the *softmax activation function*. \n",
    "\n",
    "Lastly, we mentioned *nn.BCEWithLogitsLoss* earlier which specified that it is a loss function that already contains the sigmoid function. That means we don't hae to manually apply the the sigmoid function as we did here since that will automatically be taken care of. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6d3f8-75f5-4cb3-9259-fad55858dec1",
   "metadata": {},
   "source": [
    "**Building The Training & Testing Loop**\n",
    "\n",
    "Time to start building our training & testing loop. Let's start with 100 epochs and output the model's results every 10 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde5094-60e0-45e8-8f7e-b0d079efcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Setting the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Placing data into target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device) \n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Building the training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ### SETTING TRAINING\n",
    "    model_0.train()\n",
    "\n",
    "    # Forward Pass \n",
    "    # Still confused with why applying squeeze is important? Try removing it down below and see what happens\n",
    "    train_logits = model_0(X_train).squeeze() # Removing the extra '1' dimension \n",
    "    train_preds = torch.round(torch.sigmoid(train_logits)) # Turning logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # Calculate loss \n",
    "    # Take a look on the shape of y_train -- this is critical for realizing why squeeze() is important on train_logits\n",
    "    loss = loss_fn(train_logits, y_train) # Using nn.BCEWithLogitsLoss working with raw logits\n",
    "\n",
    "    # IF we were using nn.BCEloss then we apply sigmoid function manually\n",
    "    # loss = loss_fn(torch.sigmoid(y_logits), y_train)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_fn(y_train, train_preds)\n",
    "\n",
    "    # Reset Optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # Step weights\n",
    "    optimizer.step()\n",
    "\n",
    "    ### SETTING EVAL\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Forward Pass\n",
    "        test_logits = model_0(X_test).squeeze()\n",
    "        test_preds = torch.round(torch.sigmoid(test_logits))\n",
    "        # Loss\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        # Accuracy\n",
    "        test_acc = accuracy_fn(y_test, test_preds)\n",
    "\n",
    "    # Printing outputs per 10 epcohs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"EpochL: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72bc5c0-9132-4f3f-99cd-020c25e57c84",
   "metadata": {},
   "source": [
    "There doesn't seem to have an error but there is quite a small problem with this. Have you noticed?\n",
    "\n",
    "It's stuck at around 50%. The model went through both training and testing loops fine but the loss doesn't necessarily seem to be improving for both training loops. Since we're dealing with binary classification then that just means that our data is more or less randomly guessing since we're stuck at 50%. With 500 samples of class 0 and class 1, a model predicting one class or the other would achieve 50% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc89f6-65dd-4cf9-9b6b-9b6e9f0c0ed0",
   "metadata": {},
   "source": [
    "**Creating Predictions & Evaluating The Model**\n",
    "\n",
    "There is a problem with our model since it's randomly guessing but what exactly is the problem?\n",
    "\n",
    "Can't figure it out? Let's go back to visualization! First, we need to create a plot for our model's predictions then we also need to plot the data that it's trying to predict on + the decision boundary it's creating for whether or not something is class 0 or class 1.\n",
    "\n",
    "This time, we're lucky enough to have tools to help us in visualize this. We're enlisting the help of *Learn PyTorch for Deep Learning* repository that holds the *helper_functions.py* script. This scrip has a helpful function called *plot_decision_boundary* which basically creates a NumPy meshgrid to visually plot the different points where the model would be predicting the certain classes.\n",
    "\n",
    "We will also import *plot_predictions* which we already used previously in *Workflow Fundamentals*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd0e64-a5a2-4b83-b239-1e33fe50544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)\n",
    "\n",
    "from helper_functions import plot_predictions, plot_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbb49f-295f-49f4-8975-c7d5409fed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision boundaries for training & test sets\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_0, X_train, y_train)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_0, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a9bfd-f506-4111-88e6-ff5ed3a09c73",
   "metadata": {},
   "source": [
    "Notice the straight line running down the middle? It's splitting the red and blue dots. \n",
    "\n",
    "That's why it's 50% because the line doesn't match how our data works. Our data is circular and it's trying it's best to cut down the line in the middle to just get the best that it can do with what it's given. It's like trying to fit hand into a shoe.\n",
    "\n",
    "In terms of machine learning, the model is *underfitting* meaning that it isn't even learning the patterns of the data. \n",
    "\n",
    "So, how could we address this \"linear problem\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3a3b8-c181-429e-bf74-54df31c23d2a",
   "metadata": {},
   "source": [
    "**Improving Models - From a Model Perspective**\n",
    "\n",
    "This section, we'll look into potential solutions that we can use to improve or fix a model. We won't be changing the data whatsoever because as it stands, our data looks fine already! So we've narrowed it down to our model. Here, we'll take a look onto these steps that we can use to work with:\n",
    "\n",
    "1. *Adding More Layers*: Each layer has the potential of improving the model's learning capabilities since each layer can learn some kind of new pattern with the data. Think of adding a layer as a new pattern it can recognize. More layers makes the neural network **deeper**\n",
    "\n",
    "2. *Adding More Hidden Units*: Or adding more neurons per layer also means a potential increase in the learning capabilities of the model, this is referred to making a neural network **wider**. Think of it as adding more eyes to the neural network.\n",
    "\n",
    "3. *Fitting For Longer - More Epochs*: Just adding more epochs adds more opportunities for the model to look at the data and the layers to learn more patterns.\n",
    "\n",
    "4. *Changing Activation Functions*: Some data just can't work with certain activation functions. For example, in our case, whatever we do we can't fit a sraight line to match a circle. We might have to work with something aside from a straight line *Hmmmmm???*.\n",
    "\n",
    "5. *Change Learning Rate*: While a bit far from model specific, it is still a hyperparameter that decides how much the optimizer should change the parameter for each step. If it's too big then we risk memorizing the entire data, if it's too little then it probably won't have enough time to learn the patterns of the data.\n",
    "\n",
    "6. *Changing Loss Function*: Similiar to the previous change, not too model specific but vital. Different problems require different loss functions. You can't work with a multi-class classification while using a binary cross entropy loss function because they are meant for two different things.\n",
    "\n",
    "7. *Transfer Learning*: Taking something that has already been trained on a similiar problemset and adjust that to fit your own needs. Will be covered in *Chapter-06 Transfer Learning*\n",
    "\n",
    "**NOTE:** Notice how you can manually change these according to what you think that you need. These are called **Hyperparameters**. This is a part where machine learning is not-too-sciency because there's not really much you can do when it comes to knowing what are the best hyperparamaters to work with. There's no guarantee or clear-cut solution. Good thing the word 'experiment' exists in the world of science because that will be what we're going to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959198b-41fd-4ae3-b117-c32066af674a",
   "metadata": {},
   "source": [
    "Let's start experimenting with some of the solutions. First, we'll try out what happens if we add more layers to our model, fit for longer (setting epochs to 1000 instead of 100), and also increasing the number of hidden units/neurons from 5 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec1247-3769-4f63-9c03-b7ee2f47ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModelV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer2 = nn.Linear(in_features=10, out_features=10) # Extra Layer\n",
    "        self.layer3 = nn.Linear(in_features=10, out_features=1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer3(self.layer2(self.layer1(x)))\n",
    "\n",
    "model_1 = CircleModelV1().to(device)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a3a4c-27aa-46c5-b97e-9a9a534b69dd",
   "metadata": {},
   "source": [
    "We've now created a new model with an additional layer, we'll recreate the loss and optimizer is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9070d96-7d1d-4c88-90eb-9ca03470626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252690ac-e67e-451a-b829-3e9e6aa2badc",
   "metadata": {},
   "source": [
    "Time to do all the training & testing loop again. The change would only be on the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4de5d6-237a-4599-a244-a1505878f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 1000\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### SET TRAINING\n",
    "    model_1.train()\n",
    "    # FORWARD PASS\n",
    "    train_logits = model_1(X_train).squeeze()\n",
    "    train_preds = torch.round(torch.sigmoid(train_logits))\n",
    "    # CALC LOSS\n",
    "    loss = loss_fn(train_logits, y_train)\n",
    "    # ZERO GRAD\n",
    "    optimizer.zero_grad()\n",
    "    # BACKPROP\n",
    "    loss.backward()\n",
    "    # STEP WEIGHTS\n",
    "    optimizer.step()\n",
    "    # CALC ACC\n",
    "    acc = accuracy_fn(y_train, train_preds)\n",
    "\n",
    "    ### SET EVAL\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        # FORWARD PASS\n",
    "        test_logits = model_1(X_test).squeeze()\n",
    "        test_preds = torch.round(torch.sigmoid(test_logits))\n",
    "        # CALC LOSS & ACC\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_test, test_preds)\n",
    "\n",
    "    # Printing outputs per 100 epcohs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"EpochL: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab80e7-2ef6-4546-8bf4-f2cf2f79b3e5",
   "metadata": {},
   "source": [
    "What? There's no changes at all! But we changed the number of epochs and even changed the number of layers + the neurons/hidden units. That's three improvement methods that we added but nothing changed at all. \n",
    "\n",
    "Let's get back to visualizing our data, perhaps there would be more details on the exact issue that we're facing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3880f6e-ad00-4c28-a768-f6fa283c3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision boundaries for training & test sets\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_0, X_train, y_train)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_0, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b2ed2-fd54-4bc0-92fd-4c212da4e19e",
   "metadata": {},
   "source": [
    "It's still drawing a straight line and dividing the circle by half. Let's experiment. Since our model is drawing a straight line, can it perhaps model linear data? Similiar to we did with the model in *PyTorch Workflow Fundamentals*? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd75234-9ee5-47eb-9cf6-942534bdb3ca",
   "metadata": {},
   "source": [
    "**Experimenting With Linear Data**\n",
    "\n",
    "Let's try creating some linear data to try our model on and visualize what would happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbaf44-0b47-4557-9bd3-9ede3db29282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Linear Data\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.01\n",
    "\n",
    "X_regression = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y_regression = weight * X_regression + bias # Linear Regression Formula\n",
    "\n",
    "# Check Data\n",
    "print(len(X_regression))\n",
    "X_regression[:5], y_regression[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583c33d-38df-49af-950a-bc78e6f62ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into Training & Testing Sets\n",
    "train_split = int(0.8 * len(X_regression)) # Get 80%\n",
    "X_train_regression, y_train_regression = X_regression[:train_split], y_regression[:train_split]\n",
    "X_test_regression, y_test_regression = X_regression[train_split:], y_regression[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfd15e-dfcb-43e7-a49d-fe2efeb32563",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train_regression))\n",
    "print(len(y_train_regression))\n",
    "print(len(X_test_regression))\n",
    "print(len(y_test_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef8b2b-cb98-4bfa-bc88-d377b1476292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing using plot_prediction() \n",
    "plot_predictions(train_data=X_train_regression,\n",
    "    train_labels=y_train_regression,\n",
    "    test_data=X_test_regression,\n",
    "    test_labels=y_test_regression\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4afdeb-c908-462d-aead-d4de7bc17bd5",
   "metadata": {},
   "source": [
    "**Adjusting Model_1 To Fit Straight Line**\n",
    "\n",
    "Let's recreate *Model_1* to make it fit our regression problem. We'll also change the loss function since we're no longer dealing with a classification problem with our experiment. We'll utilize *nn.Sequential*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f43e14-306e-43a8-ad36-745789318e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=10),\n",
    "    nn.Linear(in_features=10, out_features=10),\n",
    "    nn.Linear(in_features=10, out_features=1)\n",
    ").to(device)\n",
    "\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347cc2b-86a2-4c0f-9ae1-b8bea6584571",
   "metadata": {},
   "source": [
    "The setup loss function that we'll be using is *nn.L1Loss()*. It's similiar to mean absolute error. The optimizer will be retained as SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb1472-c4f6-46a1-8052-2538b0abe2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68050aa3-718f-4fa2-aa09-ef55b7df1487",
   "metadata": {},
   "source": [
    "Let's do the training & test loop again but this time for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04f3ba-4340-4f0b-8ae7-670d186f0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 1000 \n",
    "\n",
    "# SET DATA TO DEVICE\n",
    "X_train_regression, y_train_regression = X_train_regression.to(device), y_train_regression.to(device)\n",
    "X_test_regression, y_test_regression = X_test_regression.to(device), y_test_regression.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### SET TO TRAIN\n",
    "    model_2.train()\n",
    "    # FORWARD PASS\n",
    "    train_pred = model_2(X_train_regression)\n",
    "    # CALC LOSS\n",
    "    loss = loss_fn(train_pred, y_train_regression)\n",
    "    # ZERO GRAD\n",
    "    optimizer.zero_grad()\n",
    "    # BACKPROP\n",
    "    loss.backward()\n",
    "    # STEP WEIGHTS\n",
    "    optimizer.step()\n",
    "    ### SET TO EVAL\n",
    "    model_2.eval()\n",
    "    with torch.inference_mode():\n",
    "        # FORWARD PASS\n",
    "        test_pred = model_2(X_test_regression)\n",
    "        # CALC LOSS\n",
    "        test_loss = loss_fn(test_pred, y_test_regression)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, | Test Loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f51e3-e919-48ea-9188-ef7f2e9424b7",
   "metadata": {},
   "source": [
    "Seems like the loss is going down! Unlike how our model_1 works previously, this seems to be doing better and actually learning the patters of a straight line. Let's take a look and plot the predictions too. \n",
    "\n",
    "Remember that for visualization, we're using *matplotlib*. This doesn't support PyTorch tensors much more for data on GPU Devices. So we'll have to transition our data back to the CPU before we pass it on to *matplotlib*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c00ea-74b5-4dd8-adbb-599a1fbbc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_2(X_test_regression)\n",
    "\n",
    "plot_predictions(train_data=X_train_regression.cpu(),\n",
    "    train_labels=y_train_regression.cpu(),\n",
    "    test_data=X_test_regression.cpu(),\n",
    "    test_labels=y_test_regression.cpu(),\n",
    "    predictions=y_preds.cpu()\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f2ac2-84c6-4b8d-b82c-9d0d0724934d",
   "metadata": {},
   "source": [
    "Seems like the model is capable of guessing on straight lines rather than circles. No more random predictins here or standing on the 50% mark. This is a good thing because we know that the model can learn.\n",
    "\n",
    "One of the great ways to troubleshoot a model is to always start small and scale up as you go. What does it mean by starting small? Not many layers, not many neurons, and a small dataset to work with. \n",
    "\n",
    "In addition, it's one of the few cases where **overfitting** can be a good idea to do on that small dataset. Then by gradually increasing the amount of data exposed to the model, you'll be able to reduce overfitting.\n",
    "\n",
    "With these , we can start working out the next piece of the puzzle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb345013-8f6c-40f2-8e52-0023be5a364c",
   "metadata": {},
   "source": [
    "**The Missing Piece: Non-linearity**\n",
    "\n",
    "We've noticed how our model is capable of drawing and predicting straight (linear) lines primarily due to the linear layers that we are using. \n",
    "\n",
    "But, what if we're dealing with non-linear / non-straight lines? \n",
    "\n",
    "We need to be able to accomodate for those situations as well but how do we exactly do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2e279-c714-4ebf-88fa-545c0005ca04",
   "metadata": {},
   "source": [
    "**Recreating Non-Linear Data (Red & Blue Circles)**\n",
    "\n",
    "First, let's try making our data again. Same setup as before just reworking them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e275d6-5283-40c8-aaaf-bf262d289899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and plot data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "X, y = make_circles(n_samples=1000,\n",
    "    noise=0.03,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab49c6e-cc81-43f5-a67a-b33ff353dae8",
   "metadata": {},
   "source": [
    "Same as before, let's split these into 80% of the data for training and the remaining 20% for testing. We'll still use the train_test_solit from *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa9598-b852-4604-869f-7b54bb025bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Turn Data Into Tensors\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "# Split into Train & Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f403c-d647-45b7-9c6a-fb3fc1fd13f4",
   "metadata": {},
   "source": [
    "**Building Model With Non-Linearity**\n",
    "\n",
    "Let's imagine what we can draw with an unlimited straight line (linear)? There's a lot of things that we can cover with that but can you imagine if we had something that also draw non-straight lines? (non-linear)?\n",
    "\n",
    "The possibilities are almost endless and creativity is king. \n",
    "\n",
    "So far, the neural networks that we have been making can only accomodate linear (straight) line functions. But the data that we are currently working with is non-linear (circles).\n",
    "\n",
    "It's no wonder why we couldn't make it work. Let's try to imagine what if we had the capability to make our model handle **non-linear activation functions?**\n",
    "\n",
    "Let's take a look.\n",
    "\n",
    "PyTorch already has these **ready-made non-linear activation functions** built-in. They are all similiar but can do different things. \n",
    "\n",
    "One of the most common methods of handling non-linearity due to it's very good performance is **ReLU** (*rectified linear-unit, torch.nn.ReLU()*).\n",
    "\n",
    "But talking about it won't do us much good so let's try actually using it in the moddel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f7a19-25b3-4e23-aca9-2f6b4e755858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model with a non-linear activation function\n",
    "from torch import nn\n",
    "class CircleModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        # ReLU & Sigmoid both are capable of handling non-linear problems \n",
    "        # However, ReLU is more common nowadays but if you want to use Sigmoid\n",
    "        # then self.sigmoid = nn.Sigmoid() will do just fine, it would mean\n",
    "        # that you won't need to use it on the predictions anymore\n",
    "        self.layer3 = nn.Linear(in_features=10, out_features=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.layer3(self.relu(self.layer2(self.layer1(x))))\n",
    "\n",
    "model_3 = CircleModelV2().to(device)\n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa837d8-7493-4391-991a-1d95b5b35dc8",
   "metadata": {},
   "source": [
    "![Display](images/02-tensorflow-playground-relu-activation.png \"Visualization of How Neurons Work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61fffa-69c7-42ee-8acb-f6f1cee15724",
   "metadata": {},
   "source": [
    "Above is a great exmaple of visualization on what this neural network would look like with ReLU as the activation function. \n",
    "\n",
    "**Things To Ponder**: Where would be the best place to put non-linear activation functions when constructing neural networks? There's no definite answer for this but there is one rule of thumb that you can consider.\n",
    "\n",
    "The best places is between hidden layers and just right after the output layer. However, feel free to experiment around as you learn more about neural networks. There are many different ways of assembling things together. \n",
    "\n",
    "It's up to you to discover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1e65f-13f1-4066-8fc9-f9597c3d64af",
   "metadata": {},
   "source": [
    "Since we have a model that is ready and can accomodate for non-linear problems, let's create  the binary classification loss and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e97ec6-5f7d-4bb5-bd0c-0484c4cdfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model_3.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea43628-67d0-488c-b277-78d45421ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2f610-ebb8-4f0e-b0ab-49c14b1e6dca",
   "metadata": {},
   "source": [
    "**Training Model With Non-Linearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e00c69-d89b-44ec-82fe-e3bb6a1f3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 1000\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### SET MODEL TO TRAIN\n",
    "    model_3.train()\n",
    "    # FORWARD PASS\n",
    "    train_logits = model_3(X_train).squeeze()\n",
    "    # ROUND + SIGMOID\n",
    "    train_preds = torch.round(torch.sigmoid(train_logits))\n",
    "    # CALC LOSS (MODEL) & ACC (USER)\n",
    "    loss = loss_fn(train_logits, y_train)\n",
    "    acc = accuracy_fn(y_train,  train_preds)\n",
    "    # WEIGHT ZERO\n",
    "    optimizer.zero_grad()\n",
    "    # BACKPROP\n",
    "    loss.backward()\n",
    "    # STEP WEIGHT\n",
    "    optimizer.step()\n",
    "\n",
    "    ### SET MODEL TO EVAL\n",
    "    model_3.eval()\n",
    "    with torch.inference_mode():\n",
    "    # FORWARD PASS\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "    # ROUND + SIGMOID\n",
    "        test_preds = torch.round(torch.sigmoid(test_logits))\n",
    "    # CALC LOSS & LOSS\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_test, test_preds)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa921263-eb99-4ba0-87d1-2a000837022f",
   "metadata": {},
   "source": [
    "Seems like the model's accuracy and loss are improving on both the training and test sets! That's GREAT. \n",
    "\n",
    "Since our model can now also accomodate non-linear functions due to ReLU our model isn't having a hard time working with only a straight line in it's arsenal. \n",
    "\n",
    "Let's try to look at this in a more visual perspective. For sure that'll be more exciting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf1fa5-fcca-4704-9efe-d198e036aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.eval()\n",
    "with torch.inference_mode():\n",
    "    test_preds = torch.round(torch.sigmoid(model_3(X_test))).squeeze()\n",
    "    # Keep the preds in the same shape as the labels\n",
    "test_preds[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628e653-7fe1-4b74-827b-62e38a700bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundaries for training and test sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train - Model 1 Perspective NO Non-Linearity\")\n",
    "plot_decision_boundary(model_1, X_train, y_train) # model_1 = no non-linearity\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test - Model 3 Perspective YES Non-Linearity\")\n",
    "plot_decision_boundary(model_3, X_test, y_test) # model_3 = has non-linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2c3aa-3265-49ed-8d43-bdd8f7125c30",
   "metadata": {},
   "source": [
    "Take a look at our plotting. We are comparing our very first model that had no non-linearity with our current model that has non-linearity. \n",
    "\n",
    "See the difference? It can now accomodate and shape itself to the pattern of a circle. Much like what our data is! That's a big step.\n",
    "\n",
    "Try playing around with the number of epochs and see how our model can be improved. Maybe adding more layers or neurons? Experiment!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7bc4d-3719-4d2c-97cd-a103a9231820",
   "metadata": {},
   "source": [
    "**Replicating Non-Linear Activation Functions**\n",
    "\n",
    "Adding a non-linear activation function can help the model in working with non-linear data. But what does exactly a non-linear activation look like? \n",
    "\n",
    "**NOTE:** For the majority of the time, the data that you would be working on is non-linear or at least a combination of both. As of now, we are working with dots on a 2D plot but in the real world, real data can be daunting. \n",
    "\n",
    "For example, if we had images of plants that we would want to classify, there are plenty of different plant types to consider. Different shapes and such. \n",
    "\n",
    "Maybe we would be working with text from Wikipedia and we'd like to summarize them, there are plenty of different words that have numerous combinations (linear and non-linear patterns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55fd9c-bf3c-4054-a2fc-1d6dad13f706",
   "metadata": {},
   "source": [
    "Going back to the question earlier of what a non-linear activation looks like, let's try first replicating some and what they do. \n",
    "\n",
    "First, we're going to need some data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae113b-2c36-441e-8398-cf63a7ad30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experimental/toy tensor\n",
    "A = torch.arange(-10,10,1, dtype=torch.float32)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c65f34-c643-4692-ad76-1ee7dc173dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Data in a Plot\n",
    "plt.plot(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071553da-70d3-462d-88d9-1892403244bf",
   "metadata": {},
   "source": [
    "It's a straight line. Now, what happens if we use the ReLU Activation function on it and see how it influences the straight line. \n",
    "\n",
    "But this time, we won't be using PyTorch's built in *torch.nn.ReLU* instead we'll be making it ourselves. \n",
    "\n",
    "The ReLU functions in a nutshell turns all the negatives to 0 and leaves the positive values as is. So basically, we're removing all the negatives. This works similiarly to the Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c5f57-5de9-4c5c-baa5-0832398d1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ReLU Manually\n",
    "def relu(x):\n",
    "    return torch.maximum(torch.tensor(0), x) # The input must be a tensor\n",
    "    # torch.maximum takes all the maximum values from torch.tensor(0) and x,\n",
    "    # So the negatives from x are replaced by 0 from torch.tensor(0)\n",
    "\n",
    "# Pass by experimental/toy tensor into ReLU Function\n",
    "relu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9763f2-7347-4b2d-9ef3-5221db054fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data after ReLU application\n",
    "plt.plot(relu(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a526f55-aa3b-4982-a61c-2cc7a90fe077",
   "metadata": {},
   "source": [
    "We've succesfully recreated the ReLU function! It wasn't that hard and the concept itself is relatively simple. It's not magic. Just basic mathematics. \n",
    "\n",
    "Let's take a look at the sigmoid function as it functions similiarly and is also an activation function like ReLU.\n",
    "\n",
    "The sigmoid function formula goes along like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35429bb3-6c36-4cd7-9fc1-6a8312c13f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "sigmoid(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2ae3e-6e71-4969-b417-a40fba1e556c",
   "metadata": {},
   "source": [
    "Remember the prediction probabilities that we had earlier? Also notice how there isn't any negative values in the outputs. Let's try graphing this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd7bfc-ca4e-4b49-885b-39ef22ea006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data after Sigmoid application\n",
    "plt.plot(sigmoid(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee788d-5f6c-41c9-bf22-f1d11e4c2bbe",
   "metadata": {},
   "source": [
    "Notice how the sigmoid function is a curved while ReLU is pretty much straight lines. These two are the most common types of activation functions that you would encounter when dealing with non-linear data. \n",
    "\n",
    "If you think about it, what type of patterns can you make if you have an unlimited amount of linear and non-linear lines? You can use lines and curved. \n",
    "\n",
    "You can make almost anything with these in hand. That's exactly what we want and what our model is capable of when we combine both linearity and non-linearity. \n",
    "\n",
    "What we are doing is not telling our model what to do and how to do it. Instead, we're just giving it the necessary tools that it needs to be able to solve a problem. You can't expect a mine to be dug and ores to come out without a pickaxe, correct? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0046d2-9419-48ec-ab5f-1f1756d21532",
   "metadata": {},
   "source": [
    "**Putting Things Together - Building Multiclass PyTorch Model**\n",
    "\n",
    "We've covered a large section already and discussed many different 'mysteries' when dealing with neural networks, but it's time to finally put all these newly discovered information to good use. This time, we're going to implement all that we've learned in a multiclass classification problem. \n",
    "\n",
    "Recall that a binary classification problem revolves around a \"this or that\" / \"0 or 1\" concept. While multiclass classification deals with having more options. So it's much akin to \"it's this or the many other options\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18fb6cf-f199-47e8-b563-fa7ff0213d03",
   "metadata": {},
   "source": [
    "![Display](images/02-binary-vs-multi-class-classification.png \"Multiclass Classification vs Binary Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfa688-7663-444a-8055-20936c70003e",
   "metadata": {},
   "source": [
    "As shown in the image, this is an example of what binary and multiclass classifications look like. For example, one of the more popular datasets for computer vision benchmarks is the *ImageNet-1k Dataset* which has 1000 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eebb71-d2d5-4837-bac3-72963e5d7e0c",
   "metadata": {},
   "source": [
    "**Creating Multiclass Classification Data**\n",
    "\n",
    "Before we get started with solving a multiclass classification problem, we'll need some multiclas data to work with. \n",
    "\n",
    "As before to make our lives easier, we'll be using *Scikit-Learn - make_blobs()* method.\n",
    "\n",
    "This gives us the capacity to create data with how many classes that we want by utilizing the *centers* parameter. So let's go over this in a step-by-step basis first.\n",
    "\n",
    "1. Create multiclass data with *make_blobs()*.\n",
    "2. Turn the data into tensors as *make_blobs()* provides the data in NumPy arrays.\n",
    "3. Split the data into a training and testing set.\n",
    "4. Visualize the created data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f47264-b485-4aff-b73b-2ac7b785f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for data creation\n",
    "NUM_CLASSES = 4\n",
    "NUM_FEATURES = 2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Create Multiclass Data\n",
    "X_blob, y_blob = make_blobs(n_samples=1000,\n",
    "                           n_features=NUM_FEATURES, # X Features\n",
    "                           centers=NUM_CLASSES, # y Labels\n",
    "                           cluster_std=1.5, # Gives clusters some 'uniqueness'\n",
    "                           random_state=RANDOM_SEED \n",
    "                           )\n",
    "\n",
    "# Turn Data Into Tensors\n",
    "X_blob = torch.from_numpy(X_blob).type(torch.float)\n",
    "y_blob = torch.from_numpy(y_blob).type(torch.LongTensor)\n",
    "print(X_blob[:5], y_blob[:5])\n",
    "\n",
    "\n",
    "# Split Data Into Train & Test Sets\n",
    "X_blob_train, X_blob_test, y_blob_train,  y_blob_test = train_test_split(\n",
    "    X_blob,\n",
    "    y_blob,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Plot Data\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_blob[:,0], X_blob[:,1], c=y_blob, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74c9c5-d55e-4012-8832-09365d169348",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blob_train.dtype, X_blob_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f906fb-f99f-4e74-a10d-f3a443cb8514",
   "metadata": {},
   "source": [
    "Each color represents a different class. Notice how we have at four colors? That means our multiclass data contains 4 classes. Now that we've made the data, we're ready to get started. Let's create a model to seperate the coloured blobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277c46d-2db8-49e6-9738-1c3934843a51",
   "metadata": {},
   "source": [
    "**Building Multiclass Classification Model in PyTorch**\n",
    "\n",
    "We've been building many models already just from the previous two sections and you might have started to realize how flexible we can be when it comes to working with neural networks. \n",
    "\n",
    "Can you think about how we can build a model that is similiar to *model_3* but modified in the way that we can accomodate for multiclass data?\n",
    "\n",
    "Let's create a new subclass of *nn.Module* that has three hyperparameters:\n",
    "\n",
    "1. *input_features*: The number of *X* that the model takes\n",
    "2. *output_features*: The ideal number of output features we would want, this is equivalent to the number of classes (*NUM_CLASSES*) that we specified earlier.\n",
    "3. *hidden_units*: The number of hidden neurons that we want per layer.\n",
    "\n",
    "Because we're putting everything together again, we'll create some device agnostic code. (Yes, we already did this and there's no need to keep repeating it but it's good practice.)\n",
    "\n",
    "Afterwards, we'll start making the model with the set hyperparameters mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74021fa0-2187-42b4-99b6-2ff6f82a9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Device Agnostic Code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7518c-0590-454f-86e6-9e3331db6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Building Model\n",
    "class BlobModel(nn.Module):\n",
    "    def __init__(self, input_features, out_features, hidden_units):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(input_features, hidden_units),\n",
    "            # nn.ReLU(), # Play around and see what happens if we don't have non-linearity covered.\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            # nn.ReLU(), # Play around and see what happens if we don't have non-linearity covered.\n",
    "            nn.Linear(hidden_units, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of BlobModel & Send to device\n",
    "model_4 = BlobModel(input_features=NUM_FEATURES, \n",
    "                    out_features=NUM_CLASSES, \n",
    "                    hidden_units=10).to(device)\n",
    "\n",
    "model_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea072a-55bd-4a97-8d8e-4d696e0960d6",
   "metadata": {},
   "source": [
    "Notice how we shortened our entire model by using a *nn.Sequential* inside the class? That makes it a lot easier for us when creating our *forward*. We've made it a lot easier to modify our class by adding in parameters to it whenever initialized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4692e-5f21-4b8a-8e77-97bb78a29702",
   "metadata": {},
   "source": [
    "**Creating a Loss Function & Optimizer For Multiclassification PyTorch Models**\n",
    "\n",
    "Now that is done, it's time to choose an optimizer and a loss function. Since we're working with a multiclassification problem, binary-cross-entropy wouldn't work this time. So we'll be instead using *nn.CrossEntropyLoss()*. The Optimizer would still remaine as *SGD* with a learning rate of 0.1 for optimization of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae795da-2bcf-4a95-a841-e666e88d8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_4.parameters(), lr=0.1)\n",
    "# Try experimenting with the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442d98d-3514-4842-94fd-9c8eae60c79f",
   "metadata": {},
   "source": [
    "**Creating Predictions With Multiclassification Models**\n",
    "\n",
    "We have the data, model, loss function, and optimizer. We're all set to start training the model. But let's try doing a single forward pass on the data with the model to see if everything is running smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f431fa-9a21-4cde-b8a9-3f45484e2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4(X_blob_train.to(device))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05fb33-b924-4b9b-a166-aa0aa3cb889d",
   "metadata": {},
   "source": [
    "Seems like we're getting one value per feature from the sample. Let's take a look at the shape to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da275ed-9297-4d09-ba01-9380bf2c7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4(X_blob_train.to(device))[0].shape, NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc45fa-79a7-467a-b11f-ae831d476860",
   "metadata": {},
   "source": [
    "The shape matches with the number of classes that we have. That's exactly that we want beacuse that means each of our class has a corresponding value connected to it. \n",
    "\n",
    "What's the name of these outputs? *Logits* !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb11884-700a-4bee-8ebc-3624208553db",
   "metadata": {},
   "source": [
    "So, we now have an output of logits but how do we exactly figure out which label was giving the sample? Simply put:\n",
    "\n",
    "How do we do the conversions? From logits to labels?\n",
    "\n",
    "*logits -> prediction probabilities -> prediction labels*. \n",
    "\n",
    "Before we utilized *Sigmoid* and *Binary Cross Entropy* but how about this time? We're dealing with multiple classes so it can't be *Sigmoid*. \n",
    "\n",
    "That's where *softmax activation function* starts being relevant.\n",
    "\n",
    "The softmax function in it's most simplest terms, calculates the probability of each prediction class being the actual predicted class compared to all the other classes. \n",
    "\n",
    "Let's try seeing this in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eea110-b7ec-4ce5-9ba6-cf08d8295d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36307230-9439-4e2f-9153-45f4d2c09f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction logits with model\n",
    "y_logits = model_4(X_blob_train.to(device))\n",
    "\n",
    "# Perform softmax calculation on logits across dim-1 to get predicted probabilities\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "print(y_logits[:5], y_logits.shape)\n",
    "print(y_pred_probs[:5], y_pred_probs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a15fa7-815d-4889-bf87-7ed4f5153736",
   "metadata": {},
   "source": [
    "To reitarate, we apply the softmax on the first dimension which are the values of each element inside a single row.  So softmax is applied to every single row.\n",
    "\n",
    "So, the numbers are quite jibberish at best. First thing that you might notice that there is no negative numbers just akin to *ReLU* and *Sigmoid*. But if you look a little closer on each value in one single row. \n",
    "\n",
    "You might notice that the numbers are in a pattern of some sort. Specifically, they all seem to add up to 1. Let's check this hypothesis. Try summing up one row and see the total value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6507b26-61df-4d02-863a-b0563b4f67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the First Sample Output of the Softmax Activation Function\n",
    "torch.sum(y_pred_probs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585358ba-d2fd-4fb2-b842-86ce36465544",
   "metadata": {},
   "source": [
    "What this means is that for each class that we have, these prediction probabilities are saying how much the model *thinks* it is that corresponding class. \n",
    "\n",
    "Since we have values for each class that we have in *y_pred_probs* then the index with the highest value is the class that the model thinks that specific data most belong to. \n",
    "\n",
    "So, let's check the index which has the highest value using *torch.argmax()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f297958-8e6a-4b83-9175-4b969d812c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which class does the model think is *most* likely to belong to at index 0?\n",
    "print(y_pred_probs[0])\n",
    "print(torch.argmax(y_pred_probs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c461c-2679-48b1-bfb4-28df59222b2b",
   "metadata": {},
   "source": [
    "Depending on the value that you get from argmax then that would most likely be the class that the data belongs to. Try to check if the index matches that the highest value in *y_pred_probs*. \n",
    "\n",
    "Remember that we're dealing with random guesses right now due to the fact that we haven't really done any training whatsoever. So this prediction will have a 25% chance of being correct. \n",
    "\n",
    "But we don't need to randomly guess. Let's start training the model.\n",
    "\n",
    "**NOTE**: Essentially, we grabbed logits from inputting the data into the model. We convert these logits into prediction probabilities using the softmax activation function. Then we check each index in the prediction probabilities, finding the highest prediction probability. The highest prediction probability is the class that the model thinks the data given belongs to. Important to remember that it's a prediction so there's no guarantee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72373a1e-0366-470e-a838-6bebb132effd",
   "metadata": {},
   "source": [
    "**Creating a Training & Testing Loop For Multiclassifcation PyTorch Model**\n",
    "\n",
    "We now have everything that we need so it's time to write the training and testing loop. We've already written these steps multiple times but KEEP PRACTICING!\n",
    "\n",
    "The difference this time is that we'll be adjusting the steps to turn the logits (model outputs) into prediction probabilities (softmax function) and then the prediction labels (argmax of the softmax).\n",
    "\n",
    "As always, start with 100 epochs and print the results for every 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c5753-d407-428b-ad1c-7e9ee6eee9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 100\n",
    "\n",
    "X_blob_train, y_blob_train = X_blob_train.to(device), y_blob_train.to(device)\n",
    "X_blob_test, y_blob_test = X_blob_test.to(device), y_blob_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### SET TO TRAINING\n",
    "    model_4.train()\n",
    "\n",
    "    # FORWARD PASS\n",
    "    train_logits = model_4(X_blob_train)\n",
    "    # CONVERT LOGITS -> PRED PROB -> PRED LAB\n",
    "    train_pred = torch.softmax(train_logits, dim=1).argmax(dim=1)\n",
    "    # CALC LOSS (LOGITS) / CALC ACC (LAB)\n",
    "    loss = loss_fn(train_logits, y_blob_train)\n",
    "    acc = accuracy_fn(y_blob_train, train_pred)\n",
    "    # OPTIM ZERO\n",
    "    optimizer.zero_grad()\n",
    "    # BACKPROP\n",
    "    loss.backward()\n",
    "    # OPTIM STEP\n",
    "    optimizer.step()\n",
    "\n",
    "    ### SET TO TESTING\n",
    "    model_4.eval()\n",
    "    with torch.inference_mode():\n",
    "        # FORWARD PASS\n",
    "        test_logits = model_4(X_blob_test)\n",
    "        # CONVERT LOGITS -> PRED PROB -> PRED LAB\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "        # CALC LOSS (LOGITS) / CALC ACC (LAB)\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "        test_acc = accuracy_fn(y_blob_test, test_pred)\n",
    "        \n",
    "    # PRINT\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea613b7-1561-4eb9-81ef-5de72a4300c6",
   "metadata": {},
   "source": [
    "**Making & Evaluating Predictions With PyTorch Multiclassification Model**\n",
    "\n",
    "It seems like the trained model is highly capable. But let's try this out on the test set and visualize the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e92a8-a423-4003-a152-7eea1f663f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "model_4.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_4(X_blob_test)\n",
    "\n",
    "y_logits[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f8e6a-d1db-4bab-81dd-8bee367883ce",
   "metadata": {},
   "source": [
    "Seems like we forgot to apply the softmax function and convert these into prediction probabilities. We'll need to make these into an integer first as the same as *y_blob_test*. \n",
    "\n",
    "**NOTE:** It's possible to skip the torch.softmax() function and go straight from logits to labels by just calling *torch.argmax()* on the logits. This saves us time but we lose *prediction probabilities* because we never made them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa8160-c6ee-454d-b349-0be8fce2ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Softmax\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "# Apply Argmax\n",
    "y_preds = torch.argmax(y_pred_probs, dim=1)\n",
    "\n",
    "# Print Model Prediciton & Test Labels\n",
    "print(f\"Predictions: {y_preds[:10]}\\nLabels: {y_blob_test[:10]}\")\n",
    "print(f\"Test accuracy: {accuracy_fn(y_true=y_blob_test, y_pred=y_preds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8398b-abaa-4725-b136-ad39b424bdc5",
   "metadata": {},
   "source": [
    "Seems like our model is actually correct with the predictions! 99% is really really good. Let's visualize these with *plot_decision_boundary()*.\n",
    "\n",
    "It's important to remember that our tensors are in the gpu so we'll have to transfer these back to the cpu so we can work with them.\n",
    "\n",
    "Luckily the *plot_decision_boundary()* already does this automatically so we won't need to do it manually but just keep it in mind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8700e-1f13-4376-ae29-a7bd247eef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model_4, X_blob_train, y_blob_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model_4, X_blob_test, y_blob_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef1230-bb4c-483d-ac34-1dae85ad3f7a",
   "metadata": {},
   "source": [
    "It is very important to note that the model does not create 'four lines' to seperate the decision boundaries but instead visualizes where the model draws these decision boundaries on. Notice how these boundaries are all linear?\n",
    "\n",
    "We don't need to add non-linearity to the model because the groups of data can be linearilly seperated.\n",
    "\n",
    "This would be a different case if the data is much more scattered and randomized. You might ask a question, why not just add a ReLU in-case? or why not accomodate for non-linearity just for the sake? One of the goals of machine learning in classification tasks is to find the simplest model that can make the best predictions. \n",
    "\n",
    "While it's true that you can accomodate for non-linearity, you could also make the argument that why shouldn't we just accomodate for everything that we can out there? \n",
    "\n",
    "If this is how things work then we'll have a very bloated model filled with unecessary features that will only complicate and slow things down.\n",
    "\n",
    "That is why it is important to decide when to add or not to add a feature. \n",
    "\n",
    "Remember *Occam's Razor* - The simplest solution is usally the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f221ad59-ccee-4f47-9c83-5b2a2f5a450d",
   "metadata": {},
   "source": [
    "**More Classification Evaluation Metrics**\n",
    "\n",
    "We've gotten over a couple of means that we can use to evaluate metrics which were accuracy, loss, and visualization of predictions. \n",
    "\n",
    "Naturally, these are the most common methods that you can come across and are even great starting points for many more.\n",
    "\n",
    "Let's list some of these other evaluation metrics that you can use to improve models.\n",
    "\n",
    "1. **Accuracy** - Answers the question: \"Out of 100 predictions, how many did your model get correct?\" For example, if you're model got 95/100 then that means you have an accuracy of 95%. *torchmetrics.Accuracy()* / *sklearn.metrics.precision_score()*\n",
    "\n",
    "2. **Precision** - Answers the question: \"Of all the instances the model labeled as positive, how many are actually positive?\". Proportion of true positive predictions in the total predicted positives. Higher precision means fewer false positives.  *torchmetrics.Precision()* / *sklearn.metrics.precision_score()*\n",
    "\n",
    "3. **Recall** - Answers the question: \"Of all the actual positives, how many did the model label correctly\". It is also known as sensitivity, is the proportion of true positives that were correctly identified by the model. Higher recall means fewer false negatives. *torchmetrics.Recall()* / *sklearn.metrics.recall_score()*\n",
    "\n",
    "4. **F1-Score** - Combines both precision and recall into one metric. 1 is best while 0 is worst. *torchmetrics.F1Score()* / *sklearn.metrics.f1_score()*\n",
    "\n",
    "5. **Confusion Matrix** - Compares predicted values with the true values in a tabular way. If it is 100% correct then all the values in the matrix will be top left to botto right. Basically forming a diagonal line. *torchmetrics.ConfusionMatrix* or *sklearn.metrics.plot_confusion_matrix()*.  --- MORE ON THIS --- \n",
    "\n",
    "6. **Classification Report** -  Collection of some of the main classification metrics such as precision, recall, and F1-Score. *sklearn.metrics.classification_report()*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe172d0d-968d-467e-9dbb-34249b0bfadf",
   "metadata": {},
   "source": [
    "Skicit-Learn is a popular machine learning library that has many implementations of the mentioned metrics above. If you want PyTorch-like versions then you can also check out TorchMetrics. \n",
    "\n",
    "Let's look at the *torchmetrics.Accuracy* and try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32224ec8-ea50-41c4-bb35-3be3a5d7fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Setting up the metrics and making sure it's on the proper target device\n",
    "torchmetrics_accuracy = Accuracy(task='multiclass', num_classes=4).to(device)\n",
    "\n",
    "# Calculate Accuracy\n",
    "torchmetrics_accuracy(y_preds, y_blob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910a5d9-e0a7-4cd0-83f9-f77bb0f89f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
