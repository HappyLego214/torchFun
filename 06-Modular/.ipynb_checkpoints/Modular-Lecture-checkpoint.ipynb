{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca476be-c46d-4351-a9ae-ea6d586effeb",
   "metadata": {},
   "source": [
    "# 05 - Going Modular #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedca19a-c596-4c8b-9e21-4225d6c34c6c",
   "metadata": {},
   "source": [
    "We've primarily been working with jupyter notebook ever since this course started so in this chapter we'll be thinking of how to turn these notebook code into Python scripts. At the end of the day, when it comes to creating production code, you'll have to make Python scripts.\n",
    "\n",
    "To start off, we'll be using taking the most useful code cells from the previous chapter - PyTorch Custom Datasets into a series of Python scripts that is going to be saved in a directory called *going_modular*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f888e4-20aa-4188-8fb6-5c4a0e738687",
   "metadata": {},
   "source": [
    "**What is Going Modular?**\n",
    "\n",
    "If we want to be modular, we'll have to turn notebook code into a series of different Python scripts that offer the same functionality. Remember how we had helper code before and we just called them from their .py scripts? That's what we're going to do in this chapter.\n",
    "\n",
    "For example, we could make the following notebook code into their own script files:\n",
    "\n",
    "1. *data_setup.py* - a script that prepares and downloads data if needed.\n",
    "2. *engine.py* - a script that contains different training functions.\n",
    "3. *model_builder.py* or *model.py* - a script that creates a PyTorch model.\n",
    "4. *train.py* - a script that runs through all the other scripts to train a target PyTorch model.\n",
    "5. *utils.py* - a script that is solely for containing helpful utility functions.\n",
    "\n",
    "**NOTE**: The different naming functions for these files are entirely dependent on the use case and the code contained. You can treat Python scripts as individual notebook cells which means that you can create a Python script to suite for any functionality that you need. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445686e-c46b-468b-91cc-279c49d5bb77",
   "metadata": {},
   "source": [
    "**Why Modular?**\n",
    "\n",
    "Notebooks are excellent ways for experimenting and exploring. You don't need to run the entire code but instead can just run cells individually. But the dynamics change when working with larger scale projects. You may find that Python scripts are much more easier to run.\n",
    "\n",
    "This isn't really a factual statement. There are debates to which is better - Notebooks or Scripts since apparently, Netflix uses notebooks for their production code.\n",
    "\n",
    "Just to be clear **prodcution code** is code that is run to offer services to someone or something - basically it's code that is being practically delivered to users for them to do whatever. It's very important.\n",
    "\n",
    "For example, if you've made a model and the code associated with it and it is being actively used by other people or is being relied on by other codebases then that is production code.\n",
    "\n",
    "Let's go over the pros and cons of Notebooks & Python Scripts\n",
    "\n",
    "1. **Notebooks** - **PROS**: easy to experiment, easy to share, and highly visual | **CONS**: Versioning is hard, split to specific parts, and text + graphics can make code look too convoluted.\n",
    "\n",
    "2. **Python Scripts** - **PROS**: Can package code together - no need to rewrite code anymore, git for version control, open source projects use scripts, larger projects can be run with cloud vendors | **CONS**: Experimenting isn't that quick and is not really visual, you run the entire project (all the code) than just one cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcd5ce-7131-4b25-93fe-99277114fa06",
   "metadata": {},
   "source": [
    "![Display](images/05-my-workflow-for-experimenting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9994f-e377-4b95-977e-74f230399105",
   "metadata": {},
   "source": [
    "This is one example of a workflow that starts with experimenting from Jupyter Notebook and then transitioning to Python scripts. You can do the same vice versa if you want. There's no 'line' to follow. Just make whatever you want that suits you best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a422e0-141a-449c-80d6-70097d2b956e",
   "metadata": {},
   "source": [
    "**PyTorch in the Wild**\n",
    "\n",
    "There will be a lot of times that you will encounter code repositories with PyTorch-based ML projects that have instructions on how to to run their PyTorch code in the form of Python scripts. \n",
    "\n",
    "So for example, you'll be seeing code that deals with writing in the command line specific parameters to run what you need.\n",
    "\n",
    ": *python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86126965-68ab-4f50-ac11-a2f9bab6b9f3",
   "metadata": {},
   "source": [
    "![Display](images/05-python-train-command-line-annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ea624-fe3e-4ff3-94fb-6378ce07c76f",
   "metadata": {},
   "source": [
    "This explains in a visual way what the previous command line instructions is supposed to work. You can notice that we call *train.py* script alongside the various hyperparameters settings associated to train the model. \n",
    "\n",
    "Going over this again:\n",
    "\n",
    "*train.py* is the target Python script which contains the many different functions to train a PyTorch model.\n",
    "\n",
    "*--model*, *--batch_size*, *--lr*, *--num_epochs* are known as argument flags. \n",
    "\n",
    "We can set these argument flags to whatever value we want and need but of course they must be compatible with *train.py* meaning that they should be recognizable by script or else you'll get an error. \n",
    "\n",
    "Let's try putting in some values that we want. Let's say from the previous chapter. We use the command line to input the TinyVGG model as the one that we'll train with a batch_size of 32 for the *DataLoaders*, with a learning rate of 0.001, and we'll train for 10 epochs.\n",
    "\n",
    "*python train.py --model TinyVGG --batch_size 32 --lr 0.001 --num_epochs 10*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c94234-158c-4297-ac75-7b2bcae6c3cf",
   "metadata": {},
   "source": [
    "You're not only limited to these argument flags. You can also add in some other arguments that you want, for example, if you want to specify the loss function or the optimizer then you can add these. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7613416-e1e8-49f9-af5c-5b1388061267",
   "metadata": {},
   "source": [
    "Take a look how the PyTorch blog post for training state-of-the-art computer vision models uses this style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828edbe-794c-4535-a055-d2943e582e84",
   "metadata": {},
   "source": [
    "![Display](images/05-training-sota-recipe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd2c77-56d1-4e61-868a-4ed1e88c5a3a",
   "metadata": {},
   "source": [
    "**Coverage of Chapter**\n",
    "\n",
    "The main idea of this chapter is to *turn the notebook code cells into reusable Python files.*\n",
    "\n",
    "Because this saves us from rewriting code over and over again. There are two different notebooks for this section:\n",
    "\n",
    "1. [05. Going Modular: Part 1 (cell mode)](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb) - This notebook serves as a traditional Jupyter Notebook and is pretty much just a condensed version of the previous chapter.\n",
    "\n",
    "3. [05. Going Modular: Part 2 (script mode)](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb) - This notebook is written akin to a Python Script. It has added functionality to turn each major section into *Python Scripts* - such as *data_setup.py* and *train.py*\n",
    "\n",
    "We're going to focus more on the script mode version so you're probably thinking\n",
    "\n",
    "**Why Is There Two Parts?**\n",
    "\n",
    "That's because it's another way to --- VISUALIZE! The reason that we split these into a notebook and script part is that you can compare  the implementations of the two and see the differences. You can't identify what you're learning if you aren't paying attention to the difference on the implementation of a notebook and a script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae6244-9214-49dd-ae48-faa427ca643d",
   "metadata": {},
   "source": [
    "![Display](images/05-notebook-cell-mode-vs-script-mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8783673-9c1a-4fd4-93a6-a3ada4c36de4",
   "metadata": {},
   "source": [
    "If you run the two notebooks side-by-side then you'll notice that the script notebook applies a function that makes the notebook cells into a Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6722df-2c94-4e21-9390-021200aef497",
   "metadata": {},
   "source": [
    "**What We're Going For**\n",
    "\n",
    "By the end of this chapter we'd want to have two things to come out:\n",
    "\n",
    "1. The ability to train the model that we've built in the previous chapter - TinyVGG with one line of instruction on the command line: *python train.py*\n",
    "\n",
    "2. The directory structure of reusable Python scripts. Example:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e07b399a-4d0e-42e2-94c2-1ddffd8d47ee",
   "metadata": {},
   "source": [
    "going_modular/\n",
    "├── going_modular/\n",
    "│   ├── data_setup.py\n",
    "│   ├── engine.py\n",
    "│   ├── model_builder.py\n",
    "│   ├── train.py\n",
    "│   └── utils.py\n",
    "├── models/\n",
    "│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth\n",
    "│   └── 05_going_modular_script_mode_tinyvgg_model.pth\n",
    "└── data/\n",
    "    └── pizza_steak_sushi/\n",
    "        ├── train/\n",
    "        │   ├── pizza/\n",
    "        │   │   ├── image01.jpeg\n",
    "        │   │   └── ...\n",
    "        │   ├── steak/\n",
    "        │   └── sushi/\n",
    "        └── test/\n",
    "            ├── pizza/\n",
    "            ├── steak/\n",
    "            └── sushi/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a03e4-11f2-441d-9a9a-a504522b145e",
   "metadata": {},
   "source": [
    "**Things To Take Note**\n",
    "\n",
    "* **Docstrings** - It is valuable and important to write reproducable/understandable code. All the code that is written in this section follows *Google's Python Docstring* style.\n",
    "\n",
    "* **Important Items At The Top** - All the import modules and the necessary items needed for the code below to run are always placed on top of the script. So things like *import torch* or *from torchvision import transforms* are always placed at the very first lines of the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18541d45-1ab9-4d7c-a827-a863174fd536",
   "metadata": {},
   "source": [
    "**Cell Mode vs Script Mode**\n",
    "\n",
    "The cell mode notebook is meant to run as a regular notebook with individual cells. Majority of the codeblocks are in code or markdown. Script notebooks on the other hand are for the most part, similiar to a regular notebook but with the added caveat that it turns the code cells into Python script.\n",
    "\n",
    "It is important to note that you should work with an IDE such as Visual Studio Code when working with the script mode. The reason why the script mode is utilizing notebook is because it's just a way to demonstrate how notebooks can be converted to Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949cf96-a47a-449b-a5c6-5486b30fd7a3",
   "metadata": {},
   "source": [
    "**Storing Scripts**\n",
    "\n",
    "We'll need a place to call these scripts from and at the same time store it. It's best to create a folder to place these in. You can decide on the name for yourself but in this case, we'll call it *going_modular* and make that with Python's *os.makedirs()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5228da5b-9318-4000-8faf-85b8d26445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"scripts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb7796-1c2a-4f51-8ade-6bd2ce050d15",
   "metadata": {},
   "source": [
    "**1. Get Data**\n",
    "\n",
    "We'll start off with the same method as the previous chapter when it comes to downloading the data that we need. We'll still work with *pizza_steak_sushi* so that there's less to worry about when it comes to errors and the like because we've already worked this out before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51433bc-f64d-4962-be15-ab8f5a98ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi - This directory already exists!\n",
      "Downloading Dataset\n",
      "Extracting Dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path/\"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} - This directory already exists!\")\n",
    "else: \n",
    "    print(f\"{image_path} - Does not exist ... Creating directory\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(data_path/'pizza_steak_sushi.zip', 'wb') as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
    "    print(f\"Downloading Dataset\")\n",
    "    f.write(request.content)\n",
    "\n",
    "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as data_zip:\n",
    "    print(f\"Extracting Dataset\")\n",
    "    data_zip.extractall(image_path)\n",
    "\n",
    "os.remove(data_path/'pizza_steak_sushi.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92ae0ae-8ee3-47c5-9d32-68fde0306405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path/'train'\n",
    "test_dir = image_path/'test'\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85186291-e208-49f7-87d3-a96ceb38240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37c7819-01a9-40fa-bc4f-3964d63fd494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset ImageFolder\n",
       "     Number of datapoints: 450\n",
       "     Root location: data\\pizza_steak_sushi\\train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset ImageFolder\n",
       "     Number of datapoints: 150\n",
       "     Root location: data\\pizza_steak_sushi\\test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=simple_transform, target_transform=None)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=simple_transform, target_transform=None)\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b507c87b-2d74-4a7c-ac9e-99602d8bc578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4961fae0-d9b5-48da-9ae4-30363dfc97f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pizza': 0, 'steak': 1, 'sushi': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = train_dataset.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef38f7d-ffe5-4b1b-84df-c1f8163ce02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a2dbc9-778f-4602-8b2b-0472c2c04c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1b11c1cfe60>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1b113a8f260>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce40c8c-e58a-4699-a775-cf334c923960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 64, 64]), torch.Size([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1957bef6-5bdd-4c1f-94d1-dbf9b66048ba",
   "metadata": {},
   "source": [
    "**Creating Datasets & DataLoaders - Script Mode**\n",
    "\n",
    "- Refer to *data_setup.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a3389",
   "metadata": {},
   "source": [
    "**Creating Model Builder - Script Mode**\n",
    "\n",
    "* Refer to model_builder.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f66b4e-c361-49b8-b2a5-22b5e9849b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (convblock1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convblock2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Instantiating a model from model_builder.py\n",
    "\n",
    "from scripts import model_builder\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device is {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = model_builder.TinyVGG(3, 10, len(class_names))\n",
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dad800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Image Shape: torch.Size([1, 3, 64, 64])\n",
      "\n",
      "Output Logits: tensor([[ 0.0208, -0.0475,  0.0334]], device='cuda:0')\n",
      "\n",
      "Output Prediction Probabilities: tensor([[0.3394, 0.3170, 0.3437]], device='cuda:0')\n",
      "\n",
      "Output Labels: tensor([2], device='cuda:0')\n",
      "\n",
      "Output Labels: sushi\n",
      "\n",
      "Actual Label: pizza\n"
     ]
    }
   ],
   "source": [
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single Image Shape: {img_single.shape}\\n\")\n",
    "\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    preds = model_0(img_single.to(device))\n",
    "\n",
    "print(f\"Output Logits: {preds}\\n\")\n",
    "print(f\"Output Prediction Probabilities: {torch.softmax(preds, 1)}\\n\")\n",
    "print(f\"Output Labels: {torch.argmax(torch.softmax(preds, dim=1), dim=1)}\\n\")\n",
    "print(f\"Output Labels: {class_names[torch.argmax(torch.softmax(preds, dim=1), dim=1)]}\\n\")\n",
    "print(f\"Actual Label: {class_names[label_single]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19b098c-74cf-4202-ba91-8cf6a8e4ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "  train_dir: str,\n",
    "  test_dir: str,\n",
    "  transform: transforms.Compose,\n",
    "  batch_size: int,\n",
    "  num_workers: int=NUM_WORKERS\n",
    "):\n",
    "\n",
    "    # Creating Dataset\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "    # Creating class list\n",
    "    class_list = train_dataset.classes\n",
    "\n",
    "    # Creating DataLoader\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd70fb26-54fe-4dba-80d9-8373007727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm    \n",
    "\n",
    "def train_step(\n",
    "       model: torch.nn.Module,\n",
    "       dataloader: torch.utils.data.DataLoader,\n",
    "       loss_fn: torch.nn.Module,\n",
    "       optimizer: torch.optim.Optimizer,\n",
    "       device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0,0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax((torch.softmax(logits, dim=1)), dim=1)\n",
    "        train_acc += ((preds == y).sum().item() / len(preds))\n",
    "    \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc \n",
    "\n",
    "def test_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0,0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            test_loss += loss\n",
    "\n",
    "            preds = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
    "            test_acc += ((preds == y).sum().item() / len(preds))\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(\n",
    "        model: torch.nn.Module,\n",
    "        train_dataloader: torch.utils.data.DataLoader,\n",
    "        test_dataloader: torch.utils.data.DataLoader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device: torch.device,\n",
    "        epochs: int = 10\n",
    "):\n",
    "    \n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Train Accuracy: {train_acc:.4f} | \"\n",
    "            f\"Test Loss: {test_loss:.4f} | \"\n",
    "            f\"Test Accuracy: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c1d079-88ae-4f2e-a674-5e23e9758253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Jupyter/torchFun/data/pizza_steak_sushi/train')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data')\n",
    "image_path = data_path/'pizza_steak_sushi'\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "train_dir = parent_dir/image_path/'train'\n",
    "test_dir = parent_dir/image_path/'test'\n",
    "\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d5f7aa-31f1-4be7-b20b-e5ca20a5ba92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_setup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 35\u001B[0m\n\u001B[0;32m     28\u001B[0m model_path \u001B[38;5;241m=\u001B[39m parent_dir\u001B[38;5;241m/\u001B[39mPath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     30\u001B[0m data_transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m     31\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m64\u001B[39m,\u001B[38;5;241m64\u001B[39m)),\n\u001B[0;32m     32\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor()\n\u001B[0;32m     33\u001B[0m ])\n\u001B[1;32m---> 35\u001B[0m train_dataloader, test_dataloader, class_list \u001B[38;5;241m=\u001B[39m \u001B[43mdata_setup\u001B[49m\u001B[38;5;241m.\u001B[39mcreate_dataloaders(\n\u001B[0;32m     36\u001B[0m     train_dir\u001B[38;5;241m=\u001B[39mtrain_dir,\n\u001B[0;32m     37\u001B[0m     test_dir\u001B[38;5;241m=\u001B[39mtest_dir,\n\u001B[0;32m     38\u001B[0m     transform\u001B[38;5;241m=\u001B[39mdata_transform,\n\u001B[0;32m     39\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE,\n\u001B[0;32m     40\u001B[0m     num_workers\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mcpu_count()\n\u001B[0;32m     41\u001B[0m )\n\u001B[0;32m     43\u001B[0m model_0 \u001B[38;5;241m=\u001B[39m model_builder\u001B[38;5;241m.\u001B[39mTinyVGG(input_shape\u001B[38;5;241m=\u001B[39mINPUT_SHAPE, hidden_units\u001B[38;5;241m=\u001B[39mHIDDEN_UNITS, output_shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(class_list))\n\u001B[0;32m     44\u001B[0m model_0\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data_setup' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "    \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 0.001\n",
    "HIDDEN_UNITS = 10\n",
    "INPUT_SHAPE = 3\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "data_path = Path('data')\n",
    "image_path = data_path/'pizza_steak_sushi'\n",
    "\n",
    "train_dir = image_path/'train'\n",
    "test_dir = image_path/'test'\n",
    "\n",
    "model_path = parent_dir/Path('models')\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_list = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=data_transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "\n",
    "model_0 = TinyVGG(input_shape=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, output_shape=len(class_list))\n",
    "model_0.to(device)\n",
    "\n",
    "print(f\"Using {device} For Training\")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_0.parameters(), lr=LR)\n",
    "\n",
    "results = engine.train(\n",
    "    model=model_0,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device = device,\n",
    "    epochs = EPOCHS\n",
    ")\n",
    "\n",
    "utils.save_model(\n",
    "    model=model_0,\n",
    "    target_dir=model_path,\n",
    "    model_name='TinyVGG'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed87738-e657-49fd-a72b-72ba707d7611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
