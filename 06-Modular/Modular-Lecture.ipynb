{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca476be-c46d-4351-a9ae-ea6d586effeb",
   "metadata": {},
   "source": [
    "# 05 - Going Modular #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedca19a-c596-4c8b-9e21-4225d6c34c6c",
   "metadata": {},
   "source": [
    "We've primarily been working with jupyter notebook ever since this course started so in this chapter we'll be thinking of how to turn these notebook code into Python scripts. At the end of the day, when it comes to creating production code, you'll have to make Python scripts.\n",
    "\n",
    "To start off, we'll be using taking the most useful code cells from the previous chapter - PyTorch Custom Datasets into a series of Python scripts that is going to be saved in a directory called *going_modular*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f888e4-20aa-4188-8fb6-5c4a0e738687",
   "metadata": {},
   "source": [
    "**What is Going Modular?**\n",
    "\n",
    "If we want to be modular, we'll have to turn notebook code into a series of different Python scripts that offer the same functionality. Remember how we had helper code before and we just called them from their .py scripts? That's what we're going to do in this chapter.\n",
    "\n",
    "For example, we could make the following notebook code into their own script files:\n",
    "\n",
    "1. *data_setup.py* - a script that prepares and downloads data if needed.\n",
    "2. *engine.py* - a script that contains different training functions.\n",
    "3. *model_builder.py* or *model.py* - a script that creates a PyTorch model.\n",
    "4. *train.py* - a script that runs through all the other scripts to train a target PyTorch model.\n",
    "5. *utils.py* - a script that is solely for containing helpful utility functions.\n",
    "\n",
    "**NOTE**: The different naming functions for these files are entirely dependent on the use case and the code contained. You can treat Python scripts as individual notebook cells which means that you can create a Python script to suite for any functionality that you need. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445686e-c46b-468b-91cc-279c49d5bb77",
   "metadata": {},
   "source": [
    "**Why Modular?**\n",
    "\n",
    "Notebooks are excellent ways for experimenting and exploring. You don't need to run the entire code but instead can just run cells individually. But the dynamics change when working with larger scale projects. You may find that Python scripts are much more easier to run.\n",
    "\n",
    "This isn't really a factual statement. There are debates to which is better - Notebooks or Scripts since apparently, Netflix uses notebooks for their production code.\n",
    "\n",
    "Just to be clear **prodcution code** is code that is run to offer services to someone or something - basically it's code that is being practically delivered to users for them to do whatever. It's very important.\n",
    "\n",
    "For example, if you've made a model and the code associated with it and it is being actively used by other people or is being relied on by other codebases then that is production code.\n",
    "\n",
    "Let's go over the pros and cons of Notebooks & Python Scripts\n",
    "\n",
    "1. **Notebooks** - **PROS**: easy to experiment, easy to share, and highly visual | **CONS**: Versioning is hard, split to specific parts, and text + graphics can make code look too convoluted.\n",
    "\n",
    "2. **Python Scripts** - **PROS**: Can package code together - no need to rewrite code anymore, git for version control, open source projects use scripts, larger projects can be run with cloud vendors | **CONS**: Experimenting isn't that quick and is not really visual, you run the entire project (all the code) than just one cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcd5ce-7131-4b25-93fe-99277114fa06",
   "metadata": {},
   "source": [
    "![Display](images/05-my-workflow-for-experimenting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9994f-e377-4b95-977e-74f230399105",
   "metadata": {},
   "source": [
    "This is one example of a workflow that starts with experimenting from Jupyter Notebook and then transitioning to Python scripts. You can do the same vice versa if you want. There's no 'line' to follow. Just make whatever you want that suits you best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a422e0-141a-449c-80d6-70097d2b956e",
   "metadata": {},
   "source": [
    "**PyTorch in the Wild**\n",
    "\n",
    "There will be a lot of times that you will encounter code repositories with PyTorch-based ML projects that have instructions on how to to run their PyTorch code in the form of Python scripts. \n",
    "\n",
    "So for example, you'll be seeing code that deals with writing in the command line specific parameters to run what you need.\n",
    "\n",
    ": *python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86126965-68ab-4f50-ac11-a2f9bab6b9f3",
   "metadata": {},
   "source": [
    "![Display](images/05-python-train-command-line-annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ea624-fe3e-4ff3-94fb-6378ce07c76f",
   "metadata": {},
   "source": [
    "This explains in a visual way what the previous command line instructions is supposed to work. You can notice that we call *train.py* script alongside the various hyperparameters settings associated to train the model. \n",
    "\n",
    "Going over this again:\n",
    "\n",
    "*train.py* is the target Python script which contains the many different functions to train a PyTorch model.\n",
    "\n",
    "*--model*, *--batch_size*, *--lr*, *--num_epochs* are known as argument flags. \n",
    "\n",
    "We can set these argument flags to whatever value we want and need but of course they must be compatible with *train.py* meaning that they should be recognizable by script or else you'll get an error. \n",
    "\n",
    "Let's try putting in some values that we want. Let's say from the previous chapter. We use the command line to input the TinyVGG model as the one that we'll train with a batch_size of 32 for the *DataLoaders*, with a learning rate of 0.001, and we'll train for 10 epochs.\n",
    "\n",
    "*python train.py --model TinyVGG --batch_size 32 --lr 0.001 --num_epochs 10*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c94234-158c-4297-ac75-7b2bcae6c3cf",
   "metadata": {},
   "source": [
    "You're not only limited to these argument flags. You can also add in some other arguments that you want, for example, if you want to specify the loss function or the optimizer then you can add these. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7613416-e1e8-49f9-af5c-5b1388061267",
   "metadata": {},
   "source": [
    "Take a look how the PyTorch blog post for training state-of-the-art computer vision models uses this style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828edbe-794c-4535-a055-d2943e582e84",
   "metadata": {},
   "source": [
    "![Display](images/05-training-sota-recipe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd2c77-56d1-4e61-868a-4ed1e88c5a3a",
   "metadata": {},
   "source": [
    "**Coverage of Chapter**\n",
    "\n",
    "The main idea of this chapter is to *turn the notebook code cells into reusable Python files.*\n",
    "\n",
    "Because this saves us from rewriting code over and over again. There are two different notebooks for this section:\n",
    "\n",
    "1. [05. Going Modular: Part 1 (cell mode)](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb) - This notebook serves as a traditional Jupyter Notebook and is pretty much just a condensed version of the previous chapter.\n",
    "\n",
    "3. [05. Going Modular: Part 2 (script mode)](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb) - This notebook is written akin to a Python Script. It has added functionality to turn each major section into *Python Scripts* - such as *data_setup.py* and *train.py*\n",
    "\n",
    "We're going to focus more on the script mode version so you're probably thinking\n",
    "\n",
    "**Why Is There Two Parts?**\n",
    "\n",
    "That's because it's another way to --- VISUALIZE! The reason that we split these into a notebook and script part is that you can compare  the implementations of the two and see the differences. You can't identify what you're learning if you aren't paying attention to the difference on the implementation of a notebook and a script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae6244-9214-49dd-ae48-faa427ca643d",
   "metadata": {},
   "source": [
    "![Display](images/05-notebook-cell-mode-vs-script-mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8783673-9c1a-4fd4-93a6-a3ada4c36de4",
   "metadata": {},
   "source": [
    "If you run the two notebooks side-by-side then you'll notice that the script notebook applies a function that makes the notebook cells into a Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6722df-2c94-4e21-9390-021200aef497",
   "metadata": {},
   "source": [
    "**What We're Going For**\n",
    "\n",
    "By the end of this chapter we'd want to have two things to come out:\n",
    "\n",
    "1. The ability to train the model that we've built in the previous chapter - TinyVGG with one line of instruction on the command line: *python train.py*\n",
    "\n",
    "2. The directory structure of reusable Python scripts. Example:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e07b399a-4d0e-42e2-94c2-1ddffd8d47ee",
   "metadata": {},
   "source": [
    "going_modular/\n",
    "├── going_modular/\n",
    "│   ├── data_setup.py\n",
    "│   ├── engine.py\n",
    "│   ├── model_builder.py\n",
    "│   ├── train.py\n",
    "│   └── utils.py\n",
    "├── models/\n",
    "│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth\n",
    "│   └── 05_going_modular_script_mode_tinyvgg_model.pth\n",
    "└── data/\n",
    "    └── pizza_steak_sushi/\n",
    "        ├── train/\n",
    "        │   ├── pizza/\n",
    "        │   │   ├── image01.jpeg\n",
    "        │   │   └── ...\n",
    "        │   ├── steak/\n",
    "        │   └── sushi/\n",
    "        └── test/\n",
    "            ├── pizza/\n",
    "            ├── steak/\n",
    "            └── sushi/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a03e4-11f2-441d-9a9a-a504522b145e",
   "metadata": {},
   "source": [
    "**Things To Take Note**\n",
    "\n",
    "* **Docstrings** - It is valuable and important to write reproducable/understandable code. All the code that is written in this section follows *Google's Python Docstring* style.\n",
    "\n",
    "* **Important Items At The Top** - All the import modules and the necessary items needed for the code below to run are always placed on top of the script. So things like *import torch* or *from torchvision import transforms* are always placed at the very first lines of the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18541d45-1ab9-4d7c-a827-a863174fd536",
   "metadata": {},
   "source": [
    "**Cell Mode vs Script Mode**\n",
    "\n",
    "The cell mode notebook is meant to run as a regular notebook with individual cells. Majority of the codeblocks are in code or markdown. Script notebooks on the other hand are for the most part, similiar to a regular notebook but with the added caveat that it turns the code cells into Python script.\n",
    "\n",
    "It is important to note that you should work with an IDE such as Visual Studio Code when working with the script mode. The reason why the script mode is utilizing notebook is because it's just a way to demonstrate how notebooks can be converted to Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949cf96-a47a-449b-a5c6-5486b30fd7a3",
   "metadata": {},
   "source": [
    "**Storing Scripts**\n",
    "\n",
    "We'll need a place to call these scripts from and at the same time store it. It's best to create a folder to place these in. You can decide on the name for yourself but in this case, we'll call it *going_modular* and make that with Python's *os.makedirs()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5228da5b-9318-4000-8faf-85b8d26445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"scripts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb7796-1c2a-4f51-8ade-6bd2ce050d15",
   "metadata": {},
   "source": [
    "**1. Get Data**\n",
    "\n",
    "We'll start off with the same method as the previous chapter when it comes to downloading the data that we need. We'll still work with *pizza_steak_sushi* so that there's less to worry about when it comes to errors and the like because we've already worked this out before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51433bc-f64d-4962-be15-ab8f5a98ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi - This directory already exists!\n",
      "Downloading Dataset\n",
      "Extracting Dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path/\"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} - This directory already exists!\")\n",
    "else: \n",
    "    print(f\"{image_path} - Does not exist ... Creating directory\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(data_path/'pizza_steak_sushi.zip', 'wb') as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
    "    print(f\"Downloading Dataset\")\n",
    "    f.write(request.content)\n",
    "\n",
    "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as data_zip:\n",
    "    print(f\"Extracting Dataset\")\n",
    "    data_zip.extractall(image_path)\n",
    "\n",
    "os.remove(data_path/'pizza_steak_sushi.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92ae0ae-8ee3-47c5-9d32-68fde0306405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path/'train'\n",
    "test_dir = image_path/'test'\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85186291-e208-49f7-87d3-a96ceb38240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37c7819-01a9-40fa-bc4f-3964d63fd494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset ImageFolder\n",
       "     Number of datapoints: 450\n",
       "     Root location: data\\pizza_steak_sushi\\train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset ImageFolder\n",
       "     Number of datapoints: 150\n",
       "     Root location: data\\pizza_steak_sushi\\test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=simple_transform, target_transform=None)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=simple_transform, target_transform=None)\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b507c87b-2d74-4a7c-ac9e-99602d8bc578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4961fae0-d9b5-48da-9ae4-30363dfc97f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pizza': 0, 'steak': 1, 'sushi': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = train_dataset.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef38f7d-ffe5-4b1b-84df-c1f8163ce02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a2dbc9-778f-4602-8b2b-0472c2c04c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1b11c1cfe60>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1b113a8f260>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce40c8c-e58a-4699-a775-cf334c923960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 64, 64]), torch.Size([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1957bef6-5bdd-4c1f-94d1-dbf9b66048ba",
   "metadata": {},
   "source": [
    "**Creating Datasets & DataLoaders - Script Mode**\n",
    "\n",
    "- Refer to *data_setup.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a3389",
   "metadata": {},
   "source": [
    "**Creating Model Builder - Script Mode**\n",
    "\n",
    "* Refer to model_builder.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f66b4e-c361-49b8-b2a5-22b5e9849b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (convblock1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convblock2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Instantiating a model from model_builder.py\n",
    "\n",
    "from scripts import model_builder\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device is {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = model_builder.TinyVGG(3, 10, len(class_names))\n",
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dad800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Image Shape: torch.Size([1, 3, 64, 64])\n",
      "\n",
      "Output Logits: tensor([[ 0.0208, -0.0475,  0.0334]], device='cuda:0')\n",
      "\n",
      "Output Prediction Probabilities: tensor([[0.3394, 0.3170, 0.3437]], device='cuda:0')\n",
      "\n",
      "Output Labels: tensor([2], device='cuda:0')\n",
      "\n",
      "Output Labels: sushi\n",
      "\n",
      "Actual Label: pizza\n"
     ]
    }
   ],
   "source": [
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single Image Shape: {img_single.shape}\\n\")\n",
    "\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    preds = model_0(img_single.to(device))\n",
    "\n",
    "print(f\"Output Logits: {preds}\\n\")\n",
    "print(f\"Output Prediction Probabilities: {torch.softmax(preds, 1)}\\n\")\n",
    "print(f\"Output Labels: {torch.argmax(torch.softmax(preds, dim=1), dim=1)}\\n\")\n",
    "print(f\"Output Labels: {class_names[torch.argmax(torch.softmax(preds, dim=1), dim=1)]}\\n\")\n",
    "print(f\"Actual Label: {class_names[label_single]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19b098c-74cf-4202-ba91-8cf6a8e4ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "  train_dir: str,\n",
    "  test_dir: str,\n",
    "  transform: transforms.Compose,\n",
    "  batch_size: int,\n",
    "  num_workers: int=NUM_WORKERS\n",
    "):\n",
    "\n",
    "    # Creating Dataset\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "    # Creating class list\n",
    "    class_list = train_dataset.classes\n",
    "\n",
    "    # Creating DataLoader\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd70fb26-54fe-4dba-80d9-8373007727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm    \n",
    "\n",
    "def train_step(\n",
    "       model: torch.nn.Module,\n",
    "       dataloader: torch.utils.data.DataLoader,\n",
    "       loss_fn: torch.nn.Module,\n",
    "       optimizer: torch.optim.Optimizer,\n",
    "       device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0,0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax((torch.softmax(logits, dim=1)), dim=1)\n",
    "        train_acc += ((preds == y).sum().item() / len(preds))\n",
    "    \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc \n",
    "\n",
    "def test_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0,0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            test_loss += loss\n",
    "\n",
    "            preds = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
    "            test_acc += ((preds == y).sum().item() / len(preds))\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(\n",
    "        model: torch.nn.Module,\n",
    "        train_dataloader: torch.utils.data.DataLoader,\n",
    "        test_dataloader: torch.utils.data.DataLoader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device: torch.device,\n",
    "        epochs: int = 10\n",
    "):\n",
    "    \n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Train Accuracy: {train_acc:.4f} | \"\n",
    "            f\"Test Loss: {test_loss:.4f} | \"\n",
    "            f\"Test Accuracy: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c1d079-88ae-4f2e-a674-5e23e9758253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Jupyter/torchFun/data/pizza_steak_sushi/train')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data')\n",
    "image_path = data_path/'pizza_steak_sushi'\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "train_dir = parent_dir/image_path/'train'\n",
    "test_dir = parent_dir/image_path/'test'\n",
    "\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7782a3cc-0124-4104-82e0-7275e22ac512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85d5f7aa-31f1-4be7-b20b-e5ca20a5ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda For Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34de6dca4e64b59b1a998e09add9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 51\u001B[0m\n\u001B[0;32m     48\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m     49\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mSGD(model_0\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mLR)\n\u001B[1;32m---> 51\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m save_model(\n\u001B[0;32m     62\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel_0,\n\u001B[0;32m     63\u001B[0m     target_dir\u001B[38;5;241m=\u001B[39mmodel_path,\n\u001B[0;32m     64\u001B[0m     model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTinyVGG\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     65\u001B[0m )\n",
      "Cell \u001B[1;32mIn[14], line 77\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, device, epochs)\u001B[0m\n\u001B[0;32m     69\u001B[0m results \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_acc\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_acc\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m     74\u001B[0m }\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(epochs)):\n\u001B[1;32m---> 77\u001B[0m     train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m     test_loss, test_acc \u001B[38;5;241m=\u001B[39m test_step(\n\u001B[0;32m     86\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     87\u001B[0m         dataloader\u001B[38;5;241m=\u001B[39mtest_dataloader,\n\u001B[0;32m     88\u001B[0m         loss_fn\u001B[38;5;241m=\u001B[39mloss_fn,\n\u001B[0;32m     89\u001B[0m         device\u001B[38;5;241m=\u001B[39mdevice\n\u001B[0;32m     90\u001B[0m     )\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m     93\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     97\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     98\u001B[0m     )\n",
      "Cell \u001B[1;32mIn[14], line 16\u001B[0m, in \u001B[0;36mtrain_step\u001B[1;34m(model, dataloader, loss_fn, optimizer, device)\u001B[0m\n\u001B[0;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     14\u001B[0m train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 16\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1291\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1292\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1294\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1295\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1296\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1297\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1122\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1133\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1135\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[0;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[1;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:346\u001B[0m, in \u001B[0;36mPipeConnection._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_got_empty_message \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m    344\u001B[0m             _winapi\u001B[38;5;241m.\u001B[39mPeekNamedPipe(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:1084\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(object_list, timeout)\u001B[0m\n\u001B[0;32m   1081\u001B[0m                 ready_objects\u001B[38;5;241m.\u001B[39madd(o)\n\u001B[0;32m   1082\u001B[0m                 timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1084\u001B[0m     ready_handles \u001B[38;5;241m=\u001B[39m \u001B[43m_exhaustive_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwaithandle_to_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;66;03m# request that overlapped reads stop\u001B[39;00m\n\u001B[0;32m   1087\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ov \u001B[38;5;129;01min\u001B[39;00m ov_list:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:1016\u001B[0m, in \u001B[0;36m_exhaustive_wait\u001B[1;34m(handles, timeout)\u001B[0m\n\u001B[0;32m   1014\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m L:\n\u001B[1;32m-> 1016\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_winapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mWaitForMultipleObjects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1017\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m WAIT_TIMEOUT:\n\u001B[0;32m   1018\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "    \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 0.001\n",
    "HIDDEN_UNITS = 10\n",
    "INPUT_SHAPE = 3\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "data_path = Path('data')\n",
    "image_path = data_path/'pizza_steak_sushi'\n",
    "\n",
    "train_dir = image_path/'train'\n",
    "test_dir = image_path/'test'\n",
    "\n",
    "model_path = parent_dir/Path('models')\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_list = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=data_transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "\n",
    "model_0 = model_builder.TinyVGG(input_shape=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, output_shape=len(class_list))\n",
    "model_0.to(device)\n",
    "\n",
    "print(f\"Using {device} For Training\")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_0.parameters(), lr=LR)\n",
    "\n",
    "results = train(\n",
    "    model=model_0,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device = device,\n",
    "    epochs = EPOCHS\n",
    ")\n",
    "\n",
    "save_model(\n",
    "    model=model_0,\n",
    "    target_dir=model_path,\n",
    "    model_name='TinyVGG'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed87738-e657-49fd-a72b-72ba707d7611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
