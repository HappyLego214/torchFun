{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9bc26e-638a-44a6-a097-c48ba7be7e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under input (6).txt\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://raw.githubusercontent.com/karpathy/ng-video-lecture/master/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b616136-d9f0-46c7-97a7-64c69d3b63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5043f76-8511-4840-ae3b-b14f4342711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset in Characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Dataset in Characters: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5804377-2af4-4dde-9a14-1e4becb55b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64cdb0c2-97ac-4659-af5b-52fa09527355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Number of Charactes: 65\n"
     ]
    }
   ],
   "source": [
    "# set takes all the characters from text -> it is made into a list -> and sorted\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(''.join(chars))\n",
    "print(f'Number of Charactes: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791bd6c0-3336-4a09-bca9-ab54b747b8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "test = enumerate(chars)\n",
    "print(dict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d198c27-38af-4b6f-975d-649df6459476",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = dict(enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d977963f-ace6-4e97-a8c9-5ddc6d4d02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e3aed51-0d56-4a9d-9550-fd45668a3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065c0ab4-f667-4c7e-9bd7-498942c2e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decoder = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d362eebf-d511-4670-852c-319884aa9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(s):\n",
    "    return [stoi[c] for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2181f6f-9138-467b-a520-f74ae321a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(l):\n",
    "    return ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6acb53a0-df13-4007-8312-81e91d338f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 47, 1, 32, 46, 43, 56, 43, 2]\n",
      "Hi There!\n"
     ]
    }
   ],
   "source": [
    "print(encode('Hi There!'))\n",
    "print(decoder(encoder('Hi There!')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777a6f87-619d-4ae3-9ef1-e441026f99eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d917acd1-64ce-434d-8ef3-d12c0366b7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3827e482-59ed-4e1f-addc-d798813b1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(data))\n",
    "train_data = data[:split]\n",
    "valid_data = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c270a869-d774-453d-994a-939602c155f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892315\n",
      "223079\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2588168a-fb66-489a-9b89-0b7cd25af09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter - block size\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d7f4816-5c8e-46f4-a47f-3fd8ed6b4095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whenever input is tensor([18]) -- target is 47\n",
      "Whenever input is tensor([18, 47]) -- target is 56\n",
      "Whenever input is tensor([18, 47, 56]) -- target is 57\n",
      "Whenever input is tensor([18, 47, 56, 57]) -- target is 58\n",
      "Whenever input is tensor([18, 47, 56, 57, 58]) -- target is 1\n",
      "Whenever input is tensor([18, 47, 56, 57, 58,  1]) -- target is 15\n",
      "Whenever input is tensor([18, 47, 56, 57, 58,  1, 15]) -- target is 47\n",
      "Whenever input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) -- target is 58\n",
      "\n",
      "X Data: tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "Y Data: tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"Whenever input is {context} -- target is {target}\")\n",
    "\n",
    "print(f\"\\nX Data: {x}\")\n",
    "print(f\"Y Data: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e6f05-960d-404b-b901-4e2b5c508b2e",
   "metadata": {},
   "source": [
    "What we're essentially going for in this section is that we want to always get the targets. What we're doing is always shifting right for the target because that is what we want to predict. So the target is always one step ahead. That is why we have *1:block_size*. When it comes to +1, it's that we also need the target for the last token in the sequence. So we have to grab the next token from the next sequence. \n",
    "\n",
    "So for block_size, the last +1 means that we have a target for the last token in the sequence. BUT we don't use the +1 as input context. The +1 is used as a target ONLY. See how the X and Y data have the same length but Y is shifted to the right at one position. So the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dda5c52-52da-411d-b0bc-d5e8381d34f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc03572-ccc7-4cfe-ae76-7153b0558ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # How many sequences in one batch \n",
    "block_size = 8 # Maximum length of a sequence\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if \"train\" else valid_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    xb = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    yb = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a88aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1078327,  453969,   41646,  671252])\n"
     ]
    }
   ],
   "source": [
    "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4fa614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[59, 52, 49, 47, 52, 42,  1, 40],\n",
      "        [53, 54, 43, 44, 59, 50,  1, 50],\n",
      "        [27, 24, 33, 25, 26, 21, 13, 10],\n",
      "        [47, 41, 43,  1, 53, 60, 43, 56]])\n"
     ]
    }
   ],
   "source": [
    "xb = torch.stack([data[i:i+block_size] for i in ix])\n",
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ed65c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52, 49, 47, 52, 42,  1, 40, 56],\n",
      "        [54, 43, 44, 59, 50,  1, 50, 39],\n",
      "        [24, 33, 25, 26, 21, 13, 10,  0],\n",
      "        [41, 43,  1, 53, 60, 43, 56, 58]])\n"
     ]
    }
   ],
   "source": [
    "yb = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f546e8-ff6d-419a-b682-38e801d15efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 56, 63,  1, 47, 52,  1, 46],\n",
      "        [44, 47, 45, 46, 58,  1, 40, 43],\n",
      "        [58, 46, 43, 56,  8,  0,  0, 24],\n",
      "        [ 6,  0, 21,  1, 52, 43, 60, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[56, 63,  1, 47, 52,  1, 46, 47],\n",
      "        [47, 45, 46, 58,  1, 40, 43,  1],\n",
      "        [46, 43, 56,  8,  0,  0, 24, 17],\n",
      "        [ 0, 21,  1, 52, 43, 60, 43, 56]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print(f'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f47c78ba-0e0f-47b0-bd9f-6366b71853e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43, 56, 63,  1, 47, 52,  1, 46],\n",
       "        [44, 47, 45, 46, 58,  1, 40, 43],\n",
       "        [58, 46, 43, 56,  8,  0,  0, 24],\n",
       "        [ 6,  0, 21,  1, 52, 43, 60, 43]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f0bca2f-c7cd-47cc-8622-f49527b605df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [43] -> Target: 56\n",
      "Context: [43, 56] -> Target: 63\n",
      "Context: [43, 56, 63] -> Target: 1\n",
      "Context: [43, 56, 63, 1] -> Target: 47\n",
      "Context: [43, 56, 63, 1, 47] -> Target: 52\n",
      "Context: [43, 56, 63, 1, 47, 52] -> Target: 1\n",
      "Context: [43, 56, 63, 1, 47, 52, 1] -> Target: 46\n",
      "Context: [43, 56, 63, 1, 47, 52, 1, 46] -> Target: 47\n",
      "Context: [44] -> Target: 47\n",
      "Context: [44, 47] -> Target: 45\n",
      "Context: [44, 47, 45] -> Target: 46\n",
      "Context: [44, 47, 45, 46] -> Target: 58\n",
      "Context: [44, 47, 45, 46, 58] -> Target: 1\n",
      "Context: [44, 47, 45, 46, 58, 1] -> Target: 40\n",
      "Context: [44, 47, 45, 46, 58, 1, 40] -> Target: 43\n",
      "Context: [44, 47, 45, 46, 58, 1, 40, 43] -> Target: 1\n",
      "Context: [58] -> Target: 46\n",
      "Context: [58, 46] -> Target: 43\n",
      "Context: [58, 46, 43] -> Target: 56\n",
      "Context: [58, 46, 43, 56] -> Target: 8\n",
      "Context: [58, 46, 43, 56, 8] -> Target: 0\n",
      "Context: [58, 46, 43, 56, 8, 0] -> Target: 0\n",
      "Context: [58, 46, 43, 56, 8, 0, 0] -> Target: 24\n",
      "Context: [58, 46, 43, 56, 8, 0, 0, 24] -> Target: 17\n",
      "Context: [6] -> Target: 0\n",
      "Context: [6, 0] -> Target: 21\n",
      "Context: [6, 0, 21] -> Target: 1\n",
      "Context: [6, 0, 21, 1] -> Target: 52\n",
      "Context: [6, 0, 21, 1, 52] -> Target: 43\n",
      "Context: [6, 0, 21, 1, 52, 43] -> Target: 60\n",
      "Context: [6, 0, 21, 1, 52, 43, 60] -> Target: 43\n",
      "Context: [6, 0, 21, 1, 52, 43, 60, 43] -> Target: 56\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"Context: {context.tolist()} -> Target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295e75e2-f095-4fd3-bf22-bfde5aba14fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 47, 45, 46, 58, 1, 40, 43]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a8e1cb7-1e99-42e2-8898-75ca07df7ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c3f97d4-3499-49b0-b4fe-c24f9a48402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "I neve\n"
     ]
    }
   ],
   "source": [
    "print(decoder(xb[3].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "496106c8-76be-4590-a5fb-62e2c6c935f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size:int):\n",
    "        super().__init__()\n",
    "        # nn.Embedding requires the actual number of vocab_size (characters being used) for the first argument\n",
    "        # second argument is a hyperparameter that dictates the length of the embedding vector\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Shape of BTC \n",
    "            logits = self(idx)\n",
    "            # Select last token in sequence to predict next token - transforms to BC. We are currently\n",
    "            # working with the batch of the last token in the sequence's logits. \n",
    "            logits = logits[:,-1]\n",
    "            # We get the probabilities with softmax on the logits\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            # We predict the next token\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # We concatenate the new token to idx - adding to the sequence B,T+1\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "        \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits = model(xb)\n",
    "print(decoder(model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fe3189a-40b5-4325-a082-4d2f461f1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
       "          [-0.6722,  0.2322, -0.1632,  ...,  0.1390,  0.7560,  0.4296],\n",
       "          [-0.8109,  0.2410, -0.1139,  ...,  1.4509,  0.1836,  0.3064],\n",
       "          ...,\n",
       "          [-0.2103,  0.4481,  1.2381,  ...,  1.3597, -0.0821,  0.3909],\n",
       "          [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275],\n",
       "          [ 1.0901,  0.2170, -2.9996,  ..., -0.5472, -0.8017,  0.7761]],\n",
       " \n",
       "         [[ 1.0541,  1.5018, -0.5266,  ...,  1.8574,  1.5249,  1.3035],\n",
       "          [ 1.6515, -0.0424, -0.7355,  ...,  0.8682,  2.0593, -0.8159],\n",
       "          [ 0.6635,  0.2673, -0.0410,  ..., -0.5861, -1.0893,  0.1948],\n",
       "          ...,\n",
       "          [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275],\n",
       "          [ 1.4311,  0.4160, -2.2246,  ...,  0.7330,  0.3551,  0.1472],\n",
       "          [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594]],\n",
       " \n",
       "         [[ 0.2475, -0.6349, -1.2909,  ...,  1.3064, -0.2256, -1.8305],\n",
       "          [ 1.0901,  0.2170, -2.9996,  ..., -0.5472, -0.8017,  0.7761],\n",
       "          [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
       "          ...,\n",
       "          [ 0.1808, -0.0700, -0.3596,  ...,  1.6097, -0.4032, -0.8345],\n",
       "          [ 0.1808, -0.0700, -0.3596,  ...,  1.6097, -0.4032, -0.8345],\n",
       "          [-1.5101, -0.0948,  1.0927,  ..., -0.6126, -0.6597,  0.7624]],\n",
       " \n",
       "         [[ 0.4160,  0.3362, -0.4512,  ..., -1.6525, -0.8816, -1.4546],\n",
       "          [ 0.1808, -0.0700, -0.3596,  ...,  1.6097, -0.4032, -0.8345],\n",
       "          [-2.1910, -0.7574,  1.9656,  ..., -0.3580,  0.8585, -0.6161],\n",
       "          ...,\n",
       "          [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
       "          [-0.1679,  0.5602,  0.6467,  ...,  0.1522,  0.5109,  0.0990],\n",
       "          [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([4, 8, 65]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a0963f1-ff13-42f1-883b-1b4e78c87659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0901,  0.2170, -2.9996,  1.4690, -0.1948, -0.1507,  0.2601, -0.9647,\n",
      "          0.1162, -0.8295, -0.2266,  0.0219, -0.2785, -0.4851, -1.8023, -0.7330,\n",
      "         -1.2828,  0.8863,  1.0515, -0.9823, -1.6369, -1.3499,  0.1830,  0.0532,\n",
      "         -1.1438, -0.2829, -0.5979,  1.4757,  0.4655, -3.0346,  0.5516,  1.3107,\n",
      "          0.1240, -1.8046,  0.2700, -0.4322,  0.2784, -0.5599,  1.2502,  0.7051,\n",
      "         -1.0169,  0.4854, -1.0808, -0.3128, -0.4189, -0.5718,  0.8215,  1.7384,\n",
      "          0.5578,  0.6167,  1.5260, -0.3508, -1.5615,  0.4548, -0.8935,  0.3642,\n",
      "          0.5714,  2.7072, -1.5443,  1.1288, -1.1217, -1.7328, -0.5472, -0.8017,\n",
      "          0.7761],\n",
      "        [ 0.3323, -0.0872, -0.7470, -0.6074,  0.3418,  0.5343,  0.3957, -0.4919,\n",
      "         -0.0894, -1.3886,  1.2835, -0.3975,  2.0152,  1.6773, -0.3833,  1.5728,\n",
      "          1.9458,  0.7247, -0.4834, -0.3263,  0.3193, -0.4198, -0.6435, -0.3311,\n",
      "          0.7554, -1.2385,  0.4067,  0.9982, -0.6511,  1.2450,  0.2804,  0.8371,\n",
      "         -0.4119,  0.2115, -0.6240,  0.0203, -0.3418,  1.4934,  1.7307,  1.3354,\n",
      "         -0.2712,  0.4902,  0.6600, -1.6321, -0.7858,  1.7688,  2.6160, -0.5767,\n",
      "         -0.3628, -2.7428,  0.7428,  0.0737,  0.2050, -0.5497,  2.1261, -0.9240,\n",
      "          0.1048,  0.8324,  1.4287, -0.7789,  2.9275, -0.8525, -0.6716, -0.9572,\n",
      "         -0.9594],\n",
      "        [-1.5101, -0.0948,  1.0927,  0.1505,  1.6347, -0.0518,  0.4996,  0.7216,\n",
      "         -0.8968, -0.4122,  1.0030,  0.8508,  0.2178,  0.0328, -0.1699,  1.0659,\n",
      "         -0.6177,  1.1824,  0.0214, -0.2154, -1.4623,  2.1707,  0.1624,  1.0296,\n",
      "          0.4154,  0.6207,  0.2341, -0.0326,  1.0124,  1.5122, -0.3359,  0.2456,\n",
      "          1.8682,  0.7536, -0.1177, -0.1967, -0.9552, -0.8995, -0.9583, -0.5945,\n",
      "          0.1321, -0.5406,  0.1405, -0.7321,  1.1796,  1.3316, -0.2094,  0.0960,\n",
      "          0.9040, -0.4032,  0.3027, -0.8034, -1.2537, -1.5195,  0.7446,  1.1914,\n",
      "         -0.8061, -0.6290,  1.2447, -2.4400,  0.8408, -0.3993, -0.6126, -0.6597,\n",
      "          0.7624],\n",
      "        [ 0.3323, -0.0872, -0.7470, -0.6074,  0.3418,  0.5343,  0.3957, -0.4919,\n",
      "         -0.0894, -1.3886,  1.2835, -0.3975,  2.0152,  1.6773, -0.3833,  1.5728,\n",
      "          1.9458,  0.7247, -0.4834, -0.3263,  0.3193, -0.4198, -0.6435, -0.3311,\n",
      "          0.7554, -1.2385,  0.4067,  0.9982, -0.6511,  1.2450,  0.2804,  0.8371,\n",
      "         -0.4119,  0.2115, -0.6240,  0.0203, -0.3418,  1.4934,  1.7307,  1.3354,\n",
      "         -0.2712,  0.4902,  0.6600, -1.6321, -0.7858,  1.7688,  2.6160, -0.5767,\n",
      "         -0.3628, -2.7428,  0.7428,  0.0737,  0.2050, -0.5497,  2.1261, -0.9240,\n",
      "          0.1048,  0.8324,  1.4287, -0.7789,  2.9275, -0.8525, -0.6716, -0.9572,\n",
      "         -0.9594]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([4, 65])\n"
     ]
    }
   ],
   "source": [
    "print(logits[:,-1,:])\n",
    "print(logits[:,-1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebdb1c26-9986-4f2d-8585-74116a487c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n",
      "torch.Size([4, 65])\n",
      "torch.Size([4, 65])\n",
      "torch.Size([4, 1])\n",
      "tensor([[22],\n",
      "        [42],\n",
      "        [31],\n",
      "        [ 8]])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 8, 65])\n",
      "torch.Size([4, 65])\n",
      "torch.Size([4, 65])\n",
      "torch.Size([4, 1])\n",
      "tensor([[42],\n",
      "        [ 0],\n",
      "        [54],\n",
      "        [20]])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 9])\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    idx = logits\n",
    "    print(logits.shape)\n",
    "    check = logits[:,-1]\n",
    "    print(check.shape)\n",
    "    probs = F.softmax(check, dim=1)\n",
    "    print(probs.shape)\n",
    "    idx_next = torch.multinomial(probs, num_samples=1)\n",
    "    print(idx_next.shape)\n",
    "    print(idx_next)\n",
    "    print(xb.shape)\n",
    "    idx = torch.cat((xb, idx_next), dim=1)\n",
    "    print(idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06491669-97eb-4be3-88ac-a9b6fa94b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5193, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logits.view(4*8,65), yb.view(4*8))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "482caaec-6361-4e18-985d-2a7b5139bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cea2dc2-db4f-4387-8f6c-178639888cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ab038a5-0f4f-43d5-8ee1-111b53fb989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, train, target, epochs, device, loss_fn, optim):\n",
    "    data.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        logits = model(train)\n",
    "        loss = loss_fn(logits.view(4*8,65), target.view(4*8))\n",
    "        optim.zero_grad\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if epoch % 1000 == 0:\n",
    "            print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6de9d3f9-19c1-4b70-b00b-ea55407f104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4506940841674805\n",
      "1.8645155429840088\n",
      "0.8274747729301453\n"
     ]
    }
   ],
   "source": [
    "train_step(model, xb, yb, 3000, device, loss_fn, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16c2d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 37, 27, 30, 48, 22, 63, 42, 53, 41, 49,  1, 58, 46, 56, 53, 41, 49,\n",
      "          8,  0,  0, 37, 35, 31, 64, 28, 26, 62, 40, 48, 28, 47, 41, 49,  8,  0,\n",
      "         37, 27, 30, 48, 11, 60, 35, 56, 53, 58, 43, 57, 42, 53, 41, 49,  8,  0,\n",
      "         37, 27, 30, 56, 53, 41, 50, 53, 58, 43, 57, 42, 53, 51,  1, 54, 56, 53,\n",
      "         51,  1, 54, 56, 53, 51,  1, 58, 46, 39, 57, 42,  3, 24, 48, 11, 12, 63,\n",
      "         64, 63, 33, 41, 50, 53, 41, 50, 53, 58, 46, 57, 42, 38, 29, 45, 15,  7,\n",
      "         46, 50, 53, 41, 49,  1, 58, 43, 57, 42, 53, 41, 49,  8,  0, 37, 27, 30,\n",
      "         22,  1, 21, 57, 42, 53, 51,  1, 58, 46, 28, 57, 42, 53, 58, 43, 57, 42,\n",
      "         53, 41, 49,  1, 54, 56, 53, 41, 49,  1, 54, 56, 53, 58, 46, 63,  5, 46,\n",
      "         38, 15, 35, 46, 59,  8,  0, 37, 27, 30, 48, 28,  1, 41, 49,  8,  0, 37,\n",
      "         27, 30, 54, 56, 53, 58, 46, 57, 42, 53, 41, 49,  8,  0,  0,  0, 37, 27,\n",
      "         30, 53, 41]])\n",
      "torch.Size([1, 201])\n",
      "tensor([ 0,  0,  0, 37, 27, 30, 48, 42, 53, 51,  1, 61, 39, 57, 42, 53, 51,  1,\n",
      "        61, 39, 57, 42, 53, 51,  1, 61, 39, 57, 42, 53, 58, 43, 57, 42, 53, 58,\n",
      "        43, 57, 42, 53, 51,  1, 54, 56, 53, 51,  1, 54, 56, 53, 41, 49,  1, 41,\n",
      "        49,  8,  0,  0, 37, 27, 30, 31, 28, 21,  1, 41, 50, 53, 41, 50, 53, 41,\n",
      "        50, 53, 51,  1, 41, 49,  8,  0, 37, 27, 30, 58, 43, 57, 42, 22, 11, 39,\n",
      "        57, 42, 41, 49,  1, 54, 56, 53, 41, 49,  8,  0, 37, 27, 30, 61, 39, 57,\n",
      "        42, 53, 58, 43, 57, 42, 53, 41, 49,  8, 49,  1, 21,  1, 41, 49,  8,  0,\n",
      "        37, 27, 30, 54, 56, 53, 58, 43, 57, 42, 53, 41, 49,  8,  0, 37, 27, 30,\n",
      "        40, 27, 30, 23, 47, 41, 50, 51,  1, 21,  1, 41, 49,  8,  0, 37, 27, 30,\n",
      "        22, 11, 20, 49,  1, 54, 56, 53, 58, 43, 57, 42, 53, 58, 46, 50, 53, 51,\n",
      "         1, 41, 49,  8,  0,  0, 37, 27, 30, 22, 59, 20,  7, 23, 22, 18, 40, 48,\n",
      "        62, 55,  7])\n",
      "torch.Size([201])\n",
      "[0, 37, 27, 30, 48, 8, 0, 37, 27, 30, 15, 22, 46, 9, 6, 27, 30, 48, 23, 20, 44, 26, 23, 20, 11, 17, 39, 57, 15, 25, 51, 1, 21, 1, 41, 50, 53, 41, 49, 1, 61, 39, 57, 42, 36, 26, 43, 57, 42, 53, 41, 49, 8, 0, 0, 0, 37, 27, 30, 51, 1, 61, 39, 57, 42, 53, 51, 1, 41, 49, 1, 61, 39, 57, 42, 53, 41, 49, 1, 58, 46, 31, 13, 20, 56, 53, 41, 49, 8, 0, 37, 27, 30, 54, 56, 53, 41, 50, 53, 41, 50, 53, 41, 49, 1, 58, 46, 64, 24, 60, 47, 57, 42, 53, 41, 50, 53, 58, 46, 59, 48, 24, 2, 55, 54, 56, 53, 41, 50, 53, 51, 1, 41, 49, 8, 0, 0, 37, 27, 30, 46, 56, 21, 1, 61, 39, 57, 42, 53, 41, 49, 8, 0, 37, 27, 30, 48, 18, 11, 11, 53, 51, 1, 21, 1, 21, 1, 21, 1, 41, 49, 8, 0, 0, 37, 27, 30, 48, 59, 29, 53, 41, 49, 8, 0, 0, 37, 27, 30, 35, 12, 37, 27, 30, 54, 56, 55, 20, 62, 56, 53]\n"
     ]
    }
   ],
   "source": [
    "print((model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=200)))\n",
    "print((model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=200)).shape)\n",
    "print((model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=200)[0]))\n",
    "print((model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=200)[0]).shape)\n",
    "print((model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "221ba835-cbfd-4ded-a9b2-429c7d8ae3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YORrock protesdom I I I ck.\n",
      "YORV;JYORCb;hRj,F'zI prothuKth$?,Sesdock I I ck tesdom proclotesdom proclock.\n",
      "\n",
      "YORjQFJg ck.\n",
      "YORvck.\n",
      "\n",
      "YORV$Sqcloclock prom wasdock proclotesdothR,FqprothSwasdotesdothsdocloc\n"
     ]
    }
   ],
   "source": [
    "print(decoder(model.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "324e6fed-1884-41a2-a240-51340b7303e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05d635b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 5, 'test': 5}\n"
     ]
    }
   ],
   "source": [
    "batch_loss = {}\n",
    "for split in ['train', 'test']:\n",
    "    batch_loss[split] = 5\n",
    "\n",
    "print(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00bcb597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9fc110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.1808, -0.0700]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931],\n",
      "        [ 1.4870,  0.5910]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931],\n",
      "        [ 1.4870,  0.5910],\n",
      "        [ 0.1260, -1.5627]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931],\n",
      "        [ 1.4870,  0.5910],\n",
      "        [ 0.1260, -1.5627],\n",
      "        [-1.1601, -0.3348]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931],\n",
      "        [ 1.4870,  0.5910],\n",
      "        [ 0.1260, -1.5627],\n",
      "        [-1.1601, -0.3348],\n",
      "        [ 0.4478, -0.8016]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.2858,  0.9651],\n",
      "        [-2.0371,  0.4931],\n",
      "        [ 1.4870,  0.5910],\n",
      "        [ 0.1260, -1.5627],\n",
      "        [-1.1601, -0.3348],\n",
      "        [ 0.4478, -0.8016],\n",
      "        [ 1.5236,  2.5086]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215],\n",
      "        [ 0.1584,  1.1340]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215],\n",
      "        [ 0.1584,  1.1340],\n",
      "        [-1.1539, -0.2984]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215],\n",
      "        [ 0.1584,  1.1340],\n",
      "        [-1.1539, -0.2984],\n",
      "        [-0.5075, -0.9239]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215],\n",
      "        [ 0.1584,  1.1340],\n",
      "        [-1.1539, -0.2984],\n",
      "        [-0.5075, -0.9239],\n",
      "        [ 0.5467, -1.4948]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215],\n",
      "        [ 0.1584,  1.1340],\n",
      "        [-1.1539, -0.2984],\n",
      "        [-0.5075, -0.9239],\n",
      "        [ 0.5467, -1.4948],\n",
      "        [-1.2057,  0.5718]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[-0.6631, -0.2513],\n",
      "        [ 1.0101,  0.1215],\n",
      "        [ 0.1584,  1.1340],\n",
      "        [-1.1539, -0.2984],\n",
      "        [-0.5075, -0.9239],\n",
      "        [ 0.5467, -1.4948],\n",
      "        [-1.2057,  0.5718],\n",
      "        [-0.5974, -0.6937]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759],\n",
      "        [-1.5108,  2.1048]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759],\n",
      "        [-1.5108,  2.1048],\n",
      "        [ 2.7630, -1.7465]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759],\n",
      "        [-1.5108,  2.1048],\n",
      "        [ 2.7630, -1.7465],\n",
      "        [ 1.4516, -1.5103]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759],\n",
      "        [-1.5108,  2.1048],\n",
      "        [ 2.7630, -1.7465],\n",
      "        [ 1.4516, -1.5103],\n",
      "        [ 0.8212, -0.2115]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759],\n",
      "        [-1.5108,  2.1048],\n",
      "        [ 2.7630, -1.7465],\n",
      "        [ 1.4516, -1.5103],\n",
      "        [ 0.8212, -0.2115],\n",
      "        [ 0.7789,  1.5333]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n",
      "\n",
      "tensor([[ 1.6455, -0.8030],\n",
      "        [ 1.3514, -0.2759],\n",
      "        [-1.5108,  2.1048],\n",
      "        [ 2.7630, -1.7465],\n",
      "        [ 1.4516, -1.5103],\n",
      "        [ 0.8212, -0.2115],\n",
      "        [ 0.7789,  1.5333],\n",
      "        [ 1.6097, -0.4032]])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        print(f\"\\n{xprev}\")\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "        print(xbow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b2091d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0b428b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73d8a5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1113003e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0894"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "data1 = [0.1808, -0.3596]\n",
    "check = statistics.mean(data1)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e745707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones((3,3)))\n",
    "print(a.shape)\n",
    "print(a)\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "377a2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETER EXPLANATIONS FOR torch.sum()\n",
    "\n",
    "# If we change the dimension to 0 - then the operations will be conducted column-wise\n",
    "# as compared to 1 - which makes the operations happen row-wise\n",
    "\n",
    "# If keepdim=False, broadcasting occurs, which turns the operation into:\n",
    "\n",
    "# tensor([[1.0000 / 1., 0.0000 / 2., 0.0000 / 3.],\n",
    "#         [1.0000 / 1., 1.0000 / 2., 0.0000 / 3.],\n",
    "#         [1.0000 / 1., 1.0000 / 2., 1.0000 / 3.]])\n",
    "\n",
    "# Output:\n",
    "\n",
    "# tensor([[1.0000, 0.0000, 0.0000],\n",
    "#         [1.0000, 0.5000, 0.0000],\n",
    "#         [1.0000, 0.5000, 0.3333]])\n",
    "\n",
    "# If keepdim=True, broadcasting doesn't occur, which turns the operation into:\n",
    "\n",
    "# tensor([[1.0000 / 1., 0.0000 / 1., 0.0000 / 1.],\n",
    "#         [1.0000 / 2., 1.0000 / 2., 0.0000 / 2.],\n",
    "#         [1.0000 / 3., 1.0000 / 3., 1.0000 / 3.]])\n",
    "\n",
    "# Output:\n",
    "\n",
    "# tensor([[1.0000, 0.0000, 0.0000],\n",
    "#         [0.5000, 0.5000, 0.0000],\n",
    "#         [0.3333, 0.3333, 0.3333]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fee01a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([4, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tril(torch.ones((T,T)))\n",
    "weights = weights / torch.sum(weights, 1, keepdim=True)\n",
    "print(weights.shape)\n",
    "# PyTorch broadcasting aligns dimensions from right to left.\n",
    "# The original shape of weights is (T, T), which does not match with (B, T, C).\n",
    "# PyTorch aligns the rightmost dimensions first, so (T, T) is paired with (T, C).\n",
    "# Since B does not have a pair, PyTorch adds a dimension to the leftmost position of (T, T),\n",
    "# resulting in (B, T, T).\n",
    "xbow2 = weights @ x  # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "print(xbow.shape)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b269d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70233b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0bbea54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Single Head performing self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B,T,16)\n",
    "q = query(x) # (B,T,16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) = (B, T, T)\n",
    "# wei = q @ k.transpose(-2, -1) / head_size**0.5\n",
    "# The above code scales the dot product of q and k by the inverse of the square root of the head size.\n",
    "# This scaling prevents the softmax function from producing extremely large values,\n",
    "# which would cause it to assign very high attention to a few tokens and very low attention to others.\n",
    "# By scaling, we ensure a more balanced distribution of attention across tokens.\n",
    "\n",
    "tril = torch.tril(torch.ones((T,T)))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x) # (B,T,16)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05386bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86100d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5014, 0.4986, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1014, 0.7953, 0.1034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0268, 0.2879, 0.4719, 0.2135, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5155, 0.0233, 0.0411, 0.0320, 0.3882, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0448, 0.0413, 0.0044, 0.0041, 0.6730, 0.2324, 0.0000, 0.0000],\n",
       "         [0.0059, 0.1334, 0.7885, 0.0345, 0.0116, 0.0086, 0.0175, 0.0000],\n",
       "         [0.0774, 0.0630, 0.1206, 0.0612, 0.1398, 0.3568, 0.0496, 0.1316]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4486, 0.5514, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.9896, 0.0085, 0.0019, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0567, 0.4144, 0.2391, 0.2898, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0240, 0.0510, 0.8162, 0.0149, 0.0940, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0542, 0.1287, 0.5672, 0.0385, 0.1057, 0.1057, 0.0000, 0.0000],\n",
       "         [0.2496, 0.1338, 0.1246, 0.2827, 0.0813, 0.0988, 0.0291, 0.0000],\n",
       "         [0.3130, 0.0474, 0.0361, 0.0725, 0.0596, 0.0249, 0.1010, 0.3454]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8685, 0.1315, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6806, 0.2562, 0.0632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0105, 0.4641, 0.3835, 0.1419, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3094, 0.0757, 0.3250, 0.2218, 0.0681, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2085, 0.0848, 0.4048, 0.1232, 0.1746, 0.0041, 0.0000, 0.0000],\n",
       "         [0.3557, 0.0528, 0.0520, 0.1789, 0.0444, 0.0140, 0.3023, 0.0000],\n",
       "         [0.3366, 0.0621, 0.1419, 0.0405, 0.1984, 0.0642, 0.1403, 0.0161]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1252, 0.8748, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1299, 0.7200, 0.1501, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0112, 0.3151, 0.5077, 0.1660, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1873, 0.0621, 0.6107, 0.1028, 0.0371, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1636, 0.3283, 0.0624, 0.4169, 0.0119, 0.0168, 0.0000, 0.0000],\n",
       "         [0.2097, 0.0167, 0.0137, 0.0530, 0.0532, 0.3837, 0.2700, 0.0000],\n",
       "         [0.0438, 0.2168, 0.3321, 0.0926, 0.0046, 0.0966, 0.1867, 0.0269]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a38e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528df2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18580fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
