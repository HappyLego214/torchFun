{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6a1d29-daf8-46a2-b988-38b7bd963086",
   "metadata": {},
   "source": [
    "**Overview of Section**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a4a29-92d9-42d0-a727-6418481fb421",
   "metadata": {},
   "source": [
    "This section will explore what *torch.nn* does in function when creating neural networks. First, this section will create a neural network from scratch. We will be using the MNIST_Dataset to train the model on without using any of the utilities of *torch.nn*, *torch.optim*, *Dataset*, and *DataLoader*. Afterwards, we will gradually refactor the code to include per module. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88596e3-a777-4cd2-b9f5-d61b00566491",
   "metadata": {},
   "source": [
    "**MNIST Data Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745b70bd-dce2-49ca-8e35-7dd42bf15ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de728c9-4acc-4645-a413-6556b9e2dd14",
   "metadata": {},
   "source": [
    "Here we are utilizing *pathlib* to create a directory for our MNIST dataset that we will download using *requests*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4454b96-75aa-4da9-80b9-3e4acf554ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH/FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bf77b-7d00-4972-bcf8-7df3adde02b6",
   "metadata": {},
   "source": [
    "The dataset is in a numpy array format, not a tensor, and is stored using pickle, a python-specific format for serializing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cca9e2-0283-4f04-acbc-73082521f9c9",
   "metadata": {},
   "source": [
    "Since we're dealing with images, we have pixel values in the shape of 28x28. This is currently being stored as a flattened row of length 784 (28x28). Let's put this back into it's proper dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f3625f-f70e-4965-b9fd-14e065329652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf968320-8962-481f-ad7c-2df3965c8864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), <function ndarray.reshape>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_train[0].reshape((28,28))\n",
    "x_train[0].shape, x_train.reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81700a6-4845-42ca-9fb3-397104aa4791",
   "metadata": {},
   "source": [
    "Remember that we are working with NumPy arrays and not PyTorch tensors. There is a similiar function for reshape on both PyTorch & NumPy. So, if we try to use *.view()* which is a PyTorch exclusive function, it wouldn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457006fc-54c8-4bd7-a197-42dedae704b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x216d3ab0dc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(z, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5e99da-d74f-4010-a802-87a8116e8298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b9c07-eedc-406d-8090-9b61bc88db3a",
   "metadata": {},
   "source": [
    "As we can see, we have 50000 images with 784 pixel cells. Each row is an image while each column is the corresponding pixel values for that specific image in that row. Now, we need to convert these to *torch.tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d5ec2a-8dd2-46e4-989c-26756b56cdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd8bab-d70c-49f1-9722-6140e4eeff7b",
   "metadata": {},
   "source": [
    "**Neural Network From Scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee99dfc-e89a-4458-bf9e-bed39ac80a98",
   "metadata": {},
   "source": [
    "We'll be creating a model with nothin but PyTorch tensor operations. We will be utilizing PyTorch's methods to create random or zero-filled tensors which we will be using to create the weights and bias for a simple linear model. Same thing as before, we'll also be telling PyTorch to require teh gradients for these so that it can track all the operations done on the tensor. This is so that we can do backpropagation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3353a87-ba81-429a-a4d3-b9f8d24d3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Utilizing Xavier initialisation\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af06938-d0b3-4625-9be8-e9998bd42e3f",
   "metadata": {},
   "source": [
    "What's Xavier initialisation? This is so that the random values generated by *torch.randn* aren't too far apart. Having values that are too high or too low can cause issues with the gradients so we do Xavier initialisation so that all the values are within a certain range of distribution. Basically, we have 784 neurons. We get the square root of 784 which is then used as a part of the scaling factor for all the values that is generated by randn for the weights. This is for normal distribution which we have. If we have a uniformed distribution then we would also use the out_features (10). But in this case that's not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004b17c-cb20-41ae-86e0-010493b90cd1",
   "metadata": {},
   "source": [
    "Since PyTorch can automatically calculate gradients, we can use any standard Python funcion as model. Here, let's write a standard plain matrix multiplicaton and broadcasted addition to create a simple linear model. We'll also need an activation function so log_softmax is what we'll be using. \n",
    "\n",
    "It's important to remember that while PyTorch provies a lot of prewritten loss and activtion functions, it is relatively easy for you to make your own custom functions as well using play Python. PyTorch will even create fast GPU or vectorized CPU code to make it run automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f24d272-858f-4604-ad3a-e40fefc6544f",
   "metadata": {},
   "source": [
    "**NOTE:** *requires_grad_()* and *requires_grad=True* both apply the tracking of gradients for the tensors that they are assigned on. It just so that these two are applied differently. *requires_gad_()* is done on existing tensors while *requires_grad=True* is done on tensors that are being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafc4717-fa30-4c9e-a214-d2f8cfc1e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2055a8-32fc-4868-b3fa-f240e61593a6",
   "metadata": {},
   "source": [
    "We specify log_softmax because that is an activation function that we will use for this model. Compared to before, in the Workflow chapter. We only used a (one) linear layer without any additions whatsoever. Here, we've added an activation function similiar to ReLU (similiar in the sense that they are both activation functions). In this case, it's a log_softmax function because that does well when dealing with classificaiton tasks.\n",
    "\n",
    "log_softmax outputs a set of probabilities, and since we're dealing with the MNIST_Dataset and we want to identify which number is an input from 0-9 then this activtion function is exactly what we need. So basically. \n",
    "\n",
    "Linear Layer (xb @ weights + bias) + Activation Function (log_softmax). That's the composition of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88c74bd-804c-4bce-adec-0e9e5b35fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7112, -2.7378, -1.8954, -2.6570, -2.3752, -2.6286, -1.4846, -2.1246,\n",
      "        -2.4539, -2.9718], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64 # batchsize\n",
    "xb = x_train[0:bs]\n",
    "\n",
    "preds = model(xb)\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b820081-0566-4491-ad1e-33988525ee79",
   "metadata": {},
   "source": [
    "As seen here, we have PyTorch actively tracking the preds tensor. Since we already have our data and model, let's start working on a loss function. Here we are using a custom function that will calculate the negative log-likelihood. It's a bit of a mouthful but the most important part is that this is a good loss function to work alongside our activation function earlier.\n",
    "\n",
    "We split our training data into different batches, in this case we specify the first 64 items in the x_train dataset.\n",
    "\n",
    "**FOR SEMI-DEEP EXPLANATION**\n",
    "\n",
    "Remember that *log_softmax* outputs the logarithm of the probabilities for each class. If we apply *torch.exp()* to the outputs of *log_softmax*, we would get the original probabilities, similar to if we used *softmax* alone. These probabilities can then be converted to percentages to see the model’s confidence in each class. However, right now, we need to measure how wrong our model is, so we use a loss function, which is the *negative log-likelihood* or *nll*.\n",
    "\n",
    "The most important thing to understand is that logarithms are often used for classification tasks, and since we’re dealing with logarithms, we also need a loss function that can handle these logarithms effectively. That’s why the negative log-likelihood is important—it works directly with the log probabilities output by log_softmax.\n",
    "\n",
    "**NOTES:**\n",
    "\n",
    "1. The log probabilities we are dealing with are negative because they are the logarithms of probabilities, which are numbers between 0 and 1\n",
    "2. Logarithms are closely related to limits, especially in the context of calculus and continuous functions.\n",
    "3. ‘Negating’ in the context of nll means we are multiplying the log probabilities by -1 as part of the loss calculation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee92132-252e-4f68-ad82-2832af1bd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5240847-f9e6-4585-9921-cd8b8960003b",
   "metadata": {},
   "source": [
    "Let's take a look at our loss with the model that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a89b1e1-d6fe-4d9c-9516-2891373b77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3520, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11327efe-df21-4c59-8178-7e267b5fae08",
   "metadata": {},
   "source": [
    "Now that we have our loss function working, let's make a metric for our consumption. We'll create an accuracy metric. The idea to it is pretty simple. If the index with the largest value matches the target value then the prediction will be correct. Quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f028e05a-93ec-49ea-b02c-20fea25ac70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    print(preds, len(preds))\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4d90e2d-4b7e-4331-a1cb-2550ad47ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7112, -2.7378, -1.8954, -2.6570, -2.3752, -2.6286, -1.4846, -2.1246,\n",
      "         -2.4539, -2.9718],\n",
      "        [-2.2197, -2.6761, -1.9929, -2.4357, -2.3288, -2.3183, -2.1476, -2.2911,\n",
      "         -2.1293, -2.7180],\n",
      "        [-2.6285, -2.4103, -2.1426, -2.3008, -2.3682, -2.7826, -2.0514, -2.1441,\n",
      "         -2.2558, -2.1676],\n",
      "        [-2.9503, -1.9193, -2.2708, -2.7580, -2.1254, -2.3067, -2.1526, -2.1568,\n",
      "         -2.3539, -2.4251],\n",
      "        [-2.3206, -2.4929, -2.2476, -2.9235, -2.1399, -2.0861, -1.8444, -2.1730,\n",
      "         -2.6552, -2.5818],\n",
      "        [-2.7248, -2.7524, -2.1689, -2.1841, -1.9512, -2.7911, -2.0443, -1.9879,\n",
      "         -2.5265, -2.3652],\n",
      "        [-2.4811, -2.1808, -2.1614, -2.5694, -2.3582, -2.5216, -2.0638, -1.8729,\n",
      "         -2.8267, -2.3343],\n",
      "        [-3.1200, -2.4704, -2.1815, -2.5682, -2.3615, -2.8568, -1.4417, -2.1134,\n",
      "         -2.4166, -2.4835],\n",
      "        [-2.6771, -2.0576, -2.0430, -2.4903, -2.2008, -2.5053, -2.2398, -2.1299,\n",
      "         -2.5779, -2.3297],\n",
      "        [-2.5851, -2.5956, -2.3731, -2.4436, -2.2492, -2.4903, -2.0828, -2.2494,\n",
      "         -1.9650, -2.1947],\n",
      "        [-2.7818, -2.3636, -2.1538, -2.6965, -2.2408, -2.5484, -1.5721, -2.0492,\n",
      "         -2.8061, -2.5378],\n",
      "        [-2.2279, -2.0063, -2.4703, -2.5262, -2.4689, -2.4735, -2.5189, -2.1474,\n",
      "         -2.2586, -2.1002],\n",
      "        [-3.2408, -2.1196, -2.4883, -2.6196, -1.9751, -2.9092, -1.7523, -1.5310,\n",
      "         -3.3165, -2.7231],\n",
      "        [-2.8192, -2.2039, -1.8650, -2.2157, -2.2469, -2.4914, -2.2178, -2.7058,\n",
      "         -2.3811, -2.2130],\n",
      "        [-2.4487, -2.1992, -1.9582, -2.5393, -2.1525, -2.8467, -2.1466, -2.1168,\n",
      "         -2.6062, -2.3296],\n",
      "        [-2.5690, -2.9363, -2.2468, -2.6276, -2.3839, -2.0542, -1.7680, -2.2687,\n",
      "         -2.2329, -2.4012],\n",
      "        [-2.5775, -2.5937, -1.8074, -2.4297, -2.3497, -2.2609, -2.0879, -2.1371,\n",
      "         -2.6669, -2.4526],\n",
      "        [-2.7542, -2.3930, -1.9071, -2.9036, -2.0778, -2.3649, -2.1265, -2.0457,\n",
      "         -2.2600, -2.6654],\n",
      "        [-2.6769, -2.5936, -2.1109, -2.2315, -1.9539, -2.2797, -2.2192, -2.3167,\n",
      "         -2.5243, -2.3379],\n",
      "        [-2.7018, -2.5257, -2.2641, -2.5210, -2.2887, -2.3142, -2.1813, -2.1442,\n",
      "         -2.0729, -2.1848],\n",
      "        [-2.9997, -2.3315, -2.3497, -2.4823, -1.8695, -2.7499, -1.8309, -1.9964,\n",
      "         -2.5803, -2.4753],\n",
      "        [-2.3504, -2.5456, -2.1466, -2.4392, -2.3854, -2.1814, -2.0480, -2.1767,\n",
      "         -2.3150, -2.5766],\n",
      "        [-2.4507, -2.7634, -2.3538, -2.6134, -2.2912, -2.3190, -2.1091, -2.0851,\n",
      "         -2.1884, -2.0783],\n",
      "        [-2.9751, -1.8400, -2.2757, -2.7491, -2.1064, -2.4002, -2.1328, -2.2064,\n",
      "         -2.4645, -2.3289],\n",
      "        [-2.3725, -2.7515, -2.4087, -2.2699, -2.1275, -2.0492, -1.9823, -2.2969,\n",
      "         -2.6766, -2.3583],\n",
      "        [-3.1271, -2.2205, -2.2026, -2.8298, -1.6376, -3.0359, -2.2450, -1.7026,\n",
      "         -3.0064, -2.3230],\n",
      "        [-2.4232, -2.1329, -2.3481, -2.6488, -2.0088, -2.0991, -1.8160, -2.5347,\n",
      "         -2.8116, -2.6913],\n",
      "        [-3.4707, -2.3184, -1.9728, -2.8813, -2.5246, -3.3469, -1.3191, -1.8170,\n",
      "         -2.5849, -2.9047],\n",
      "        [-2.9410, -3.0485, -1.8146, -2.3498, -2.4931, -2.6969, -1.6768, -1.8980,\n",
      "         -2.7821, -2.3791],\n",
      "        [-2.5251, -2.3522, -2.3888, -2.3316, -2.2595, -2.2709, -2.2295, -2.2121,\n",
      "         -2.4957, -2.0496],\n",
      "        [-2.5542, -1.9902, -2.1417, -2.1506, -2.3623, -2.8224, -1.6164, -2.3048,\n",
      "         -3.0379, -2.9622],\n",
      "        [-3.0661, -2.2634, -2.0452, -2.8354, -1.7206, -2.9031, -2.5238, -2.2413,\n",
      "         -2.1825, -2.0534],\n",
      "        [-2.5186, -2.5986, -2.3468, -2.4361, -2.3325, -2.0111, -2.0124, -2.1273,\n",
      "         -2.3804, -2.4575],\n",
      "        [-2.8120, -2.5142, -2.1604, -2.3934, -2.2065, -2.2890, -2.1103, -2.1605,\n",
      "         -2.1636, -2.4128],\n",
      "        [-3.2707, -2.5408, -1.9505, -2.1827, -2.2095, -2.5198, -1.9403, -2.1058,\n",
      "         -2.7500, -2.2190],\n",
      "        [-2.3854, -2.1967, -2.4051, -2.4153, -2.5104, -2.3990, -2.1899, -2.0890,\n",
      "         -2.2030, -2.3133],\n",
      "        [-2.4955, -2.7544, -2.1235, -2.2283, -2.2163, -2.3500, -2.0518, -1.8578,\n",
      "         -2.6457, -2.7075],\n",
      "        [-2.8541, -2.2167, -1.9206, -2.1647, -2.1266, -2.5178, -2.3663, -2.2477,\n",
      "         -2.5242, -2.3790],\n",
      "        [-2.2453, -2.4150, -2.1329, -2.6930, -2.0920, -2.1956, -1.8495, -2.1869,\n",
      "         -2.7561, -2.9813],\n",
      "        [-2.7786, -2.9882, -2.0828, -2.3815, -2.1818, -2.2570, -1.8019, -2.3249,\n",
      "         -2.6992, -2.0957],\n",
      "        [-2.6415, -2.1295, -1.9347, -2.6007, -2.0361, -2.6453, -1.9986, -2.3172,\n",
      "         -2.6433, -2.4718],\n",
      "        [-2.6918, -2.5994, -2.0743, -2.7212, -2.0204, -2.0974, -1.8992, -2.1055,\n",
      "         -2.7357, -2.5931],\n",
      "        [-2.3175, -2.3009, -2.2694, -2.6446, -1.9487, -1.9946, -1.9979, -2.4074,\n",
      "         -2.7731, -2.8095],\n",
      "        [-2.5406, -2.8005, -2.3970, -2.5119, -2.1222, -2.2578, -1.8751, -2.0467,\n",
      "         -2.3853, -2.4147],\n",
      "        [-2.4575, -2.2665, -2.3740, -2.4756, -2.2536, -2.6497, -1.6988, -1.8600,\n",
      "         -2.7492, -2.8968],\n",
      "        [-2.5511, -2.4520, -2.2158, -2.5270, -2.0252, -2.3636, -1.6490, -2.3073,\n",
      "         -2.7721, -2.7097],\n",
      "        [-2.5626, -2.4168, -2.4479, -2.5370, -2.0193, -2.0404, -1.7585, -2.2471,\n",
      "         -2.9387, -2.5980],\n",
      "        [-2.5779, -2.2182, -2.1994, -2.8739, -2.5582, -2.2212, -1.7440, -2.6226,\n",
      "         -2.0068, -2.5241],\n",
      "        [-2.3051, -2.6134, -2.5664, -2.3727, -2.4665, -2.4245, -2.0512, -1.7710,\n",
      "         -2.6805, -2.1520],\n",
      "        [-2.9606, -2.6591, -2.2697, -2.8653, -2.3877, -2.6179, -1.5860, -1.7619,\n",
      "         -2.4367, -2.4170],\n",
      "        [-2.9298, -2.2560, -2.4367, -2.5584, -2.1202, -2.4169, -1.9484, -1.9061,\n",
      "         -2.3028, -2.5692],\n",
      "        [-2.7486, -2.5162, -2.0216, -2.3326, -1.9744, -2.6710, -1.9042, -2.0604,\n",
      "         -2.5732, -2.7322],\n",
      "        [-2.2953, -2.3336, -1.8884, -2.1513, -2.5363, -2.5335, -1.6810, -2.6411,\n",
      "         -2.7164, -2.9460],\n",
      "        [-2.7060, -2.0651, -2.4647, -2.7727, -2.1603, -2.3505, -2.0903, -2.1864,\n",
      "         -2.1108, -2.3954],\n",
      "        [-2.4086, -2.2999, -2.1343, -2.1924, -2.1118, -2.6417, -1.8459, -2.4486,\n",
      "         -2.4547, -2.8583],\n",
      "        [-2.8755, -2.2816, -2.1936, -2.5554, -2.2320, -2.3092, -1.7774, -2.1528,\n",
      "         -2.5846, -2.4651],\n",
      "        [-2.7578, -2.6017, -2.0936, -2.7331, -2.0163, -2.4780, -1.8456, -2.2158,\n",
      "         -2.5995, -2.1559],\n",
      "        [-2.5946, -2.6712, -2.2129, -2.7177, -2.4254, -2.3062, -1.6850, -2.2061,\n",
      "         -2.3345, -2.3004],\n",
      "        [-2.4013, -2.2740, -2.5545, -2.4023, -2.2661, -2.7531, -1.6124, -1.8938,\n",
      "         -2.7135, -2.9076],\n",
      "        [-2.8698, -2.0168, -2.3174, -2.6951, -1.8508, -2.4165, -2.1449, -2.3064,\n",
      "         -2.4749, -2.3338],\n",
      "        [-2.7207, -1.8099, -2.1031, -2.6903, -2.2693, -2.5698, -2.6482, -1.8700,\n",
      "         -2.1246, -2.8781],\n",
      "        [-2.7857, -1.9610, -2.6305, -2.4053, -2.1348, -2.5351, -2.1052, -2.3155,\n",
      "         -2.1242, -2.3256],\n",
      "        [-2.6917, -2.7662, -2.0599, -2.2232, -1.8391, -2.5862, -2.0217, -2.0902,\n",
      "         -2.6622, -2.6114],\n",
      "        [-2.9364, -1.9018, -2.2850, -2.5288, -2.0690, -2.4354, -2.3995, -1.9623,\n",
      "         -2.3362, -2.6003]], grad_fn=<SubBackward0>) 64\n"
     ]
    }
   ],
   "source": [
    "print(preds, len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8781c625-5f89-404c-bb85-780847568a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 2, 6, 1, 6, 4, 7, 6, 2, 8, 6, 1, 7, 2, 2, 6, 2, 2, 4, 8, 6, 6, 9, 1,\n",
      "        6, 4, 6, 6, 6, 9, 6, 4, 5, 6, 6, 7, 7, 2, 6, 6, 2, 6, 4, 6, 6, 6, 6, 6,\n",
      "        7, 6, 7, 6, 6, 1, 6, 6, 6, 6, 6, 4, 1, 1, 4, 1]) 64\n",
      "tensor(0.0781)\n"
     ]
    }
   ],
   "source": [
    "accur = accuracy(preds, yb)\n",
    "print(accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c35ef-4dce-4f91-9b85-c13a13989d5a",
   "metadata": {},
   "source": [
    "Remember that argmax takes the index of the maximum value. If you inspect both the preds and the accur tensors. You can see that the outputs of the accur tensor are the indexes from the preds tensor that have the highest value / closest to 0 since all are in the negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd34fc-3562-4bc3-8bc5-276b38333f2e",
   "metadata": {},
   "source": [
    "When it comes to the optimizer, we're just going to do that manually. Remember that gradient descent's formula *weights -= weights.grad * lr*. In this case, we're not doing random batch sizes so what we're doing here is called mini-batch gradient descent. If we wanted to do stochastic gradient descent manually, we would have to shuffle the data randomly and split it into batches. Here, we're not doing the shuffle part. At the end of the day, the optimizer is just gradient descent. There's just many types of gradient descent. We can do these manually or using the PyTorch library. We're doing the latter for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5388a8d-e6a4-461b-b969-b49655b71fd2",
   "metadata": {},
   "source": [
    "Now that we have everything we need, let's do the training loop:\n",
    "\n",
    "1. Select mini-batch of data of size (bs - 64)\n",
    "2. Generate predictions with the model (forward-pass)\n",
    "3. Calculate the loss of these predictions\n",
    "4. Conduct backpropagation with *loss.backward()* (backward-pass)\n",
    "5. Step the weights & bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99377435-8105-4b82-ad29-e8bbb196b89f",
   "metadata": {},
   "source": [
    "Remember that N is a variable that holds the number of images that we have: N = 5000\n",
    "\n",
    "However, before we start we need a way to ensure that our total number of images *n* is divisible by our batchsize. That way we can account for the total number of batche sizes we need. This can easily be done by this formula: *((n - 1) // bs + 1)*. In addition, this formula also accounts for adding an extra batch if the total number of images is NOT divisible by the batchsize. This helps include all the remaining images. The last batchsize would differ depending on the amount of images left. \n",
    "\n",
    "Breaking it down:\n",
    "\n",
    "1. **(n - 1)** - this provides for the case if n is divisible by bs. If it is divisible, you won't get an additional unecessary batch. \n",
    "2. **//** - in simplest terms, this just divides n by bs. Double slash means that you'll get a whole number.\n",
    "3. **bs + 1** - this always creates an extra batch so that it can handle all the extra images that you might have left out. Unless if n is divisible by the batchsize then this just provides the last batch that you need.\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e77518e-2350-4f0c-a155-39ae16f70465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBatchNum(images, batchsize):\n",
    "    imTotal = images - 1\n",
    "    bsCalc = imTotal // batchsize\n",
    "    bsLast = imTotal % batchsize\n",
    "    bsTotal = bsCalc + 1\n",
    "    print(f\"Image Total: {imTotal} | Batch Division: {bsCalc} | Image in Last Batch: {bsLast} | Batch Total: {bsTotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35c2fcc6-7c8b-40a5-a2b8-f00355758960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Total: 49999 | Batch Division: 781 | Image in Last Batch: 15 | Batch Total: 782\n",
      "Image Total: 49999 | Batch Division: 999 | Image in Last Batch: 49 | Batch Total: 1000\n"
     ]
    }
   ],
   "source": [
    "calcBatchNum(n, bs)\n",
    "calcBatchNum(50000, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cb8aa-a14e-46a0-8847-7230af4dee39",
   "metadata": {},
   "source": [
    "Here we can see that if the batch division is 64 (5000 is not divisible by 64), it would originally have only 781 batches leaving out the 15 images not to be included. However, we've in our batch total, we've added an extra so these are automatically placed in the last batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2cd1ec8-0cbd-41db-bb66-4b143461e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "\n",
    "        # Setting Start Batch\n",
    "        start_i = i * bs\n",
    "        # Setting End Batch\n",
    "        end_i = start_i + bs\n",
    "\n",
    "        # Applying Batchsize to Data\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "\n",
    "        # Create Predictions By Model & Loss From Predictions\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        # Conduct Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # We specify these with torch.no_grad() because we do not want PyTorch to track these operations as these are not part of the\n",
    "        # forward pass.\n",
    "        with torch.no_grad():\n",
    "            # Update the weights & bias\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "\n",
    "            # Reset the gradients to zero\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a0a8c-70b0-436f-a9d7-ba7894b2da49",
   "metadata": {},
   "source": [
    "Now, this is what a minimal neural network would look like. It has everything that it needs from a model with one activation layer and one linear layer, data that is split into training and testing, a loss function, and gradient descent using mini-batches for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb9b9c0-3f3a-43fe-945f-f0ddd1ed05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8]) 16\n",
      "tensor(0.0818, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b8c92-6ad2-4e92-a144-040911928e4e",
   "metadata": {},
   "source": [
    "It's time to start refactoring this code. We'll be exchanging things bit by bit with PyTorch's *nn* modules, classes, and functions.  \n",
    "\n",
    "First order of business is to making the code easier by using activation and loss functions that is already built-in with *torch.nn.functional*. This module contains all the functions in the *torch.nn* library (other parts of the library contain classes). In addition there are also convenient functions contained here for creating neural networks such as pooling functions but there are also functions that are better suited for convolutions, linear layers, and many more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ad977-d277-4aa7-a4fc-5abe8433f3c4",
   "metadata": {},
   "source": [
    "Remember that we were using *negative log-likelihood* as our loss function and *log_softmax* as our activation function? PyTorch provides both of these in one with *F.cross_entropy*. That means that we can go and remove the activation function from the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e22b66-c816-4294-bc7e-c45f7421bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354562d-bb2c-483b-84e0-8660f0ef038e",
   "metadata": {},
   "source": [
    "With this, we're no longer using the *log_softmax* and *nll* functions that we defined manually earlier. Let's take a look if the outputs are still the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b540878-dba6-4359-b28d-c972913d5cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8]) 16\n",
      "tensor(0.0818, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ae937-4012-4865-83b1-cebf87678b28",
   "metadata": {},
   "source": [
    "Exactly the same! That means we can keep on going and that our refactored code still works. Next, we'll utilizing the *nn.Module* and *nn.Parameter* portions of the *nn* library. We subclass *nn.Module*. In this case, we are creating a new class (our model) that will be holding the weights, bias, and method for the forward step. Because this class has now access to all the attributes and methods of *nn.Module*, it'll make our life a lot more convenient when creating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b857d9d-dca4-4003-a6fe-f848a80c70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73627c79-61f9-4fdb-b53a-b117c7513657",
   "metadata": {},
   "source": [
    "So our weights is just pretty much the same as to how we defined it earlier. We also have our Xavier initialization. Nothing much changed in this regard. Same goes for our bias. Let's instantiate our model and calculate the loss.\n",
    "\n",
    "**NOTE:** PyTorch does the forward pass automatically. We just need to call our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90d640c1-d37b-456f-89a0-5c5918c03681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "678cb34c-1666-451b-abbe-9598091ff361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3404, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91162d-c421-4f4d-b769-b9ff88a695e2",
   "metadata": {},
   "source": [
    "**REFACTOR USING nn.Module | nn.Parameter**\n",
    "\n",
    "Let's now work with our parameters since we've dealt with our loss function and model. Before we've had to manually update the parameters ourselves for both weights & bias. We've also had to manually zero out our gradients for these parameters. We can do this a lot faster since we are now using *nn.Parameter*. \n",
    "\n",
    "Let's update the training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "584390f8-71c8-4c59-8971-e34d57214dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "    \n",
    "            # Setting Start Batch\n",
    "            start_i = i * bs\n",
    "            # Setting End Batch\n",
    "            end_i = start_i + bs\n",
    "    \n",
    "            # Applying Batchsize to Data\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "    \n",
    "            # Create Predictions By Model & Loss From Predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "    \n",
    "            # Conduct Backpropagation\n",
    "            loss.backward()\n",
    "    \n",
    "            # We specify these with torch.no_grad() because we do not want PyTorch to track these operations as these are not part of the\n",
    "            # forward pass.\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                # NEWLY ADDED\n",
    "                # Utilizing the model.parameters() to automatically step our weights and bias. \n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "                \n",
    "                # END\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88efe460-e828-423b-b12d-2fa00878c2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0789, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481866e-0317-4505-80c4-e0f4f023bfdd",
   "metadata": {},
   "source": [
    "**REFACTOR USING nn.Linear**\n",
    "\n",
    "We don't need to manually define and initialize *self.weights* & *self.bias*, as well as calculating *xb @ self.weights + self.bias*. We will be refactoring these parts into one convenient PyTorch class called *nn.Linear* which creates a linear layer. PyTorch has many predefined layers that we can play around with that makes neural network layers so much easier to read and write. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4500bcb-3dfa-4efb-b9d8-5261c4f9bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e14649-0a0e-4f56-9709-5a3405d60134",
   "metadata": {},
   "source": [
    "We define the *in_features* (first argument) being 784 which is the number of pixels that we are inputting in them model. We are also creating an *out_features* (second argument) as 10 outputs because we have 10 digits to work with from 0-9. Basically this just means that nn.Linear will take 784 (flattened input image - 28x28) inputs and output 10 possible classes.\n",
    "\n",
    "Here we don't need to call Xavier initialization for the linear layer as *nn.Linear* already uses a uniform distribution to initialize the weights. It's not Xavier initialization but it's close to it. \n",
    "\n",
    "That's not to say that you can't use Xavier. You can actually do that by specifying it *init_xavier_uniform(self.lin.weight)*. This applies the Xavier uniform initialization. But again, not really necessary anymore.\n",
    "\n",
    "Let's reinitialize our model and output the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726dc929-828a-4f89-8354-a95fb7e1e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3432, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a01fe-3b67-4b62-bf3b-4e57297d59b4",
   "metadata": {},
   "source": [
    "Since we've recreated our model, we'll also need to redo our training cycle. So, let's call our fit method again. Don't expect anything to change, it shouldn't have changed much since we're just refactoring our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14acc5e4-ac61-44fe-9c36-d9cda0d816aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0810, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7b9f6-bac0-4f18-87bf-8efa169d01d8",
   "metadata": {},
   "source": [
    "**REFACTOR USING torch.optim**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fc90c-2ea5-4696-8c88-768d74c7ed2f",
   "metadata": {},
   "source": [
    "During the time that we refactored our weights and bias with *nn.Parameter*, we've also had to update our step. Specifically, we cut down the code to utilizing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e7356f7-9c51-4ac5-9970-5fb830828c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1ef1c-c14f-41c7-a09f-d51e166b86bd",
   "metadata": {},
   "source": [
    "It was a lot more convenient rather than the prior code that we manually defined but even this can be a bit hectic in itself. We can further refactor this into something that is a lot simpler. PyTorch has a package that contains various different types of optimization algorithms in *torch.optim*. We can utilize a *step* method from a optimizer to take a forward step rather than manually updating each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d80bf78-480b-4a7d-982e-1ff1a3c93812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0809, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Create Model & Optimizer \n",
    "def get_model():\n",
    "    model = MNIST_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Assign Model & Assign Optimizer \n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range (epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "\n",
    "        # Ready Data\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "\n",
    "        # Create Predictions - Forwardpass\n",
    "        pred = model(xb)\n",
    "        # Calculate Loss\n",
    "        loss = loss_func(pred, yb)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Optimize / Update / Step Weights & Bias\n",
    "        opt.step()\n",
    "        # Reset Gradients to Zero\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed968c7-ae38-44dc-a27d-57eb89a43cee",
   "metadata": {},
   "source": [
    "We've shortened our optimization in the training loop to only two lines! Remember that we chose an optimizer which was *optim.SGD(model.parameters(), lr=lr)* in the *get_model()* function. Then we assigned this to optim. Which enables us to use the methods for *optim.step* which optimizes/steps/updates the weights & bias. We also had access to the *opt.zero_grad()* method which resest the gradients of the *model.parameters()* to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dd890-b81d-4388-a744-184615ed0bdd",
   "metadata": {},
   "source": [
    "**REFACTOR USING *dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1304a40-1df4-4880-bd9c-dec5109077f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
