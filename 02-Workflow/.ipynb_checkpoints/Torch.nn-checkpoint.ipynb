{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6a1d29-daf8-46a2-b988-38b7bd963086",
   "metadata": {},
   "source": [
    "**Overview of Section**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a4a29-92d9-42d0-a727-6418481fb421",
   "metadata": {},
   "source": [
    "This section will explore what *torch.nn* does in function when creating neural networks. First, this section will create a neural network from scratch. We will be using the MNIST_Dataset to train the model on without using any of the utilities of *torch.nn*, *torch.optim*, *Dataset*, and *DataLoader*. Afterwards, we will gradually refactor the code to include per module. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88596e3-a777-4cd2-b9f5-d61b00566491",
   "metadata": {},
   "source": [
    "**MNIST Data Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745b70bd-dce2-49ca-8e35-7dd42bf15ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de728c9-4acc-4645-a413-6556b9e2dd14",
   "metadata": {},
   "source": [
    "Here we are utilizing *pathlib* to create a directory for our MNIST dataset that we will download using *requests*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4454b96-75aa-4da9-80b9-3e4acf554ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH/FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bf77b-7d00-4972-bcf8-7df3adde02b6",
   "metadata": {},
   "source": [
    "The dataset is in a numpy array format, not a tensor, and is stored using pickle, a python-specific format for serializing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cca9e2-0283-4f04-acbc-73082521f9c9",
   "metadata": {},
   "source": [
    "Since we're dealing with images, we have pixel values in the shape of 28x28. This is currently being stored as a flattened row of length 784 (28x28). Let's put this back into it's proper dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f3625f-f70e-4965-b9fd-14e065329652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf968320-8962-481f-ad7c-2df3965c8864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), <function ndarray.reshape>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_train[0].reshape((28,28))\n",
    "x_train[0].shape, x_train.reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81700a6-4845-42ca-9fb3-397104aa4791",
   "metadata": {},
   "source": [
    "Remember that we are working with NumPy arrays and not PyTorch tensors. There is a similiar function for reshape on both PyTorch & NumPy. So, if we try to use *.view()* which is a PyTorch exclusive function, it wouldn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457006fc-54c8-4bd7-a197-42dedae704b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x183eb2b50c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(z, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5e99da-d74f-4010-a802-87a8116e8298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b9c07-eedc-406d-8090-9b61bc88db3a",
   "metadata": {},
   "source": [
    "As we can see, we have 50000 images with 784 pixel cells. Each row is an image while each column is the corresponding pixel values for that specific image in that row. Now, we need to convert these to *torch.tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d5ec2a-8dd2-46e4-989c-26756b56cdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd8bab-d70c-49f1-9722-6140e4eeff7b",
   "metadata": {},
   "source": [
    "**Neural Network From Scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee99dfc-e89a-4458-bf9e-bed39ac80a98",
   "metadata": {},
   "source": [
    "We'll be creating a model with nothin but PyTorch tensor operations. We will be utilizing PyTorch's methods to create random or zero-filled tensors which we will be using to create the weights and bias for a simple linear model. Same thing as before, we'll also be telling PyTorch to require teh gradients for these so that it can track all the operations done on the tensor. This is so that we can do backpropagation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3353a87-ba81-429a-a4d3-b9f8d24d3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Utilizing Xavier initialisation\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af06938-d0b3-4625-9be8-e9998bd42e3f",
   "metadata": {},
   "source": [
    "What's Xavier initialisation? This is so that the random values generated by *torch.randn* aren't too far apart. Having values that are too high or too low can cause issues with the gradients so we do Xavier initialisation so that all the values are within a certain range of distribution. Basically, we have 784 neurons. We get the square root of 784 which is then used as a part of the scaling factor for all the values that is generated by randn for the weights. This is for normal distribution which we have. If we have a uniformed distribution then we would also use the out_features (10). But in this case that's not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004b17c-cb20-41ae-86e0-010493b90cd1",
   "metadata": {},
   "source": [
    "Since PyTorch can automatically calculate gradients, we can use any standard Python funcion as model. Here, let's write a standard plain matrix multiplicaton and broadcasted addition to create a simple linear model. We'll also need an activation function so log_softmax is what we'll be using. \n",
    "\n",
    "It's important to remember that while PyTorch provies a lot of prewritten loss and activtion functions, it is relatively easy for you to make your own custom functions as well using play Python. PyTorch will even create fast GPU or vectorized CPU code to make it run automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f24d272-858f-4604-ad3a-e40fefc6544f",
   "metadata": {},
   "source": [
    "**NOTE:** *requires_grad_()* and *requires_grad=True* both apply the tracking of gradients for the tensors that they are assigned on. It just so that these two are applied differently. *requires_gad_()* is done on existing tensors while *requires_grad=True* is done on tensors that are being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafc4717-fa30-4c9e-a214-d2f8cfc1e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2055a8-32fc-4868-b3fa-f240e61593a6",
   "metadata": {},
   "source": [
    "We specify log_softmax because that is an activation function that we will use for this model. Compared to before, in the Workflow chapter. We only used a (one) linear layer without any additions whatsoever. Here, we've added an activation function similiar to ReLU (similiar in the sense that they are both activation functions). In this case, it's a log_softmax function because that does well when dealing with classificaiton tasks.\n",
    "\n",
    "log_softmax outputs a set of probabilities, and since we're dealing with the MNIST_Dataset and we want to identify which number is an input from 0-9 then this activtion function is exactly what we need. So basically. \n",
    "\n",
    "Linear Layer (xb @ weights + bias) + Activation Function (log_softmax). That's the composition of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88c74bd-804c-4bce-adec-0e9e5b35fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1927, -2.6379, -2.4251, -2.5838, -2.3804, -2.1210, -1.9880, -2.2527,\n",
      "        -2.3012, -2.3199], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64 # batchsize\n",
    "xb = x_train[0:bs]\n",
    "\n",
    "preds = model(xb)\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b820081-0566-4491-ad1e-33988525ee79",
   "metadata": {},
   "source": [
    "As seen here, we have PyTorch actively tracking the preds tensor. Since we already have our data and model, let's start working on a loss function. Here we are using a custom function that will calculate the negative log-likelihood. It's a bit of a mouthful but the most important part is that this is a good loss function to work alongside our activation function earlier.\n",
    "\n",
    "We split our training data into different batches, in this case we specify the first 64 items in the x_train dataset.\n",
    "\n",
    "**FOR SEMI-DEEP EXPLANATION**\n",
    "\n",
    "Remember that *log_softmax* outputs the logarithm of the probabilities for each class. If we apply *torch.exp()* to the outputs of *log_softmax*, we would get the original probabilities, similar to if we used *softmax* alone. These probabilities can then be converted to percentages to see the model’s confidence in each class. However, right now, we need to measure how wrong our model is, so we use a loss function, which is the *negative log-likelihood* or *nll*.\n",
    "\n",
    "The most important thing to understand is that logarithms are often used for classification tasks, and since we’re dealing with logarithms, we also need a loss function that can handle these logarithms effectively. That’s why the negative log-likelihood is important—it works directly with the log probabilities output by log_softmax.\n",
    "\n",
    "**NOTES:**\n",
    "\n",
    "1. The log probabilities we are dealing with are negative because they are the logarithms of probabilities, which are numbers between 0 and 1\n",
    "2. Logarithms are closely related to limits, especially in the context of calculus and continuous functions.\n",
    "3. ‘Negating’ in the context of nll means we are multiplying the log probabilities by -1 as part of the loss calculation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee92132-252e-4f68-ad82-2832af1bd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5240847-f9e6-4585-9921-cd8b8960003b",
   "metadata": {},
   "source": [
    "Let's take a look at our loss with the model that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a89b1e1-d6fe-4d9c-9516-2891373b77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3760, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11327efe-df21-4c59-8178-7e267b5fae08",
   "metadata": {},
   "source": [
    "Now that we have our loss function working, let's make a metric for our consumption. We'll create an accuracy metric. The idea to it is pretty simple. If the index with the largest value matches the target value then the prediction will be correct. Quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f028e05a-93ec-49ea-b02c-20fea25ac70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    print(preds, len(preds))\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4d90e2d-4b7e-4331-a1cb-2550ad47ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1927, -2.6379, -2.4251, -2.5838, -2.3804, -2.1210, -1.9880, -2.2527,\n",
      "         -2.3012, -2.3199],\n",
      "        [-2.4099, -2.6653, -2.3391, -2.1723, -2.0901, -2.4053, -2.3722, -2.1739,\n",
      "         -2.1428, -2.3856],\n",
      "        [-1.8791, -2.5442, -2.4632, -2.1490, -2.7839, -2.2268, -2.3421, -2.2445,\n",
      "         -2.3242, -2.3296],\n",
      "        [-2.1576, -2.1659, -2.0665, -2.0633, -2.6236, -2.9105, -2.5997, -1.9282,\n",
      "         -2.2168, -2.8062],\n",
      "        [-2.1189, -2.1379, -2.3394, -2.3604, -2.4416, -2.7262, -1.9230, -2.3200,\n",
      "         -2.4977, -2.3864],\n",
      "        [-2.5518, -2.2202, -2.4187, -2.2214, -2.1542, -2.4181, -2.0672, -2.3424,\n",
      "         -2.4448, -2.2877],\n",
      "        [-2.0097, -2.4755, -2.1304, -2.0972, -2.2250, -2.6348, -2.4882, -2.4458,\n",
      "         -2.4677, -2.2446],\n",
      "        [-2.3043, -2.2724, -2.4020, -2.2489, -2.4098, -2.8954, -1.7130, -2.3383,\n",
      "         -2.5456, -2.2955],\n",
      "        [-2.3398, -2.3758, -2.1362, -2.1261, -2.3170, -2.5031, -2.4144, -2.3064,\n",
      "         -2.3284, -2.2404],\n",
      "        [-2.0162, -2.7153, -2.4346, -2.1987, -2.1802, -2.4009, -2.1609, -2.5317,\n",
      "         -2.3788, -2.1981],\n",
      "        [-2.0057, -2.0829, -2.4923, -2.0977, -2.2377, -2.8918, -2.1124, -2.4147,\n",
      "         -2.7950, -2.2852],\n",
      "        [-2.2054, -2.1662, -2.0873, -2.1854, -2.0498, -3.0649, -2.2726, -2.5333,\n",
      "         -2.2107, -2.6417],\n",
      "        [-2.0693, -2.0158, -2.3732, -2.5409, -2.2219, -2.7801, -2.1974, -2.3889,\n",
      "         -2.4341, -2.2295],\n",
      "        [-2.2482, -2.3683, -2.5453, -2.1585, -2.2208, -2.5257, -2.2356, -2.3949,\n",
      "         -2.5244, -1.9655],\n",
      "        [-2.3675, -2.5740, -2.4122, -2.0055, -2.0917, -2.5770, -2.2875, -2.2045,\n",
      "         -2.2497, -2.4178],\n",
      "        [-2.0354, -2.6011, -2.5421, -2.5055, -2.5276, -2.3105, -1.6600, -2.7719,\n",
      "         -2.3644, -2.2156],\n",
      "        [-2.5173, -2.0844, -2.6194, -2.2334, -2.1870, -2.5155, -1.9625, -2.2346,\n",
      "         -2.6518, -2.2654],\n",
      "        [-2.1889, -2.0848, -2.4005, -2.1833, -2.6036, -2.8994, -1.8615, -2.2855,\n",
      "         -2.3559, -2.5351],\n",
      "        [-2.3953, -2.2335, -2.0307, -2.2893, -2.7142, -2.1347, -2.1814, -2.2022,\n",
      "         -2.6122, -2.4331],\n",
      "        [-2.0192, -2.4619, -2.4408, -2.3859, -2.5067, -2.3240, -1.8746, -2.5490,\n",
      "         -2.3436, -2.3445],\n",
      "        [-2.2209, -2.1161, -2.4803, -2.4355, -2.4572, -2.2645, -1.8931, -2.3494,\n",
      "         -2.2118, -2.9071],\n",
      "        [-2.1703, -2.6403, -2.2039, -2.1198, -2.1721, -2.6363, -2.4867, -2.0511,\n",
      "         -2.2636, -2.4915],\n",
      "        [-2.0367, -2.5791, -2.3951, -2.1163, -2.3674, -2.3745, -2.2122, -2.1963,\n",
      "         -2.5182, -2.3646],\n",
      "        [-2.1259, -2.1505, -2.0878, -2.1033, -2.6919, -2.9397, -2.5033, -1.9398,\n",
      "         -2.2087, -2.7773],\n",
      "        [-2.2109, -2.1275, -2.3368, -2.0495, -2.0675, -2.7305, -2.4207, -2.2871,\n",
      "         -2.4884, -2.5173],\n",
      "        [-2.4614, -1.6599, -2.5526, -2.6055, -2.3742, -2.7863, -1.8565, -2.3070,\n",
      "         -2.6526, -2.3882],\n",
      "        [-1.9945, -2.2028, -2.3475, -2.3362, -2.3883, -2.4302, -2.1939, -2.3516,\n",
      "         -2.4950, -2.3846],\n",
      "        [-1.8483, -2.1315, -2.4373, -2.3058, -2.3191, -3.2047, -1.7831, -2.7890,\n",
      "         -2.6697, -2.3130],\n",
      "        [-1.9208, -2.6703, -2.4950, -2.6008, -2.2979, -2.7852, -2.0939, -2.8371,\n",
      "         -2.5816, -1.5706],\n",
      "        [-2.1495, -2.1145, -2.3881, -2.3357, -2.3523, -2.5335, -2.3792, -2.1413,\n",
      "         -2.2588, -2.4641],\n",
      "        [-1.6708, -2.2267, -2.5045, -2.5391, -2.1607, -2.3439, -2.2732, -2.6287,\n",
      "         -2.5254, -2.5641],\n",
      "        [-2.8522, -2.6712, -2.2915, -1.8591, -2.2226, -3.0539, -1.9464, -2.1886,\n",
      "         -2.2040, -2.3490],\n",
      "        [-2.4722, -2.1448, -2.3777, -2.3675, -2.1195, -2.3551, -2.4380, -2.3055,\n",
      "         -2.3397, -2.1746],\n",
      "        [-2.3319, -2.3832, -2.2679, -2.2358, -2.4143, -2.2787, -1.9479, -2.7716,\n",
      "         -2.3680, -2.2114],\n",
      "        [-2.3912, -2.2093, -2.4622, -2.5448, -2.6941, -2.7601, -1.8757, -2.0502,\n",
      "         -2.5502, -1.9375],\n",
      "        [-1.8976, -2.4252, -2.1246, -1.8977, -2.3081, -2.8213, -2.4539, -2.5451,\n",
      "         -2.3215, -2.6494],\n",
      "        [-2.4929, -2.4209, -2.2160, -2.1060, -2.0653, -2.4817, -2.4743, -2.1866,\n",
      "         -2.4576, -2.2521],\n",
      "        [-2.3835, -2.4317, -2.3823, -2.0222, -2.4961, -2.6008, -2.0903, -2.2349,\n",
      "         -2.3334, -2.1987],\n",
      "        [-2.0029, -2.3503, -2.3985, -2.3238, -2.5597, -2.5119, -2.2798, -2.2237,\n",
      "         -2.3522, -2.1470],\n",
      "        [-2.6383, -2.1470, -2.3466, -2.3932, -2.3631, -2.2725, -2.2450, -2.2803,\n",
      "         -2.5009, -1.9858],\n",
      "        [-2.2547, -2.6853, -2.4618, -1.9481, -2.0240, -2.5072, -2.4968, -2.2650,\n",
      "         -2.2234, -2.3964],\n",
      "        [-2.0479, -1.8991, -2.0755, -2.6721, -2.6500, -2.8306, -1.9411, -2.2830,\n",
      "         -2.8112, -2.3924],\n",
      "        [-2.0599, -2.5828, -2.3282, -1.9295, -2.4144, -2.2962, -2.5691, -2.3237,\n",
      "         -2.2807, -2.4361],\n",
      "        [-1.9387, -2.3784, -2.3325, -2.3084, -2.1402, -2.4075, -2.1332, -2.5705,\n",
      "         -2.6370, -2.3782],\n",
      "        [-1.9546, -2.3401, -2.3303, -2.1240, -2.4376, -2.6349, -2.3505, -2.2781,\n",
      "         -2.2778, -2.4553],\n",
      "        [-2.2269, -2.1349, -2.7180, -2.4595, -2.5489, -2.6049, -1.6979, -2.4987,\n",
      "         -2.6415, -2.0115],\n",
      "        [-2.0729, -2.4871, -2.0092, -2.3627, -2.6157, -2.8615, -1.8755, -2.1123,\n",
      "         -2.3143, -2.8234],\n",
      "        [-1.9032, -2.5265, -2.3327, -2.0004, -2.1893, -3.0746, -2.1767, -2.4500,\n",
      "         -2.1620, -2.7234],\n",
      "        [-2.2276, -2.4494, -2.2142, -2.6030, -2.2633, -2.4027, -1.8912, -2.4359,\n",
      "         -2.4360, -2.2811],\n",
      "        [-1.8884, -2.5222, -2.2733, -2.1954, -2.1864, -2.9287, -2.0793, -2.3722,\n",
      "         -2.4504, -2.4796],\n",
      "        [-2.2176, -2.2288, -2.2509, -1.9599, -2.1480, -2.6665, -2.3552, -2.3154,\n",
      "         -2.6762, -2.4230],\n",
      "        [-2.4281, -2.6664, -2.0055, -2.6484, -2.4070, -2.9791, -1.7342, -1.9536,\n",
      "         -2.2893, -2.5721],\n",
      "        [-2.3425, -2.8533, -2.7460, -2.5459, -2.4483, -2.0768, -1.5590, -2.5322,\n",
      "         -2.3996, -2.1954],\n",
      "        [-2.0459, -2.5549, -2.2676, -2.1099, -2.1404, -2.4003, -2.2846, -2.4388,\n",
      "         -2.3816, -2.5455],\n",
      "        [-2.2686, -2.1252, -2.5579, -2.5914, -2.4604, -2.4065, -1.6778, -2.8244,\n",
      "         -2.6749, -2.0087],\n",
      "        [-1.9871, -2.3776, -2.2006, -2.2698, -2.6727, -3.1247, -1.8609, -2.2095,\n",
      "         -2.4030, -2.4384],\n",
      "        [-2.5234, -2.3851, -2.2004, -3.2318, -2.3383, -2.5939, -1.9263, -2.0259,\n",
      "         -2.1388, -2.1990],\n",
      "        [-1.9668, -2.5940, -2.6874, -2.2884, -2.4104, -2.4713, -1.8415, -2.5344,\n",
      "         -2.5205, -2.0928],\n",
      "        [-1.6618, -2.3536, -2.4988, -2.1273, -2.5357, -2.6367, -1.8966, -2.5869,\n",
      "         -2.4782, -2.9224],\n",
      "        [-2.0764, -2.1291, -2.0895, -2.1139, -2.4468, -2.7110, -2.6676, -2.0501,\n",
      "         -2.3370, -2.7592],\n",
      "        [-2.3663, -2.3058, -2.6522, -2.3234, -2.2481, -2.3004, -2.3899, -2.1929,\n",
      "         -2.2075, -2.1283],\n",
      "        [-2.1168, -2.3523, -2.1922, -1.9883, -2.3101, -2.8303, -2.2523, -2.2352,\n",
      "         -2.3344, -2.6793],\n",
      "        [-2.4546, -2.4081, -2.2935, -2.2073, -2.4153, -2.4100, -2.3289, -1.8319,\n",
      "         -2.3437, -2.5188],\n",
      "        [-2.7904, -3.0958, -2.0444, -1.9569, -2.1478, -3.0787, -1.9062, -1.9318,\n",
      "         -2.5296, -2.4459]], grad_fn=<SubBackward0>) 64\n"
     ]
    }
   ],
   "source": [
    "print(preds, len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8781c625-5f89-404c-bb85-780847568a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 4, 0, 7, 6, 6, 0, 6, 3, 0, 0, 4, 1, 9, 3, 6, 6, 6, 2, 6, 6, 7, 0, 7,\n",
      "        3, 1, 0, 6, 9, 1, 0, 3, 4, 6, 6, 0, 4, 3, 0, 9, 3, 1, 3, 0, 0, 6, 6, 0,\n",
      "        6, 0, 3, 6, 6, 0, 6, 6, 6, 6, 0, 7, 9, 3, 7, 6]) 64\n",
      "tensor(0.0156)\n"
     ]
    }
   ],
   "source": [
    "accur = accuracy(preds, yb)\n",
    "print(accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c35ef-4dce-4f91-9b85-c13a13989d5a",
   "metadata": {},
   "source": [
    "Remember that argmax takes the index of the maximum value. If you inspect both the preds and the accur tensors. You can see that the outputs of the accur tensor are the indexes from the preds tensor that have the highest value / closest to 0 since all are in the negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd34fc-3562-4bc3-8bc5-276b38333f2e",
   "metadata": {},
   "source": [
    "When it comes to the optimizer, we're just going to do that manually. Remember that gradient descent's formula *weights -= weights.grad * lr*. In this case, we're not doing random batch sizes so what we're doing here is called mini-batch gradient descent. If we wanted to do stochastic gradient descent manually, we would have to shuffle the data randomly and split it into batches. Here, we're not doing the shuffle part. At the end of the day, the optimizer is just gradient descent. There's just many types of gradient descent. We can do these manually or using the PyTorch library. We're doing the latter for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5388a8d-e6a4-461b-b969-b49655b71fd2",
   "metadata": {},
   "source": [
    "Now that we have everything we need, let's do the training loop:\n",
    "\n",
    "1. Select mini-batch of data of size (bs - 64)\n",
    "2. Generate predictions with the model (forward-pass)\n",
    "3. Calculate the loss of these predictions\n",
    "4. Conduct backpropagation with *loss.backward()* (backward-pass)\n",
    "5. Step the weights & bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99377435-8105-4b82-ad29-e8bbb196b89f",
   "metadata": {},
   "source": [
    "Remember that N is a variable that holds the number of images that we have: N = 5000\n",
    "\n",
    "However, before we start we need a way to ensure that our total number of images *n* is divisible by our batchsize. That way we can account for the total number of batche sizes we need. This can easily be done by this formula: *((n - 1) // bs + 1)*. In addition, this formula also accounts for adding an extra batch if the total number of images is NOT divisible by the batchsize. This helps include all the remaining images. The last batchsize would differ depending on the amount of images left. \n",
    "\n",
    "Breaking it down:\n",
    "\n",
    "1. **(n - 1)** - this provides for the case if n is divisible by bs. If it is divisible, you won't get an additional unecessary batch. \n",
    "2. **//** - in simplest terms, this just divides n by bs. Double slash means that you'll get a whole number.\n",
    "3. **bs + 1** - this always creates an extra batch so that it can handle all the extra images that you might have left out. Unless if n is divisible by the batchsize then this just provides the last batch that you need.\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e77518e-2350-4f0c-a155-39ae16f70465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBatchNum(images, batchsize):\n",
    "    imTotal = images - 1\n",
    "    bsCalc = imTotal // batchsize\n",
    "    bsLast = imTotal % batchsize\n",
    "    bsTotal = bsCalc + 1\n",
    "    print(f\"Image Total: {imTotal} | Batch Division: {bsCalc} | Image in Last Batch: {bsLast} | Batch Total: {bsTotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35c2fcc6-7c8b-40a5-a2b8-f00355758960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Total: 49999 | Batch Division: 781 | Image in Last Batch: 15 | Batch Total: 782\n",
      "Image Total: 49999 | Batch Division: 999 | Image in Last Batch: 49 | Batch Total: 1000\n"
     ]
    }
   ],
   "source": [
    "calcBatchNum(n, bs)\n",
    "calcBatchNum(50000, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cb8aa-a14e-46a0-8847-7230af4dee39",
   "metadata": {},
   "source": [
    "Here we can see that if the batch division is 64 (5000 is not divisible by 64), it would originally have only 781 batches leaving out the 15 images not to be included. However, we've in our batch total, we've added an extra so these are automatically placed in the last batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2cd1ec8-0cbd-41db-bb66-4b143461e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "\n",
    "        # Setting Start Batch\n",
    "        start_i = i * bs\n",
    "        # Setting End Batch\n",
    "        end_i = start_i + bs\n",
    "\n",
    "        # Applying Batchsize to Data\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "\n",
    "        # Create Predictions By Model & Loss From Predictions\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        # Conduct Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # We specify these with torch.no_grad() because we do not want PyTorch to track these operations as these are not part of the\n",
    "        # forward pass.\n",
    "        with torch.no_grad():\n",
    "            # Update the weights & bias\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "\n",
    "            # Reset the gradients to zero\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a0a8c-70b0-436f-a9d7-ba7894b2da49",
   "metadata": {},
   "source": [
    "Now, this is what a minimal neural network would look like. It has everything that it needs from a model with one activation layer and one linear layer, data that is split into training and testing, a loss function, and gradient descent using mini-batches for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb9b9c0-3f3a-43fe-945f-f0ddd1ed05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8]) 16\n",
      "tensor(0.0814, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b8c92-6ad2-4e92-a144-040911928e4e",
   "metadata": {},
   "source": [
    "It's time to start refactoring this code. We'll be exchanging things bit by bit with PyTorch's *nn* modules, classes, and functions.  \n",
    "\n",
    "First order of business is to making the code easier by using activation and loss functions that is already built-in with *torch.nn.functional*. This module contains all the functions in the *torch.nn* library (other parts of the library contain classes). In addition there are also convenient functions contained here for creating neural networks such as pooling functions but there are also functions that are better suited for convolutions, linear layers, and many more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ad977-d277-4aa7-a4fc-5abe8433f3c4",
   "metadata": {},
   "source": [
    "Remember that we were using *negative log-likelihood* as our loss function and *log_softmax* as our activation function? PyTorch provides both of these in one with *F.cross_entropy*. That means that we can go and remove the activation function from the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e22b66-c816-4294-bc7e-c45f7421bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354562d-bb2c-483b-84e0-8660f0ef038e",
   "metadata": {},
   "source": [
    "With this, we're no longer using the *log_softmax* and *nll* functions that we defined manually earlier. Let's take a look if the outputs are still the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b540878-dba6-4359-b28d-c972913d5cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8]) 16\n",
      "tensor(0.0814, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ae937-4012-4865-83b1-cebf87678b28",
   "metadata": {},
   "source": [
    "Exactly the same! That means we can keep on going and that our refactored code still works. Next, we'll utilizing the *nn.Module* and *nn.Parameter* portions of the *nn* library. We subclass *nn.Module*. In this case, we are creating a new class (our model) that will be holding the weights, bias, and method for the forward step. Because this class has now access to all the attributes and methods of *nn.Module*, it'll make our life a lot more convenient when creating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b857d9d-dca4-4003-a6fe-f848a80c70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73627c79-61f9-4fdb-b53a-b117c7513657",
   "metadata": {},
   "source": [
    "So our weights is just pretty much the same as to how we defined it earlier. We also have our Xavier initialization. Nothing much changed in this regard. Same goes for our bias. Let's instantiate our model and calculate the loss.\n",
    "\n",
    "**NOTE:** PyTorch does the forward pass automatically. We just need to call our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90d640c1-d37b-456f-89a0-5c5918c03681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "678cb34c-1666-451b-abbe-9598091ff361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2888, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91162d-c421-4f4d-b769-b9ff88a695e2",
   "metadata": {},
   "source": [
    "**REFACTOR USING nn.Module | nn.Parameter**\n",
    "\n",
    "Let's now work with our parameters since we've dealt with our loss function and model. Before we've had to manually update the parameters ourselves for both weights & bias. We've also had to manually zero out our gradients for these parameters. We can do this a lot faster since we are now using *nn.Parameter*. \n",
    "\n",
    "Let's update the training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "584390f8-71c8-4c59-8971-e34d57214dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "    \n",
    "            # Setting Start Batch\n",
    "            start_i = i * bs\n",
    "            # Setting End Batch\n",
    "            end_i = start_i + bs\n",
    "    \n",
    "            # Applying Batchsize to Data\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "    \n",
    "            # Create Predictions By Model & Loss From Predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "    \n",
    "            # Conduct Backpropagation\n",
    "            loss.backward()\n",
    "    \n",
    "            # We specify these with torch.no_grad() because we do not want PyTorch to track these operations as these are not part of the\n",
    "            # forward pass.\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                # NEWLY ADDED\n",
    "                # Utilizing the model.parameters() to automatically step our weights and bias. \n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "                \n",
    "                # END\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88efe460-e828-423b-b12d-2fa00878c2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0811, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481866e-0317-4505-80c4-e0f4f023bfdd",
   "metadata": {},
   "source": [
    "**REFACTOR USING nn.Linear**\n",
    "\n",
    "We don't need to manually define and initialize *self.weights* & *self.bias*, as well as calculating *xb @ self.weights + self.bias*. We will be refactoring these parts into one convenient PyTorch class called *nn.Linear* which creates a linear layer. PyTorch has many predefined layers that we can play around with that makes neural network layers so much easier to read and write. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4500bcb-3dfa-4efb-b9d8-5261c4f9bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e14649-0a0e-4f56-9709-5a3405d60134",
   "metadata": {},
   "source": [
    "We define the *in_features* (first argument) being 784 which is the number of pixels that we are inputting in them model. We are also creating an *out_features* (second argument) as 10 outputs because we have 10 digits to work with from 0-9. Basically this just means that nn.Linear will take 784 (flattened input image - 28x28) inputs and output 10 possible classes.\n",
    "\n",
    "Here we don't need to call Xavier initialization for the linear layer as *nn.Linear* already uses a uniform distribution to initialize the weights. It's not Xavier initialization but it's close to it. \n",
    "\n",
    "That's not to say that you can't use Xavier. You can actually do that by specifying it *init_xavier_uniform(self.lin.weight)*. This applies the Xavier uniform initialization. But again, not really necessary anymore.\n",
    "\n",
    "Let's reinitialize our model and output the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726dc929-828a-4f89-8354-a95fb7e1e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4176, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a01fe-3b67-4b62-bf3b-4e57297d59b4",
   "metadata": {},
   "source": [
    "Since we've recreated our model, we'll also need to redo our training cycle. So, let's call our fit method again. Don't expect anything to change, it shouldn't have changed much since we're just refactoring our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14acc5e4-ac61-44fe-9c36-d9cda0d816aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0821, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7b9f6-bac0-4f18-87bf-8efa169d01d8",
   "metadata": {},
   "source": [
    "**REFACTOR USING torch.optim**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fc90c-2ea5-4696-8c88-768d74c7ed2f",
   "metadata": {},
   "source": [
    "During the time that we refactored our weights and bias with *nn.Parameter*, we've also had to update our step. Specifically, we cut down the code to utilizing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e7356f7-9c51-4ac5-9970-5fb830828c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1ef1c-c14f-41c7-a09f-d51e166b86bd",
   "metadata": {},
   "source": [
    "It was a lot more convenient rather than the prior code that we manually defined but even this can be a bit hectic in itself. We can further refactor this into something that is a lot simpler. PyTorch has a package that contains various different types of optimization algorithms in *torch.optim*. We can utilize a *step* method from a optimizer to take a forward step rather than manually updating each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d80bf78-480b-4a7d-982e-1ff1a3c93812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Create Model & Optimizer \n",
    "def get_model():\n",
    "    model = MNIST_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Assign Model & Assign Optimizer \n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range (epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "\n",
    "        # Ready Data\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "\n",
    "        # Create Predictions - Forwardpass\n",
    "        pred = model(xb)\n",
    "        # Calculate Loss\n",
    "        loss = loss_func(pred, yb)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Optimize / Update / Step Weights & Bias\n",
    "        opt.step()\n",
    "        # Reset Gradients to Zero\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed968c7-ae38-44dc-a27d-57eb89a43cee",
   "metadata": {},
   "source": [
    "We've shortened our optimization in the training loop to only two lines! Remember that we chose an optimizer which was *optim.SGD(model.parameters(), lr=lr)* in the *get_model()* function. Then we assigned this to optim. Which enables us to use the methods for *optim.step* which optimizes/steps/updates the weights & bias. We also had access to the *opt.zero_grad()* method which resest the gradients of the *model.parameters()* to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dd890-b81d-4388-a744-184615ed0bdd",
   "metadata": {},
   "source": [
    "**REFACTOR USING *dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe639b-f31a-4e0d-aa2f-4abe0aef007b",
   "metadata": {},
   "source": [
    "PyTorch also has a Dataset class. Datasets can be anything that has a *__len__* (Python standard *len* function) and a *__getitem__* function as a way of indexing into it. PyTorch's *TensorDatset* is a Dataset that wraps around tensors. This is done by defining a length and a way of indexing. We can also iterate, index, and slice along the first dimension of a tensor. This makes it easy to access both the independent (data) and dependent (labels) variables at the same time during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef1b54d7-d0bd-4d55-aff1-72fa848fad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcc28a-8970-4509-8d23-6998293612de",
   "metadata": {},
   "source": [
    "So we've had *x_train* and *y_train* before. We can merge this into one single *TensorDataset* which will make it a lot easier to iterate over and slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "244b4079-e783-4555-81df-f15b572e1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f59a6-25e1-47a8-b4ee-1df9267d00d7",
   "metadata": {},
   "source": [
    "So what are we going to with this exactly? Let's take a look. This is what we had to do prior in our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53942a77-b6da-4da2-bf55-abb9727192b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'skip'\n"
     ]
    }
   ],
   "source": [
    "%%script skip\n",
    "\n",
    "xb = x_train[start_i:end_i]\n",
    "yb = y_train[start_i:end_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc8868-ccd2-4ada-8b60-f3d6a65485b2",
   "metadata": {},
   "source": [
    "We're going to refactor this with our newly created Dataset object. We can combine these two into one now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39508bf-6bdd-4e65-9c63-217ed7707df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[i*bs : i*bs+bs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e99e1-93d9-4432-9931-48ce9ee6d5eb",
   "metadata": {},
   "source": [
    "[i*bs : i*bs+bs] is basically the same just as start_i and end_i. They both serve the same function. They splice the dataset into batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bd22c31-d95c-4abd-8e0c-c3a9f5f24103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0828, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b0b4b-24c8-43ed-a66c-72992e8c4ca7",
   "metadata": {},
   "source": [
    "**REFACTOR using DataLoader**\n",
    "\n",
    "PyTorch *DataLoader* is responsible for handling batches. The *Dataset* that we used earlier just simply handled ... Datasets. The entire section of *xb, yb = train_ds[i*bs : i*bs+bs]* involves creating batches. We're going to refactor this using *DataLoader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cb28e66-f15d-455b-82e7-e7d9a42f3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8009d-7f20-4dd0-b53f-e52993345d3d",
   "metadata": {},
   "source": [
    "With this we've succesfully, utilized a *DataLoader*. We no longer have to deal with the loop to iterate over batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cc0b6bb-597c-4f14-b5b5-370b0cf4a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0825, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a730d-68df-4915-b250-96e66da3e510",
   "metadata": {},
   "source": [
    "Now we've refactored our manual neural network into a much more convenient and easy-to-read code using *nn.Module*, *nn.Parameter*, *Dataset*, and *DataLoader*. \n",
    "\n",
    "We're now done with refactoring so let's add some features to the model to make it a lot more interesting and effective in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e9c14-d1d4-47e6-b730-f0343ab78733",
   "metadata": {},
   "source": [
    "**Adding Validation**\n",
    "\n",
    "In the first section where we were refactoring, we were simply creating a simple training loop for our training data. In reality, there should always be a validation set in order to verify and check if we are overfitting. \n",
    "\n",
    "Overfitting is the case where the model has memorized the data that it is being trained on. It hasn't learnt the general patterns of the data but instead has fully memorized it and thus cannot be used on any other similiar data anymore. \n",
    "\n",
    "Shuffling training data is vital to prevent correlation between batches and causing overfitting. When it comes to the validation data, it's loss will still be identical whether or not we shuffle it because the model has never seen it before. Shuffling takes some time so there is no need to shuffle the validation data. \n",
    "\n",
    "So the process when it comes to the model dealing with data is the following:\n",
    "\n",
    "1. Model -> Trains with Training Dataset\n",
    "2. Model -> Verifies with Validation Dataset\n",
    "\n",
    "These two operate alongside each other in the training loop. Then finally,\n",
    "\n",
    "3. Model -> Tested with Test Dataset\n",
    "\n",
    "Now, what size should our validation set be? We'll use a size that is twice as large as the training set. Reason for this is that the validation set does not need backpropagation which means that there is less memory required in dealing with it since it doesn't have to store gradients for calculations. We make good use of this advantage by using a larger batch size to compute the loss faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e109346-af55-48ed-876b-90e2b2659d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20218ecc-9ebc-49db-a0be-3fae2231711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3431)\n",
      "1 tensor(0.3011)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # The xb, yb are from the valid_dl dataloader. This calculates the loss from these two\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    # Remember that our epoch is only 2 so our resulting output is only two batches of data with their corresponding loss values.\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b7f51-7a38-4e90-aac8-15c84b7b519b",
   "metadata": {},
   "source": [
    "We specify *model.train()* and *model.eval()* to identify which part of the training loop requires the model to track calculations. Since we're not really going to track gradients with evaluation, we specify that using *model.eval()*. Otherwise, we'll keep it to *model.train()*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa80e06-8eec-407b-9197-ff374feb2090",
   "metadata": {},
   "source": [
    "**Utilizing *fit()* & *get_data()***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ce91b-ffe1-457e-bda9-ef22d3885693",
   "metadata": {},
   "source": [
    "Let's start refactoring again, since we went through a similiar process twice for calculating the loss for both the training set and validation set, we can make that into our own function, *loss_batch*, which computes the loss for one batch.\n",
    "\n",
    "Pass an optimizer in for the training set to perform backpropagation. For the validation set, there's no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "447c2b5e-4ee7-49c8-a164-702f341d7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    # Conducts backpropagation else skipped entirely\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d68088-6b27-4008-b06f-6846b29dca73",
   "metadata": {},
   "source": [
    "Now, we'll be creating a *fit()* function which runs the necessary operations to train the model and also compute the training and validation losses for each epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2263f433-27d8-412a-9ab3-775a3f4bb855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl])\n",
    "            val_loss = np.sum(np.multiply(losses, nums) / np.sum(nums))\n",
    "\n",
    "            print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4484a-be30-47a4-8c0a-d74f3f1d3330",
   "metadata": {},
   "source": [
    "*get_data* basically just returns the dataloaders for the training and validation sets. Summing it all up, *fit()* does the work for training and outputting the loss while *get_data* just prepares the data for *fit()* to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3732f398-e86a-40f6-964f-d59e3252bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe7831-19d0-43d8-a27f-a1bc570e8a43",
   "metadata": {},
   "source": [
    "Now that we have these two, our training loop will become even a lot smaller now that we've split them up into different functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c42a6e2c-0d6b-4598-aea6-2875ee70a82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.34241887465715404\n",
      "1 0.2904830204367637\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1984072-dfa9-481a-a42c-85114a3132bc",
   "metadata": {},
   "source": [
    "We've already cut down our entire long manual training loop into just three lines of code! Since these are very flexible functions, we can experiment with them and use different models and it'll still work! Let's try switching it up from a linear model to a convolutional network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b00dd-2a9a-49a4-a727-f99003f1849a",
   "metadata": {},
   "source": [
    "**Switch To CNN**\n",
    "\n",
    "We'll be building a convolutional neural network that contains three convolutional layers. Our functions earlier were entirely seperate from our model and so we can use them to train a CNN without any changes required. Quite modular and flexible. \n",
    "\n",
    "PyTorch has a predefined class for a convolutional layer called *Conv2d* which we will be using. Each convolutional layer will be followed by a ReLU activation function. At the end, we'll perform an average pooling. \n",
    "\n",
    "Don't get too bothered with what a convolution is. We're just showcasing that we can also use our functions with an entirely different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59aebbc5-7818-452f-9f48-a0eceadc0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbcc71b-875e-4b30-899c-e64950df2207",
   "metadata": {},
   "source": [
    "*Momentum* is a variation of *Stochastic Gradient Descent* that takes previous updates into account and generally leads to faster training. It might sound a bit contradictory since don't we zero the gradients? It might sound like that but *Momentum* creates a new variable called velocity which tracks a fraction of the previous gradients and in conjunction with the current gradients is used to update the weights. \n",
    "\n",
    "Basically, the previous gradients are used to have a small effect on the updating of th weights. Think of velocity as tracking the direction of where weights are headed. This is great when updating the weights because we know where direction that we're headed thanks to velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d785e3c8-df9c-4880-ae6e-edede0856ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.34350920625925063\n",
      "1 0.27112330963313575\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14081bb-0902-47ba-9302-6096119d74ba",
   "metadata": {},
   "source": [
    "**Refactoring With nn.Sequential**\n",
    "\n",
    "We can do more refactoring and simplification of our code. We can do more with *Sequential*. This creates a *Sequential* object that runs each of the modules contained within it in a sequential manner. This makes it a lot simpler in writing neural networks (models).\n",
    "\n",
    "First, we have to defin e a custom layer from a given function. For example, PyTorch does not have a *view* layer and so we'll need to make one by ourselves. *Lambda* will create a layer that we can then use when defining a network with *Sequential*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e59aa80-f4ec-467a-aafd-5a1a62a9a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e34eb98e-7989-43a0-a0b5-0ffdbc8565c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5031dd3-23ac-4d90-99f0-306029080ff6",
   "metadata": {},
   "source": [
    "The model that can be created with *Sequential* is quite simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54b6e3c5-58df-46cb-aeea-cc28c759bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3698332043886185\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epoch, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78768b03-9e2b-49b6-90ff-67fa96aafd9b",
   "metadata": {},
   "source": [
    "Basically, *Lambda* serves as a way for us to create custom layers. It is built in a specific way that it can take different functions such as preprocess and then use that to create a custom layer that we can use in a model. As shown when we can use this in creating our model. We also used *nn.Sequential* which allows us to stack layers with each other and it operates them sequentially. \n",
    "\n",
    "Letting the output of the first layer move to the next and so on. Primarily, the *Lambda* or the custom layers here just simply reshape the data that we are using. So it changes the view at the start and does again at the end. So, why do we need to do that? Well, it's because different layers require different dimensions for the data. *nn.Conv2d* requires four dimensions so that's why we do *Lambda(preprocess)*. At the end, we return the tensors back to their original form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8057b12-28b3-469d-ae4b-5c70f8d43832",
   "metadata": {},
   "source": [
    "**Wrapping DataLoader**\n",
    "\n",
    "The CNN that we created is pretty well-functioning for the most part. However, it only specifically works with MNIST Dataset because:\n",
    "\n",
    "1. We specified that the input is a 28*28 long vector. If it recieves anything other than that, it won't work.\n",
    "2. It assumes the final CNN grid size is 4*4 (since that is the average pooling kernal size used) -- MORE ON THIS SOON \n",
    "\n",
    "We need to remove these assumptions so that we can have a much more flexible network and it would work with any 2D single channel image. \n",
    "Let's remove the initial Lambda layer by moving the data preprocessing into a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffa8de2c-af5f-4f97-b5f3-6e0dd4498791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "class WrappedDataLoader: \n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    # This allows us to use the len() function on the object and it will return the length of the DataLoader\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    # This allows us to iterate through the object's DataLoader \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7ad43-da4a-4646-a4c3-eeee893c0afa",
   "metadata": {},
   "source": [
    "We place *train_dl* and *valid_dl* into their respective *DataLoaders* using our function earlier *get_data* then we place these in a wrapper object that we defined as *WrappedDataLoader* that has functions in it such as *len()* which allows us to get the length of the *DataLoader* and it also allows us to iterate over the *DataLoader* with *iter*\n",
    "\n",
    "*__iter__* in the most easiest to describe terms is a function that is akin to a loop. So yield returns a value but unlike an actual *return*, it instead pauses the function and continues once it's called again, such as in a loop, it will get called and called until it reaches a certain condition. \n",
    "\n",
    "**b* in the yield function means that it will unpack the variable b which is our batch. So it'll unpack each batch and then apply whatever you decide to apply to it using *self.func*. So practically speaking, we are going to use *preprocess* to each batch using the iteration in the WrappedDataLoader object. This iteration will return new processed batches of *self.dl*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494c07f-4cc8-43c1-a011-1b83856a7418",
   "metadata": {},
   "source": [
    "Lastly, we change *nn.AvgPool2d* with *nn.AdaptiveAvgPool2d* which allows us to define the size of the output tensor that we want. This does not care for the input size nor does it affect it. This entirely revolves around the output size of the model. We already made our input size flexible by having our *WrappedDataLoader*. \n",
    "\n",
    "This basically means that we can put in any input size thanks to *WrappedDataLoader* and we can choose any output size thanks to *nn.AdaptiveAvgPool2d*. This combination means that we can handle any size for both input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5587ad25-01ba-4bc5-89a7-414754cfd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fd82d30-8c2d-405f-823a-8310db0c2f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.36910847609043135\n",
      "1 0.26770886365175245\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c546368-aa3e-4389-bf17-57e0c061a2a9",
   "metadata": {},
   "source": [
    "It works! We've created many different types of models. Starting off from a very manual linear model to a shortened one. We added a validation set to it. Once that's done we tried our hand making our training loop a lot easier by utilizing *fit()* and *get_data()*. We also then used CNNs and experimente with *nn.Sequential* and wrapping our *DataLoaders*. That's a lot of work!\n",
    "\n",
    "We're approaching the last part which is pretty easy - setting our device to use the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "757f3d77-3be0-4614-a694-ffe207ffe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3611c-0550-45e7-8dde-74b1c982e5d0",
   "metadata": {},
   "source": [
    "Let's move our preprocess function to the GPU. It's pretty simple. Remember, we need to convert both the Data and the Model to the same device. So we'll be starting with the *preprocess* function because that is the one that deals with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80728d42-14ba-44bb-b61d-73945e3cefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "# Preprocess is the one doing the conversions of the data. This is done inside the WrappedDataLoader object\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d619da1-e7ae-402f-b498-2cd0a973fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62ef7b78-f2bf-4812-94ad-300f32546e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22417534201145167\n",
      "1 0.17642119136452675\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec8150-5074-430b-a55e-7a5d5bde5e20",
   "metadata": {},
   "source": [
    "So what we've created here is a simple generalized pipeline for training models. This can be used for many different models that you would want to use. There are still many things that can be added such as data augmentation, hyperparameter tuning, monitoring training, transfer learning, etc. \n",
    "\n",
    "These are also available in the fastai library that can be used.\n",
    "\n",
    "Summarizing it all:\n",
    "\n",
    "**torch.nn** -  encompasses three key functions:\n",
    "\n",
    "1. *Module* - This creates a callable that is similiar to a function. It also holds states such as neural network layer weights. In addition, it can also recognize what *Parameter* contains and is capabale of zeroing the gradients / resetting them, loop through the weights for updates, and many more. \n",
    "    \n",
    "2. *Parameter* - it is used to wrap a tensor that can communicate with the *Module* that it contains weights that need to be updated during backpropagation. It is important to note that this only occurs for tensors that have the *requires_grad* attribute.\n",
    "\n",
    "3. *functional* - a module (imported as *F*)that contains multiple different functions from activation, loss, and even non-stateful versions of layers such as convolution and linear layers.\n",
    "\n",
    "**torch.optim** - Simply contains all necessary optimizers required to update the weights of *Parameter* from cross_entropy to stochastic gradient descent. \n",
    "\n",
    "**Dataset** - a flexible interface of objects that contains ___len__ and __getitem__ functions. It includes classes that comes with PyTorch such as *TensorDataset*\n",
    "\n",
    "**DataLoader** - Can retrieve any Dataset and wrap itself around it. It creates an iterator that can return batches of data. It can also shuffle the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
