{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac54dcf-d51f-4d10-84f8-90aa0772bbe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21409b2-0bcf-47f0-89d2-4e750cc0401b",
   "metadata": {},
   "source": [
    "Scalar is a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f5db66-7c13-43bc-b1bc-521b79b08efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242498b6-557c-40da-9eb7-45b71639a2d8",
   "metadata": {},
   "source": [
    "As seen below, it is only a rank-0 tensor since it is just simply one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ed9df4-b6ad-4668-8df7-ee5af2d8d7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3dbe8d-60d7-48e6-91c8-6b9c439b6b0d",
   "metadata": {},
   "source": [
    "If we want to view the scalar as a regular python integer, we use .item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803d95cd-0169-494f-8e7b-fbc84a789213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4defee-c728-4af6-ab89-454f2b4c939c",
   "metadata": {},
   "source": [
    "Let's now take a look on vectors. Vector is one dimension or a rank-1 tensor. This dimension can contain many numbers. For example, you can have [3,2] to describe the number of [bedrooms, bathrooms] in yur house. Or even  [3,2,2] to describe the [bedrooms, bathrooms, carpark]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a81090-9206-4289-9779-60843b2b8920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a88a90d-6713-4d93-ab8e-37549bae1ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a30d4b-384c-4f0e-b3c9-cfa772df9756",
   "metadata": {},
   "source": [
    "Now, you might wonder as to why does vector have only one dimension when clearly there are two numbers inside it? Well, one of the easiest ways to distinguish the rank is to count the number of brackets there are on the outside. Just count one side. - such as [ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dbad2-65fc-431f-bfc8-c3b820e7a8ef",
   "metadata": {},
   "source": [
    "Another key part of tensors is the shape of a dimension. This will tell you how many elements are inside the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b295a0a-dc03-47ac-ab4d-9dc2ac9dbd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cedcba-7228-4bfc-a3fb-16fcabce2d28",
   "metadata": {},
   "source": [
    "As we can see, it returned 2 because there are two elements inside the first dimension which as we specified earlier is [7,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc45ae7-bfcd-4771-b818-e4f5648a220a",
   "metadata": {},
   "source": [
    "Now, let's take a look how what a matrix is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559b1b00-76f9-4e21-9d9a-8e51c2eb4b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f0bf92-bd9e-4032-afe3-c344f4e8ddcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3bf11-686b-4608-8cad-5e7fc3d83247",
   "metadata": {},
   "source": [
    "It's returned 2 becuase this is a rank-2 tensor or a matrix. Did you count the first two brackets that you can see? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e852244-d444-4426-81a8-640a6ff9634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c1d4c-0208-490b-b968-d92a5a747e08",
   "metadata": {},
   "source": [
    "Here, it returned [2,2] because of our matrix is 2 elements wide and 2 elements deep. Let's take a look if we remove one element on the width and see the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c468a22-1c4e-4d08-9bb1-8c1cbd8c5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX = torch.tensor([[4],\n",
    "                       [5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f8cc13-0c17-4ad4-8c98-b0d7415e739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f02818-5e64-46e2-9e06-f3e7dae8dee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim, MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771271de-c869-409c-91bb-fb85e5ec9ab9",
   "metadata": {},
   "source": [
    "As you can see it still retains the 2 for the dimensions because the number of brackets hasn't really changed. However we did change the number of elements on it's width, we removed 1 element. Thus, our matrix is now [2,1] because it is 2 elements deep and 1 element wide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41759efe-1a78-4f6f-a1ee-1299a2e8278e",
   "metadata": {},
   "source": [
    "Now, let's try making a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34bf3c34-8be8-4c27-bb39-ab035d8f3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce68cc3a-41f7-4717-a65c-eb48f0cab60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97a17ad0-9aa0-42a3-b601-1a3fa011fe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim, TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf89ee1-f0f4-4646-a353-c61210c5697c",
   "metadata": {},
   "source": [
    "It is important to note that tensors can REPRESENT almost anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e006b20-0bd2-416a-b59f-b05f49f3122e",
   "metadata": {},
   "source": [
    "Now since there are 3 brackets on the outside, we can say that this is a rank-3 tensor. The torch.size can be easily explained by thinking of it as a series of bulletpoints\n",
    "\n",
    "1. - First outer bracket has one element which is the entire table. \n",
    "2. - Second middle bracket has three elements or three rows - this refers to the apostrophes.\n",
    "3. - Last inner bracket has three elements inside it - this refers to the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde9e2f-24c4-4e9f-8a98-887df26b859b",
   "metadata": {},
   "source": [
    "**NOTE:** Notice how the scalars and vectors are lowercased while the MATRIX and TENSORS are uppercase? This is so one can easily denote the sizes. The same practice is applied for letter variable names scalars and vectors can be 'a' / 'b' while MATRIX and TENSORS can be 'X / 'Y'.\n",
    "\n",
    "At the same time, MATRIX and TENSORS can be used interchangeably. What's important is recognizing the shape and rank of the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745eac2-9d43-40cd-b3eb-f8fb82a51fd6",
   "metadata": {},
   "source": [
    "In other words, a scalar is one number - vectors are arrays - matrices are 2D arrays - tensors are multidimensional arrays. While matrices and tensors can be used interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e92314-7981-4906-9600-95f16e1d8cff",
   "metadata": {},
   "source": [
    "**RANDOM TENSORS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca60a0-d356-4541-9339-1068ac7309e4",
   "metadata": {},
   "source": [
    "Tensors are representations of some form of data. Machine learning models try to seek and recognize patterns within these tensors. However, in the real world, you'll often find that you don't actually make tensors manually. \n",
    "\n",
    "Machine learning models actually start out with randomized weights, or basically randomly generated values. Then they adjust these values as they try to work through the data so that it can finally recognize it. \n",
    "\n",
    "In essence: \n",
    "\n",
    "start with random numbers -> analyze data -> update random numbers -> .... stop\n",
    "\n",
    "This process can be split into initialization (starting with random data), representation (analyzes data), and optimization (updating data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f011fa-1b82-43c7-97de-d9b27d58d010",
   "metadata": {},
   "source": [
    "Let's create a tensor with random values using torch.rand(). This is a PyTorch function readily available to use. We pass a size parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ac6bb20-f359-4c66-b27e-74038339dbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6073, 0.7951, 0.7115, 0.7323],\n",
       "         [0.9058, 0.4945, 0.7131, 0.0901],\n",
       "         [0.1513, 0.3903, 0.9654, 0.6571]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_TENSOR = torch.rand(size=(3,4))\n",
    "random_TENSOR, random_TENSOR.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37038e7-2589-4935-ac98-eff7529f53ec",
   "metadata": {},
   "source": [
    "Notice how it created a rank-2 tensor with a 3 elements tall and 4 elements wide. Let's try making it into a rank-3 tensor. Let's see what happens then. We added in .dtype to show what the type the values are. We can see that these are floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "980fd66b-8cde-409b-a56c-386a16ebc264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1578, 0.0352, 0.6950, 0.3020],\n",
       "          [0.0110, 0.4866, 0.4896, 0.2532],\n",
       "          [0.5094, 0.7880, 0.7868, 0.8477]],\n",
       " \n",
       "         [[0.4499, 0.9702, 0.2452, 0.6330],\n",
       "          [0.5993, 0.7212, 0.3038, 0.9270],\n",
       "          [0.5676, 0.0656, 0.6930, 0.8717]]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_random_TENSOR = torch.rand(size=(2,3,4))\n",
    "big_random_TENSOR, big_random_TENSOR.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6cace8e-aeb9-4c7e-8e51-6fdf0f9c743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_random_TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f68c7e-9007-4518-b002-781cf42a2b14",
   "metadata": {},
   "source": [
    "That's big! We've created a rank-3 tensor with shape (2, 3, 4). You can also think of reading shapes [2,3,4] as this ->\n",
    "* This means it has two rank-2 tensors along the first dimension (axis 0).\n",
    "* Each of these rank-2 tensors has three rank-1 tensors (vectors) along the second dimension (axis 1).\n",
    " * And each rank-1 tensor (vector) contains four scalars (rank-0 tensors) along the third dimension (axis 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1608b6-0583-4af0-9828-c2204ca50f98",
   "metadata": {},
   "source": [
    "Now, let's imagine that we want to create a 224x224 image that is also RGB! How do we go about making this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0778deb0-3ee0-4243-bb1e-84e4929d77bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969dbe7f-51c4-47ac-9306-c604b460f04c",
   "metadata": {},
   "source": [
    "Here, we've got 224 for our height, 224 for our width, and 3 for Red, Blue, Green! We can think of tensors as arrays in a sense. Reason we didn't visualize this is because it's a bit too large. So there's really no need to see it all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60f662-b65e-489d-9f92-0e9b653fb905",
   "metadata": {},
   "source": [
    "**Zeros & Ones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45685c3-de44-41db-9d04-39f820f34b08",
   "metadata": {},
   "source": [
    "What if we don't want to fill our tensors with random values? Luckily, we can do that by using .zeros and .ones as these are available as well from PyTorch. This is helpful for masking. What is masking? It is used as a signal for the model not to learn specific values, in this case zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49f431c2-d44a-43ab-86db-2169d22bd6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "298e33be-33f3-46d0-b8f1-f6e3a267795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3,4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a03d2d-6df1-415e-926d-bebcfdbadc5d",
   "metadata": {},
   "source": [
    "**Creating a Range & Tensors Like**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbe8f7-d3e6-4e7b-af00-c358bac9ce3f",
   "metadata": {},
   "source": [
    "How about if we want a range of numbers instead? Like from 0 - 10 or 0 - 100. We can use *torch.arrange(start, end, step)* to do that. Pretty simple, start means where we want to initialize, end is where we want to stop, and step is how many steps in-between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae05af20-7f8e-4298-8b78-205e0acf5f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(0,10,1)\n",
    "zero_to_ten, zero_to_ten.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d947dfd-fdc0-4f10-8320-7fb52441c55d",
   "metadata": {},
   "source": [
    "Notice that our type is now integers because we specified only integers in our range. If we add decimal values, it'll switch back to floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca7b25-ba71-4b16-8258-b6973796cd19",
   "metadata": {},
   "source": [
    "Sometimes, you want to create another tensor based off another but instead with all zeros or ones. You can do this by utilizing *torch.zeros_like(input)* or *torch.ones_like(input)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b6881da-72c7-4f54-9abf-24bf3ce99137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(zero_to_ten)\n",
    "ten_zeros, ten_zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19a36aed-a42b-402f-8929-88ee1c6206b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(zero_to_ten)\n",
    "ten_zeros, ten_zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21f841-b614-4c5e-a54d-43be0eaacd94",
   "metadata": {},
   "source": [
    "**Tensor Datatypes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1971731b-e917-4820-99f1-5f53cf4b417e",
   "metadata": {},
   "source": [
    "There are many different tensor datatypes. Some are good to use for the CPU and some are better with the GPU.\n",
    "\n",
    "Tensors that have *torch.cuda* generally means that these are for the GPU to use. However, the most common datatype and generaly used is *torch.float32* or *torch.float*. These are called \"32-bit floating points\".\n",
    "\n",
    "But there are also 16-bit floating points such as *torch.float16* / *torch.half* and even 64-bit floating points *torch.float64* / *torch.double*. But that's not all, there's even 8-bit, 16-bit, 32-bit, 64-bit integers! And many more. \n",
    "\n",
    "The reason that we have so many datatypes is because tensors are made to accomodate for a wide range of data and thus these are important for precision in computing. Precision is the amount of detail used to describe a number. The higher the precision value means the more detail and more data can be used to express a number. \n",
    "\n",
    "This is important for deep learning because you are dealing with a lot of operations. So more detail means more compute power is needed. When it comes to lower precision datatypes, it is typically quicker and costs less in terms of computational power that is needed but this is in exchange for evaluation performance on metrics such as accuracy.\n",
    "\n",
    "More Detail -> Costlier Compute Power -> Better Metrics | Less Detail - Affordable Compute Power -> Worse Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9680ee-dc41-449a-a796-f512aed81c00",
   "metadata": {},
   "source": [
    "Let's practice with utilizing datatypes. We can specify this using the dtype parameter when creating tensors. \n",
    "Usually, the default datatype for tensors is float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bc50753-940c-4619-ae76-88893ae307d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([3]), torch.float32, device(type='cpu'), False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                              dtype=None, #Default is None -> Float32\n",
    "                              device=None, #Default is None -> Tensor Type (eg. CUDA, CPU))\n",
    "                              requires_grad=False #If true, operations performed on the tensor are recorded\n",
    "                              )\n",
    "float_32_tensor.ndim, float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device, float_32_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7bb5c-bdb1-47a0-b289-000f02d7844e",
   "metadata": {},
   "source": [
    "Here we can see a lot of information regarding our tensor. It tells us that it is of rank-1, is comprised of three elements, is a float, and is meant for a cpu, and is not required to be recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d8ff9-c57a-481b-9cf7-f06ae8ae6ca8",
   "metadata": {},
   "source": [
    "Aside from the shape issues (meaning that two tensors are not the exact shape) two of the most common problems to encounter is datatype and device issues. For example, one tensor is of *torch.float32* while the other is of *torch.float16*. Same issue goes for device. If one tensor is a cpu type while the other is a gpu type then that could cause some issues.\n",
    "\n",
    "**PyTorch loves it when two tensors have the same format and calculations are used on the same device.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f82de-9873-4f58-a9a7-325ec34fe291",
   "metadata": {},
   "source": [
    "Let's make a tensor with *dtype=torch.float16*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e9e7512-1422-4af6-acb0-0df8a1addad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfb38158-af8c-4786-8832-4467d25a7363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([3]), torch.float32, device(type='cpu'), False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.ndim, float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device, float_32_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78478719-8dc2-45a2-828d-ea58e218175d",
   "metadata": {},
   "source": [
    "**Getting Information From Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b559433-6e6b-49b4-b749-536d366f1cbb",
   "metadata": {},
   "source": [
    "Once you've created tensors are are working with them then it is very helpful to know how to navigate through the information that they can provide. We've already used the following:\n",
    "\n",
    "1. Shape - what is the shape of a tensor?\n",
    "2. dtype - what datatype are the elements within the tensor?\n",
    "3. device - what device is it stored on - cpu or gpu?\n",
    "\n",
    "Let's make a random tensor and try to get information from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e004ada-69ac-4dd7-983a-186b8aa8348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3347, 0.1443, 0.4272, 0.3633],\n",
      "        [0.6514, 0.4040, 0.2347, 0.7513],\n",
      "        [0.6260, 0.1857, 0.2867, 0.1479]])\n",
      "Shape of Tensor: torch.Size([3, 4])\n",
      "Datatype of Tensor: torch.float32\n",
      "Device Tensor is Stored: cpu\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor)\n",
    "print(f\"Shape of Tensor: {random_tensor.shape}\")\n",
    "print(f\"Datatype of Tensor: {random_tensor.dtype}\")\n",
    "print(f\"Device Tensor is Stored: {random_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814f9b0-6c82-4f62-87f3-3f34ecd915c8",
   "metadata": {},
   "source": [
    "Whenever you run into issues with operating with tensors, it's best to review through the tensors themselves and check the very basics of information regarding them. You might discover that something is wrong with the how they are structured. \n",
    "\n",
    "The three big questions - WHAT? WHAT? WHERE? will help you in troubleshooting errors:\n",
    "\n",
    "1. What shape are my tensors?\n",
    "2. What datatype are they?\n",
    "3. Where are they stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77c710-55ca-46ed-91d8-446c7c4c7dfd",
   "metadata": {},
   "source": [
    "**Manipulating Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07081d0-dde5-4e0c-b457-b1b6342895b9",
   "metadata": {},
   "source": [
    "In deep learning, almost all the data that you work with will be represented as tensors. This can range from images, videos, text, audio, protein structures, etc. Models are able to learn simply by investigating these tensors and performing a series of operations on tensors to create a representation of the patters of the data that you are working on. These operations that are performed on the tensors could range in the millions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca18d9-18ac-4e07-9c00-b4b88e583254",
   "metadata": {},
   "source": [
    "Now, don't get all worked up because the operations are not that complex. It's all just the following:\n",
    "\n",
    "1. Addition\n",
    "2. Subtraction\n",
    "3. Multiplication (element-wise)\n",
    "4. Division\n",
    "5. Matrix Multiplication (The GOAT of Deep Learning)\n",
    "\n",
    "*GOAT - Greatest of All Time*\n",
    "\n",
    "That's basically it. Now, THERE are others but these are the majority of it and the basic building blocks of neural networks. Working with these building blocks properly will give you very sophisticated neural networks that can handle complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b48d1-99a2-4218-b5c5-6f703783f262",
   "metadata": {},
   "source": [
    "**BASIC OPERATIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97eb11-8044-425c-8962-8720d20510e0",
   "metadata": {},
   "source": [
    "Let's work with the fundamentals first. Addition, Subtraction, and Multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40f42c74-dd9c-4e8f-a5d5-fedec604f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25ffefe7-9410-476d-92e7-19604bdccbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d47f93-1b7d-42b4-944b-48cb6fb900a7",
   "metadata": {},
   "source": [
    "The tensor itself didn't change because we didn't reassign it. So if we did *tensor += 10* then that would've reassigned. Let's do this with subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07983902-2bb3-40fb-91d1-1a87fbc71d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60abb6a0-e8a4-4fdb-a9fb-46c7aba0b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4730a-06eb-4b64-91df-f3df94c11802",
   "metadata": {},
   "source": [
    "PyTorch also has a function called torch.mul() which basically does multiplication. Same goes for addition with torch.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "121c0127-17fa-4e8a-8420-7d6724f1efc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81e0aef3-922c-4a69-a030-2fb8b57ef931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6357f7c0-e450-43e0-9a89-9c272a91cc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still unchanged since we didn't reassign\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfdcb0-5568-4ce8-8f75-aaf6e34cee03",
   "metadata": {},
   "source": [
    "But it's just more convenient to use the operational symbols - * , + , - rather than *torch.mul()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bce43599-81b9-47d4-aa48-74daeaf9abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals:  tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication means that an element would be multiplied to its equivalent on the same index. Index 0 * 0 - Index 1 * 1 .. \n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals: \", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeccec79-e015-4a42-a1bb-11b0815b8697",
   "metadata": {},
   "source": [
    "**Matrix Multiplication**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79331a6-db32-4605-a679-74ffdb4d6947",
   "metadata": {},
   "source": [
    "One of the most common operations that is utilized in machine learning and deep learning algorithms such as neural networks is matrix multiplication. PyTorch implements matrix multiplication through the function *torch.matmul()*. BUT there is also the symbol *@* that is more commonly used when dealing with matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "426c80ce-5237-46a2-bbe4-2ecb9d134550",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3229613160.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[39], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    There are two main rules to remember when dealing with matrix multiplication:\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "There are two main rules to remember when dealing with matrix multiplication:\n",
    "1 - The INNER DIMENSIONS must match: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd9a143c-036a-484d-a18f-9e0d9213b505",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for @: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# WILL NOT WORK\u001b[39;00m\n\u001b[0;32m      2\u001b[0m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m@\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# WILL WORK\u001b[39;00m\n\u001b[0;32m      3\u001b[0m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m# WILL WORK\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for @: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "(3, 2) @ (3, 2) # WILL NOT WORK\n",
    "(2, 3) @ (3, 2) # WILL WORK\n",
    "(3, 2) @ (2, 3) # WILL WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec15a5-fe6f-4907-8043-1813bf70ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. - The resulting matrix will take the shape of the OUTER DIMENSIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd04804-c280-4e85-ba85-dd79c41b2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2, 3) @ (3, 2) -> (2, 2)\n",
    "(3, 2) @ (2, 3) -> (3, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179d4a8-236e-4aae-8133-a719396e15eb",
   "metadata": {},
   "source": [
    "For better visualization of how matrix multiplication works: http://matrixmultiplication.xyz/\n",
    "\n",
    "**NOTE:** ROWS x COLUMNS\n",
    "\n",
    "Let's create a tensor and perform element-wise multiplication first then conduct matrix multiplication on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6612d67b-c4dd-4275-8f99-1fdc670de346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92c5d07e-e558-4264-9a1f-b73e4962a7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1*1, 2*2, 3*3] = [1,4,9]\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b48a5f05-b912-4ae4-9ef9-69d73c69ec4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1*1 + 2*2 + 3*3]\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065b68e-8885-4a25-bc58-be0b132acfc3",
   "metadata": {},
   "source": [
    "Matrix multiplication sums up the value of the elements while element-wise multiplication retains the structure of the tensor's elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50622f-77bb-4762-b255-9f1f5a1aac83",
   "metadata": {},
   "source": [
    "You can do matrix multiplication manually. But it isn't really recommended simply because you would have to utilize for loops. These are computationally expensive. Plus, there's really no need to reinvent the wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78a91448-5f55-492c-873e-5224ed2db8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.44 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d7df519-4340-4e00-9b82-0ca95902f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tensor @ tensor\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f636659-3198-4afc-b964-3f82787fd0ef",
   "metadata": {},
   "source": [
    "**The Common Errors in Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4c36b-9316-4b12-9815-c9cea2ee2c7b",
   "metadata": {},
   "source": [
    "Deep learning is highly involved in multiplying and performing operations with matrices. Operations with matrices have strict rules to follow when it comes to the shapes and sizes of the tensors that are being combined. One of the most common error that you would encounter in deep learning is simply shape mismatch error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5c2c288-75c6-42df-b074-3075f8a649e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor ([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                           [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                           [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor ([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      6\u001b[0m                           [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      7\u001b[0m                           [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtensor_A\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.tensor ([[1,2],\n",
    "                          [3,4],\n",
    "                          [5,6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor ([[7,10],\n",
    "                          [8,11],\n",
    "                          [9,12]], dtype=torch.float32)\n",
    "\n",
    "tensor_A @ tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c1c90-3b30-4b48-8836-e6c45976bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8ff75-b8cf-4704-8e36-a286e7253da5",
   "metadata": {},
   "source": [
    "Notice the error! RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2). Remember our first rule. The INNER DIMENSIONS must match. So 3x2 @ 3x2 gets an error because the inner dimensions are different. \n",
    "\n",
    "We can make this work by simply making the inner dimensions match. One way we can do this is by using transpose. This switches the dimensions of a given tensor so a 3x2 would become a 2x3.\n",
    "\n",
    "We can perform transpose using PyTorch by:\n",
    "*torch.transpose(input, dim0, dim1)* - where input is the tensor to be transposed and dim0 / dim1 would be the dimensions to be swapped.\n",
    "*tensor.T* - where the *tensor* is the desired tensor to be transposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69a0a5-8e9d-4902-8047-f09effc598b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068dfe6-788c-4586-9d61-349ff274fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4a694-d239-4ee1-b089-424a07b80fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A.shape, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c193ed46-4d91-451a-8a69-329ebf9f171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "As we can see they are now both the same shape while also retaining the data inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbadc35b-b706-40ee-a15f-5f2f7ac5b5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 27.,  30.,  33.],\n",
       "         [ 61.,  68.,  75.],\n",
       "         [ 95., 106., 117.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tensor_A @ tensor_B.T\n",
    "output, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b214ed-ef57-4138-87ed-3d6efcb1d251",
   "metadata": {},
   "source": [
    "Here is where our 2nd rule comes into play. The resulting tensor will take the shape of the OUTER DIMENSIONS. So now our tensor is shaped at [3,3]. How about if one of the outer tensors is different in shape? Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d670fd23-1811-4e63-9dc3-3e26a9e881e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor ([[1,2],\n",
    "                          [3,4],\n",
    "                          [5,6],\n",
    "                         [14,15]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor ([[7,10],\n",
    "                          [8,11],\n",
    "                          [9,12]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4539908e-21ad-46df-9362-08980d185f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "715d500b-486e-447f-8b9f-ad8391a8d8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 27.,  30.,  33.],\n",
       "         [ 61.,  68.,  75.],\n",
       "         [ 95., 106., 117.],\n",
       "         [248., 277., 306.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tensor_A @ tensor_B.T\n",
    "output, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d2934-2e14-4255-8009-42f5e81f9ba4",
   "metadata": {},
   "source": [
    "We can see that our outer dimension is now 4 because that is the outer dimension of the first tensor. The inner dimension is now 3 becuase that is the outer dimension of the second tensor. Basically, we took the outer dimensions of the original tensors and that would be the shape of the resulting tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5954fb-6169-4a36-8b39-5a190f682326",
   "metadata": {},
   "source": [
    "Transposing is vital to ensure operations are able to go smoothly between tensors with different shapes. \n",
    "\n",
    "**NOTE:** The individual elements of the resulting matrix from matrix multiplication are calculated as the dot products of rows from the first matrix with columns from the second matrix.\n",
    "\n",
    "Neural networks are filled with matrix multiplications and dot products. The *torch.nn.Linear* module (to be seen later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input (x) and a weighst matrix (A).\n",
    "\n",
    "y = x * A^T + b\n",
    "\n",
    "That sounds rough but basically:\n",
    "\n",
    "x - is the input layer (deep learning is a stack of layers like *torch.nn.Linear* and others on top of each other).\n",
    "A - is the weights matrix created by the layer. This starts out as random values that gets adjusted as a neural networks start to recognize patterns in the data. The \"T\" means that the weights matrix is transposed. - NOTE: that the \"A\" is sometimes referred to as \"W\".\n",
    "b - is the bias term used to slightly offset the weights and inputs. \n",
    "y - is the output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951f69-410c-4f13-a926-7022ac4df8c6",
   "metadata": {},
   "source": [
    "That is the formula for a linear function or a straight line! Let's play around with linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cf2805f-47ee-45d2-8869-f0b1b348abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[ 3.8298,  6.8288, -3.2636],\n",
      "        [ 4.0394,  7.6523, -3.8208],\n",
      "        [ 4.2491,  8.4757, -4.3781]], grad_fn=<AddmmBackward0>)\n",
      "Output Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Since linear layers start with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(45)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, #in_features = matches inner dimensions of input\n",
    "                        out_features=3) #out_features = describes outer value\n",
    "\n",
    "x = tensor_B\n",
    "output = linear(x)\n",
    "print(f\"Input Shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\nOutput Shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb01f8-2fc1-487a-8c4a-155bbfa6db02",
   "metadata": {},
   "source": [
    "Basically, The in_features should match the second dimension (number of columns) of the input tensor. The out_features determines the second dimension (number of columns) of the output tensor after the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3fb62-767c-41b9-a0df-a2f145c67c60",
   "metadata": {},
   "source": [
    "**REMEMBER MATRIX MULTIPLICATION IS ALL YOU NEED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537602a4-c6af-43f5-9446-c8cd7343f398",
   "metadata": {},
   "source": [
    "**Finding the Min, Max, Mean, Sum, etc. - Aggregation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f8206-3851-4986-b478-2b2629afb018",
   "metadata": {},
   "source": [
    "Now that we're finished with manipulating tensors and conductiing operations. Let's talk about aggregating them - going from many values to less values. First, let's make a tensor and find the max, min, mean, and sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6c6e921-cf40-428a-ae52-647b2629769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.Size([10]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e54260c-c274-4ff4-a842-d0265d671d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0\n",
      "min: 90\n",
      "mean: 45.0\n",
      "sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"min: {x.min()}\")\n",
    "print(f\"min: {x.max()}\")\n",
    "print(f\"mean: {x.type(torch.float32).mean()}\") # Mean won't work without floats. So there is a need to convert first from int to float.\n",
    "print(f\"sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048f3c1-8e04-458b-904f-a21b0192ace4",
   "metadata": {},
   "source": [
    "The same can be done with torch methods such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85016685-346a-4caa-be49-28baaacba4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ea6da-0835-4797-97aa-f4b911d58848",
   "metadata": {},
   "source": [
    "**Positional Min/Max**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ad5b9-0bb4-4500-ab7f-461de614bfdd",
   "metadata": {},
   "source": [
    "You can also find the index of the max value in a tensor. The same can also be done for the minimum value using *torch.argmax()* and *torch.argmin()*. This is a great way to check the position of a max/min value of a tensor without needing the actual value itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5921d8eb-9459-45d3-b65a-422a43dbd660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Tensor - Max Value Index: 8\n",
      "Tensor - Min Value Index: 0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "print(tensor)\n",
    "print(f\"Tensor - Max Value Index: {torch.argmax(tensor)}\")\n",
    "print(f\"Tensor - Min Value Index: {torch.argmin(tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5496ab-baf2-4323-8818-03ca6cd3feca",
   "metadata": {},
   "source": [
    "**Change Tensor Datatype**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bbbd7-8a30-48dc-a30a-4de6f51814db",
   "metadata": {},
   "source": [
    "As mentioned before, one of the most common issues that people face when working with tensors is tensors that differ in datatypes. If one tensor is *torch.float32* and another is *float16* and you try to do some operations together with these then you might run into some error.\n",
    "\n",
    "Luckily, PyTorch gives you the means to check the datatype easily and change it using *torch.Tensor.type(dtype=None)* where the dtype parameter is the datatype that you want to use.\n",
    "\n",
    "Let's create a tensor and check it's datatype first. - default is *torch.float32*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1de2fba-667d-4125-8178-6bad695f60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.]), torch.float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535d247-abfa-47cf-a288-e2ce783bbee3",
   "metadata": {},
   "source": [
    "Let's change this into a *torch.float16* or a *torch.half*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "955e458e-6041-47a7-ad82-5ea5cbe7ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb23a12-9de7-4284-89ea-ebbc5856c37d",
   "metadata": {},
   "source": [
    "We can also do the same process for *torch.int*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59638566-1b20-47af-8a94-ca379bacf2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab28cb-388f-4bbe-bdb5-8690f5826004",
   "metadata": {},
   "source": [
    "Easiest way to go through datatypes is that if the higher the value the more precise it can be but the higher the cost for processing power. If the value is lower then it is less precise but a lot easier when it comes to the demand for processing power. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa40aad-1ac0-43bc-8133-d2d17af9f7db",
   "metadata": {},
   "source": [
    "**Reshaping, Stacking, Squeezing, Unsqueezing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a21177-9779-4f2c-9ac3-58994898a5d5",
   "metadata": {},
   "source": [
    "One of the more important means of manipulating tensors is through their shapes. We need to actively change or reshpae the dimensions without actually touching the values and data inside them. Here are the following methods that are available in PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e8a05-3fe8-49e2-9b1c-69a710934995",
   "metadata": {},
   "source": [
    "1. *torch.reshape(input, shape)* -> Reshapes *input* to *shape* (if compatible). Is also available in *torch.Tensor.reshape()*\n",
    "2. *tensor.view(shape)* -> Returns a view of the original tensor in a different *shape* but shares the same data as the original tensor.\n",
    "3. *torch.stack(tensors, dim=0)* -> Concatenates a sequence of tensors along a new dimension(*dim*). All tensors must be the same shape.\n",
    "4. *torch.squeeze(input)* -> Squeezes the *input* tensor by removing all the dimensions with the value 1.\n",
    "5. *torch.unsqueeze(input, dim)* -> Returs input with a dimension value of 1 added to dim.\n",
    "6. *torch.permute(input, dim)* -> Returns a view of the original input with its dimensions permuted (rearranged) to dims."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b01ab-5c0a-4db4-b134-1192abd8795f",
   "metadata": {},
   "source": [
    "Why bother with all these different methods? That's because in deep learning models, it's all about manipulating tensors in some way. Due to the strict rules of matrix multiplication, we need to be able to shape our data that can fit these rules so that we can operate them. For example, if we have shape mismatches, we'll run into errors. These methods are there for us to modify our tensors so that they can be used with each other. \n",
    "\n",
    "Let's try these methods out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60579937-ae65-47b0-acdb-f7f3cf54506e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
       "         15., 16., 17., 18., 19., 20.]),\n",
       " torch.Size([20]),\n",
       " 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 21.)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8c773-947e-4904-9e26-bd861b7eb53b",
   "metadata": {},
   "source": [
    "We'll work with adding another dimension using *torch.reshape()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b0576ba-be36-454a-ab71-01ec8f84ec55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [11., 12., 13., 14., 15., 16., 17., 18., 19., 20.]]),\n",
       " torch.Size([2, 10]),\n",
       " 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(2,10)\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee92c95-bdbf-453c-bbf5-a73f1ade7f9f",
   "metadata": {},
   "source": [
    "Notice that we now hav an extra outer bracket. Our size has also increased to adding one more dimension. When doing reshape, it's important to always remember that the resulting shape would be the same value as the input size. \n",
    "\n",
    "So originally we had [20] now we've split that up to [2,10] if you multiply 2-10 that would be 20 so it will fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b963c61b-aba6-4b28-a83e-9f16c022632a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 5]' is invalid for input of size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_reshaped_try \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m x_reshaped_try, x_reshaped_try\u001b[38;5;241m.\u001b[39mshape, x_reshaped_try\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 5]' is invalid for input of size 20"
     ]
    }
   ],
   "source": [
    "x_reshaped_try = x.reshape(1,5)\n",
    "x_reshaped_try, x_reshaped_try.shape, x_reshaped_try.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d19a9c3a-8ac8-48f2-9e3c-61edb5279e62",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 5]' is invalid for input of size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_reshaped_try \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m x_reshaped_try, x_reshaped_try\u001b[38;5;241m.\u001b[39mshape, x_reshaped_try\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 5]' is invalid for input of size 7"
     ]
    }
   ],
   "source": [
    "x_reshaped_try = x.reshape(1,5)\n",
    "x_reshaped_try, x_reshaped_try.shape, x_reshaped_try.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796013e6-51ae-4fbf-8681-9d7f875ec916",
   "metadata": {},
   "source": [
    "Now let's proceed with working on *torch.view()*. This will change the shape but retain the origin data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49d1560d-bb3e-49de-bd9e-cb80899fb3cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 7]' is invalid for input of size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m z, z\u001b[38;5;241m.\u001b[39mshape, z\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 7]' is invalid for input of size 20"
     ]
    }
   ],
   "source": [
    "z = x.view(1,7)\n",
    "z, z.shape, z.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae59b2-856e-4b2e-9332-f1f6ccdf8a00",
   "metadata": {},
   "source": [
    "Remember that changing the view of a tensor with torch.view() ONLY creates a new view of the SAME tensor. If we change the view, we would also be changing the original tensor. So these two are connected. Imagine it as wearing a pair of shades. The color of the data might change but you're still looking at the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63155b1e-958b-47b1-b3ea-dddded5be8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e415ab-8c8a-49ee-8c06-73fe5cef253c",
   "metadata": {},
   "source": [
    "See, they're the exact same even if you did the operation on z. It still changed x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb994d-22ec-420e-80b4-3111d7cd4fc1",
   "metadata": {},
   "source": [
    "If we want to make a tensor stack on top of itself repeatedly, we can do that with *torch.stack()*. This is great because you are able to  combine tensors that have the same layout into one. For example, images. We can stack images on top of each other with each row representing the pixel values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a351e48-6b6e-43d6-846b-518dcf0923d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.]]),\n",
       " torch.Size([4, 7]),\n",
       " 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim=0) # Play around with dim. Switch it to 1 and check what happens.\n",
    "x_stacked, x_stacked.shape, x_stacked.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "794b69e5-177b-44a4-a874-cde6f7500611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7.]]),\n",
       " torch.Size([7, 4]),\n",
       " 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim=1)\n",
    "x_stacked, x_stacked.shape, x_stacked.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d26b8-f0f4-43b7-8434-d6ef53ac7c21",
   "metadata": {},
   "source": [
    "Notice where the '4' is placed whenever we move dimensions. Also take note that the '4' comes from the number of tensors that we've stacked. If we go back to *torch.stack()* we placed four 'x' tensors into the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d3f4f-413f-41df-8554-78bc38911a5c",
   "metadata": {},
   "source": [
    "Let's try removing dimensions from a tensor. *torch.squeeze()* is a function that we can use to d exactly that. This will remove all single dimensions from a tensor. So dimensions that have 1 will all be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5f6905c-3a07-4e4a-8ea4-d5591b57e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous Shape: torch.Size([1, 7])\n",
      "\n",
      "New Tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New Shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous Tensor: {x_reshaped}\")\n",
    "print(f\"Previous Shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Removes extra dimensions from x_reshaped\n",
    "\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew Tensor: {x_squeezed}\")\n",
    "print(f\"New Shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ecb30-0712-496c-ba99-b847047fb212",
   "metadata": {},
   "source": [
    "Notice how the dimensions that have only 1 on it got removed? That will happen to all of them when squeeze is done. There is also an opposite for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc4e7a-96a7-4de7-b179-b8b4e06b928d",
   "metadata": {},
   "source": [
    "*torch.unsqueeze(dim=0)* does the exact opposite by adding in dimension at the value of 1 at a specified index. It's not exactly the opposite of squeeze since this only adds in single dimension at the value of 1 and you also have to specify the index for it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2daddad6-0860-4591-9ff2-824561fab775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous Shape: torch.Size([7])\n",
      "\n",
      "New Tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New Shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous Tensor: {x_squeezed}\")\n",
    "print(f\"Previous Shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Removes extra dimensions from x_reshaped\n",
    "\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew Tensor: {x_unsqueezed}\")\n",
    "print(f\"New Shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15524a8e-adda-4f37-b584-181800f4c3c8",
   "metadata": {},
   "source": [
    "There's also a function that we can use to rearrange the order of axes values using *torch.permute(input, dims)* where the input gets turned into a *view* with the new dimensions.\n",
    "\n",
    "**NOTE:** Let's remind ourselves of terminologies again before getting started. Axes is the indexing of the dimensions so using our previous example of *torch.Size([1,7])*. The 1 would be the 0-axis and the 7 would the 1-axis. Also remember that *view* means that it is just a different perspective of the data so it it still connected to the original variable where the data is stored.\n",
    "\n",
    "So if *torch.view* changes the shape of the dimensions, this changes the order of the dimensions but both still retain a connection to the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29d4f95c-ea1b-4570-8127-9724e45a273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Shape: torch.Size([224, 224, 3])\n",
      "New Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x_original = torch.rand(size=(224,224,3))\n",
    "x_permuted = x_original.permute(2, 0, 1) \n",
    "\n",
    "print(f\"Previous Shape: {x_original.shape}\")\n",
    "print(f\"New Shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea9f33-89f4-4655-bc08-6933bcc53902",
   "metadata": {},
   "source": [
    "In our permute function we specified (2,0,1). This means the following:\n",
    "\n",
    "We moved the 2-axis of the original to the 0-axis of the new\n",
    "We moved the 0-axis of the original to the 1-axis of the new\n",
    "We moved the 1-axis of the original to the 2-axis of the new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a145a-b472-4ec9-8fab-7972d00f8321",
   "metadata": {},
   "source": [
    "**Indexing - Selecting Data From Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a7225-6cfd-4477-bf17-e3dbca52dbd6",
   "metadata": {},
   "source": [
    "Sometimes, we need to select specific data from our tensors. For example, we might need the data from this specific row of this specific column. Luckily, we can approach this as we approach regular lists and arrays - which is indexing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1c5fed00-a07a-4259-bec3-f37c5e01b4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65e49039-ac50-4ccc-8026-9f33d12608ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623e221-f6a5-4473-8a1c-49b7116bcab7",
   "metadata": {},
   "source": [
    "Indexing starts at the outer dimension -> inner dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "905d505c-4aac-495d-af9a-c1dd029ae81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Square Bracket: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second Square Bracket: tensor([1, 2, 3])\n",
      "Third Square Bracket: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Square Bracket: \\n{x[0]}\")\n",
    "print(f\"Second Square Bracket: {x[0][0]}\")\n",
    "print(f\"Third Square Bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1f278-23d5-4755-b357-7eee16f0fc44",
   "metadata": {},
   "source": [
    "That's not all, we can also use : to *specify all the values in this dimension*. We can then also use a comma , to add another dimension. Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "784838e6-e7b5-4875-99ef-4453cda8f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0] # We grab all the values in the 0th dimension and the index of the 0 index of the 1st dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8549c8ae-c7f8-4591-97de-8083acadda29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 1] # We get all the values of the of the 0th & 1st dimensions but only index 1 of the 2nd dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1bdbd45-b99d-40a6-9253-6d20fd88f631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1, 1] # We get all the values of the 0th dimension but only index 1 of the 1st & 2nd dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6a59578-c7b1-44e6-9f14-1338a25fb89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :] # We grab the 0-index of the 0th & 2nd dimension then we get all the values of the 2nd dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545a376-9242-4343-b64d-8e3194a15e59",
   "metadata": {},
   "source": [
    "Don't worry if you get a bit confused when dealing with indexing. Especially with large tensors as it can really get confusing. But! Luckily, there's no cost in experimenting around and deducing the location of the data that you're trying to find. Keep practicing and follow the pattern of VISUALIZE! VISUALIZE! VISUALIZE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d3525-887a-4918-81d3-78c870f102d4",
   "metadata": {},
   "source": [
    "**PyTorch Tensors & NumPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6609daa-e8d6-4bce-81d3-78c630da3afb",
   "metadata": {},
   "source": [
    "PyTorch tensors and NumPy arrays are pretty similiar in a lot ways but PyTorch tensors have the added strength of utilizing CUDA which makes it a lot faster.\n",
    "\n",
    "NumPy is widely adopted because one of it's strengths is being able to visualize and graph data. So it's no wonder why PyTorch have functionalities that allow it to interact with NumPy and vice versa. \n",
    "\n",
    "There are two main ways that we use to interact with these two different libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40882a23-d87b-4ea8-99f0-8243124628c4",
   "metadata": {},
   "source": [
    "1. *torch.from_numpy(ndarray)* - NumPy array converts to PyTorch tensor.\n",
    "2. *torch.Tensor.numpy()* - PyTorch tensor converts to NumPy array.\n",
    "\n",
    "Let's try using these in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "10ae5927-d12d-44eb-b0ee-6df86b05bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NumPy Array to PyTorch Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e658fe7e-2f4a-41cc-9577-7fb1e8d9c1df",
   "metadata": {},
   "source": [
    "Notice that np also uses the arange function which is what we also use for PyTorch. NumPy arrays have the default datatype of float64 which is different from what PyTorch's default flaot32 - but there are always means of converting these.\n",
    "\n",
    "Here's an example of converting from NumPy array to PyTorch tensor while also changing the datatype to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e9ee1dfa-8a16-4e4d-8503-ddebfc131037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd954f-3f3d-4e4c-97a6-be26dd27c5bd",
   "metadata": {},
   "source": [
    "Since we reassigned the tensor, even if we change the tensor, our array would stay the same and vice-versa. There's no connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a1513d0e-1431-4077-a6c4-fec4289e75ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc6f211-30e6-48be-bd70-d56a308980a5",
   "metadata": {},
   "source": [
    "If we want to convert our PyTorch tensors to NumPy array - we use tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c7eb2d64-e8e5-4440-8b99-57e4d5364f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(7) # This creates a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # Will retain the datatype unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d92ce-89a2-43ef-88db-e9cdef024dbd",
   "metadata": {},
   "source": [
    "**Reproducability** - Removing The Random From Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4ee91-5ca7-4510-967b-ea2eab9cd68b",
   "metadata": {},
   "source": [
    "Deep learning revolves a lot around randomness, especially when initializing parameters/weights. However, there's a lot of different types of 'randomness'\n",
    "\n",
    "As mentioned before, neural networks start off with random weights which are very poor descriptions of the data. But we calculate these and adjust them to better represent the data. So recall the steps:\n",
    "\n",
    "start with random weights -> perform tensor operations on the weights -> update the weights -> repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f181b5-b491-4ccf-a706-bafd2fd742e9",
   "metadata": {},
   "source": [
    "So randomess is important since we start from there but sometimes, it's better to have the option of having a certain type of random. Not too random but 'just right' enough to do experiments with. It's not really effective to determine something is going well if the results you get is always widely different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad15ab-8872-44b8-80fd-ef6fd81fad4f",
   "metadata": {},
   "source": [
    "For example, you've created an algorithm that is capable of executing a certain operation at X performance. You need someone else to verify that this isn't just a coincidence. That is where *reproducability* starts to come into the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18f97b-c046-404f-81d3-6b3fbc411a5a",
   "metadata": {},
   "source": [
    "You both get similiar, not exactly the same but not too far apart results that is executed on two different machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f52a4-57bd-4943-b9f0-210280b61406",
   "metadata": {},
   "source": [
    "Let's try executing reproducability in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3d06a2c0-93f9-4a79-b03b-ea68ef9ebf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: \n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "\n",
      "Tensor B: \n",
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
      "\n",
      "Is Tensor A == Tensor B? - in any value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(f\"Tensor A: \\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B: \\n{random_tensor_B}\\n\")\n",
    "print(f\"Is Tensor A == Tensor B? - in any value\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642aa236-f728-469e-97d5-36029a5775c6",
   "metadata": {},
   "source": [
    "It's way too random! Values are just getting crazy and the chances that you'll get something similiar is very rare. But what if you wanted to create two random tensors that have the same values? They'll be still randomly generated but they would share the same values regardless.\n",
    "\n",
    "Thankfully, *we have torch.manual_seed(seed)*. This is a function that we can use to solve that exact problem. *seed* is an integer that we can specify the randomess that we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "10e1fec5-cd8c-41a8-932b-5816d2dc38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C: \n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D: \n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Is Tensor C == Tensor D? - in any value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random_seed = 42\n",
    "torch.manual_seed(seed=random_seed)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(seed=random_seed)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "print(f\"Tensor C: \\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D: \\n{random_tensor_D}\\n\")\n",
    "print(f\"Is Tensor C == Tensor D? - in any value\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9a0fbf-c79c-4ac1-adcc-e7af892e8047",
   "metadata": {},
   "source": [
    "**NOTE:** When utilizing the GPU. It is important to specify that seed generation with cuda as well. Using *torch.cuda.manual_seed()* to ensure reproducability when dealing with CPU and GPU operations involving randomess.\n",
    "\n",
    "So basically aside just using *torch.manual_seed()* you should also add in *torch.cuda.manual_seed()*. This is so that both CPU and GPU share the same seed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998439bd-40be-477e-977a-cd7630b2ff05",
   "metadata": {},
   "source": [
    "**Getting PyTorch to run on GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21c2e2-a1f6-4897-9381-8779447d3ce0",
   "metadata": {},
   "source": [
    "This is so that we can check whether or not PyTorch has access to our gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4f426a2a-b4f3-4570-98eb-69f5a4e4cbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a653b-842b-42b4-bf6c-86ad7eac9bf6",
   "metadata": {},
   "source": [
    "We create a device variable so that we can check whether we are currently using a gpu or a cpu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f82f40e0-e407-45e9-8a52-f075312ad527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8074357-5708-4623-a6ed-9f5eb12cfea5",
   "metadata": {},
   "source": [
    "Let's count the number of gpus that PyTorch has access to,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7afc9d0a-d415-439f-a64b-058d9d4100c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e927a-055c-4dd7-95b8-18e3a60e9edd",
   "metadata": {},
   "source": [
    "This is important because you can have the option of running one process in one gpu while running another in a different gpu. You can also have all these gpu's work together on one process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7077154-fe0b-45ee-bdca-44beade2dea0",
   "metadata": {},
   "source": [
    "**Putting Tensors & Models on GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f2c2a-803c-43d7-9fb0-f32fd8940a75",
   "metadata": {},
   "source": [
    "We can specify where a tensor is stored by calling *to(device)* wherein device is the target device that we specified earlier. Why is this important?\n",
    "\n",
    "Because GPUs are computationally faster than CPUs and if in the case that the GPU isn't available we can still go back to the CPU because we have covered the case earlier with device checking whether or not we have cuda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be2594-bd0c-407b-806d-59978c4ff09b",
   "metadata": {},
   "source": [
    "Putting a tensor on a GPU using *to(device)* will return a copy of that tensor. So that tensor will be on the CPU and GPU. In order to overwrite tensors, we need to reassign them so do the following:\n",
    "\n",
    "*some_tensor = some_tensor.to(device)*\n",
    "\n",
    "Let's try creating a tensor and put it on the gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "183f81b0-da11-495a-b7b4-6ff58bf22d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "# Tenor is not yet on the GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Tenosr reassigned to a variable in the GPU\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2eee4-54b5-4b71-99d2-6c300c012350",
   "metadata": {},
   "source": [
    "**Moving Tensors Back To CPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eec61e-cf47-495e-8aa0-10525b6965a1",
   "metadata": {},
   "source": [
    "What if we wanted to put our tensor back to the CPU? Firstly, you might think what's the advantage of that? Remember that NumPy arrays are great for visualizing data? \n",
    "\n",
    "One of the things that make PyTorch unique is because it's capacity of utilizing CUDA for matrix multiplication. NumPy can't do that thus it doesn't have access to CUDA. So if you try to convert a tensor from a GPU to NumPy, it won't work.\n",
    "\n",
    "Let's try doing that now and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6b69b79e-9668-40ad-ba30-aef732e4080f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59415def-b765-40bc-98d7-73c1a3aa3888",
   "metadata": {},
   "source": [
    "We've gotta specify first that we put this back to the CPU before we can make this into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c1a6dd89-a3ba-46a6-b51f-21954cf18d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b0619-cf68-4d09-b76b-299a5e1e478f",
   "metadata": {},
   "source": [
    "Remember, that this only creates a copy of the tensor to the CPU. So we still have our original tensor on the GPU. You can think of it now as having two versions in two different devices. These are two seperate objects and have no connection with each other whatsoever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53344bdd-5258-4f44-9775-d7495905899b",
   "metadata": {},
   "source": [
    "**EXERCISES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716064e-31cd-4b14-9027-d0eef22e93d7",
   "metadata": {},
   "source": [
    "Refer to -> https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc8d1a-5f3d-4a2e-abb4-2a984eeb8a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18f6ab-c33d-4bc5-8f68-589af55ae4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
