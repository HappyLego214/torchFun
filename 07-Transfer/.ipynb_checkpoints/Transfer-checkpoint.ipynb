{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d316b4ea-3341-4f3e-8215-ef16aba3da9d",
   "metadata": {},
   "source": [
    "## Transfer Learning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdc28b-e707-489b-b9fc-26e4a4e4bb8c",
   "metadata": {},
   "source": [
    "We are already done with trying to build a couple of different models from basic linear to convolutional models. However, for the majority of the models that we've been making, they've all resulted with poor performances on their prediction power.\n",
    "\n",
    "So, it begs the question - **are there already well-performing models that exist which we can use to solve our problems?**\n",
    "\n",
    "The answer is a big YES!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56036971-7fd4-4cbb-b9a9-cb0e54cd89de",
   "metadata": {},
   "source": [
    "**What is Transfer Learning?**\n",
    "\n",
    "**Transfer Learning** is the process of taking existing patterns (weights) from another model has learned from a different problem which we can also use for our own problem. \n",
    "\n",
    "An example of this would be to take the patterns from a computer vision model that has learned from other datasets such as *ImageNet* - which is a dataset composed of millions of different object images and then use these patterns to power our own model, in our case that would be the FoodVision Mini model that we tried making in the previous chapter. \n",
    "\n",
    "You could also do this for models that focus on Natural Language Processing. You can take the learned patterns from a language model that has gone through large amounts of text representing a certain to language and from there use that as a basis for your model to classify different text samples.\n",
    "\n",
    "The core concept is simple - take well-performing existing models and apply their patterns to your own problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2443d-b03f-46be-ba90-7470ff9d7d4b",
   "metadata": {},
   "source": [
    "![Display](images/07-transfer-learning-example-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09545b36-9a89-4326-95a0-68881a47d34b",
   "metadata": {},
   "source": [
    "**Why Use Transfer Learning?**\n",
    "\n",
    "There are two major reasons why transfer learning is beneficial:\n",
    "\n",
    "1. You can use an already existing model proven to work on a set of problems that are similiar to yours.\n",
    "\n",
    "2. You can use the *learned patterns* from similiar data to your own data. This tends to result in a high predictive power when working with less custom data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a86631-fbcd-427a-8f62-7ad6f4ba5088",
   "metadata": {},
   "source": [
    "![Display](images/07-transfer-learning-for-foodvision-mini.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6558e3-b128-48fe-ae7e-31ed1accbfd4",
   "metadata": {},
   "source": [
    "Professionals have been utilizing transfer learning in practice and this has also been used for research purposes. Overall, it's a well accepted method for improving the predictive power of models. \n",
    "\n",
    "Jeremy Howard who is the founder of *fast.ai* and is one of the bigger names in the machine learning world is a big proponent for transfer learning. In his own words -\n",
    "\n",
    "*'The things that really make a difference (transfer learning), if we can do better at transfer learning, it’s this world changing thing. Suddenly lots more people can do world-class work with less resources and less data. — Jeremy Howard on the Lex Fridman Podcast'*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa3302-6842-462c-98c2-cad0af8cc597",
   "metadata": {},
   "source": [
    "**Where To Get Pretrained Models?**\n",
    "\n",
    "Luckily for you, deep learning is a very open field. Many scholars and professionals share theor work which in turn makes things a lot more accessible for those that have less resources and data to work with.\n",
    "\n",
    "Code and pretrained models from the latest state-of-the-art research is released to the public within a few days after publishing. In addition, you can have easy access to these pretrained models from many different platforms which in turn you can use for your own problems.\n",
    "\n",
    "Let's take a look at a few of these places to get from:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60718003-4cde-4d80-a267-579a5774639a",
   "metadata": {},
   "source": [
    "* **PyTorch Domain Libraries** - Each of the PyTorch domains (torchvision, torchtext) come with pretrained models.\n",
    "\n",
    "* **HuggingFace Hub** - Series of pretrained models on different domains - vision, text, audio, and more. These models come from a range of organizations around the world. Not to mention that there are also many datasets available to use.\n",
    "\n",
    "* **timm - PyTorch Image Models Library** - This is a collection of all PyTorch computer voision models in addition to other computer vision features that you can use to your benefit.\n",
    "\n",
    "* **paperswithcode** - Colllection of the latest state-of-the-art machine learning papers in addition to code implementations of these research papers. You can also see benchmarks of different models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68bdc4-d613-471c-b2f3-7b839118432a",
   "metadata": {},
   "source": [
    "![Display](images/07-transfer-learning-where-to-find-pretrained-models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b7317-f0c4-48af-8e5d-fd5e5b55d953",
   "metadata": {},
   "source": [
    "**Topics To Cover**\n",
    "\n",
    "1. *Setting Up* - Since we've already written the code that we need to work with models, we'll just download them and use them again.\n",
    "\n",
    "2. *Getting Data* - We'll be using the same dataset as before - the pizza, steak, and sushi image classification dataset since we're looking to improve the model's results on this problem.\n",
    "\n",
    "3. *Creating Datasets & DataLoaders* - We've made *data_setup.py* which was a script that we used to make Datasets and DataLoader's and we'll still use them here\n",
    "\n",
    "4. *Get + Customize Pretrained Model* - Choose a pretrained model and download from *torchvision.models* then customize that to address our own problem.\n",
    "\n",
    "5. *Train Model* - Test how the pretrained model works on our dataset. We'll still use the same functions for training in the previous chapter.\n",
    "\n",
    "6. *Evaluate Model Through Plotting Loss Curves* - We'll check the loss curves and see if the model is overfitting or underfitting.\n",
    "\n",
    "7. *Make Predictions* - We'll grab images from the test set and make predictions on them. It's good to see the evaluation metrics and all but it's another to visualize the actual work and results being done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c9685-88d5-40e5-87f2-8c6f04fde240",
   "metadata": {},
   "source": [
    "**Setting Up**\n",
    "\n",
    "As from before, we start with importing/downloading the required modules. We've already made some of the scripts before that we need to train a model so it's good practice to leverage those now. Specifically, we're going to use *data_setup.py*  and *engine.py*. We will also grab the *torchinfo* package so that we can see more in-depth view of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77bbab34-4719-4cf0-88f7-e98c09196604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from scripts import data_setup\n",
    "from scripts import engine\n",
    "from scripts import helper_functions\n",
    "from torchinfo import summary\n",
    "from timeit import default_timer as timer\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import List, Tuple\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d06bea-e83e-4d7f-94f3-784c339a6abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e636fed-f645-4516-ac40-c82ab60cd383",
   "metadata": {},
   "source": [
    "/// Manually Copied Files From 06 - 07 ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c00474-68d9-4bff-bbcd-ee3185628f14",
   "metadata": {},
   "source": [
    "Let's setup the directory paths for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b6a577-8d5b-4b8f-a148-6b3d134bad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/\")\n",
    "image_path = data_path/\"pizza_steak_sushi\"\n",
    "\n",
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24db9f-1c85-4ed6-8ad4-0ffa4894c5d6",
   "metadata": {},
   "source": [
    "**Creating Datasets & DataLoaders**\n",
    "\n",
    "We'll import the modules from *data_setup* to make the Datasets and DataLoaders but before we are able to work with those functions, we'll have to address something very important first. Since we're dealing with a pretrained model from *torchvision.models*, we'll need a specific transform to prepare the images that we have because right now, it won't work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4fa1a-eca6-4a18-84cd-e3d8eb74664e",
   "metadata": {},
   "source": [
    "**Creating Transform For Pretrained Model - Manual Creation**\n",
    "\n",
    "When it comes to dealing with pretrained models, it's important to always make sure the custom data going into the model is compatible and prepared the same way that the original training data went through the model. Everything has to be the same. You can't fit a square in a triangle hole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b3b1e-cb19-4159-b1ed-6a95b9b11d17",
   "metadata": {},
   "source": [
    "Let's list down the transforms that we're going to need to use:\n",
    "\n",
    "1. Mini-batches of size [batch_size, color_channels, height, width] of which height and width are at least 224x224. | Code to use are *torch.vision.transforms.Resize((224,224))* for resizing images and *torch.utils.data.DataLoader()* for creating batches\n",
    "\n",
    "2. We need to make the images into values between 0 & 1. | Code to use is *torchvision.transforms.ToTensor()*\n",
    "\n",
    "3. For the third step, we'll need to get the mean of [0.485, 0.456, 0.406] - this is the values across each color channel. | Code to use is torchvision.transforms.Normalize(mean=...) to adjust the mean of the images.\n",
    "\n",
    "4. Lastly, we'll set a standard deviation of [0.299, 0.224, 0.225]. These are the values across each colour channel similiar to the previous step. | Code to use is *torchvision.transforms.Normalize(std=...)* to adjust the standard deviation of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d52577-73f2-42ed-9d51-cce188854396",
   "metadata": {},
   "source": [
    "It's important to note that different pretrained models have different input requirements. So in the pretrained model that we're going to use, it's size is [3,224,224] but for others it might be [3,240,240] and etc. Just check the documentation to see what sizes they take. \n",
    "\n",
    "You might be wondering what's the purpose of the mean and standard deviation? Those come from the data itself. They were calculated from the ImageNet dataset by taking the mean and standard deviation from a subset of images.\n",
    "\n",
    "More importantly, *we don't actually need to do these two*. Neural networks are inherently capable of figuring out the appropriate data distributions meaning that they'll calculate the mean and standard deviations on their own. But adding them manually at the start can help the network achieve better performances quicker since they won't have to calculate these two anymore.\n",
    "\n",
    "With that said, let's make the *transforms* that can make our data compatible to our pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d027e94-be9a-4936-bfff-15a99b8947d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.299, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.299, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "manual_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a95230-3af0-4df4-97ab-87cc3da29caa",
   "metadata": {},
   "source": [
    "We've manually created a series of transforms to prep our data meaning that we can now switch to setting up our Datasets and DataLoaders. Let's use the same function from *data_setup.py* in making them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9767aa85-109c-476b-8a6e-569ead160507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1bca2dc9820>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1bca2d5f3e0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader, class_list = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=manual_transform,\n",
    "    batch_size=32,\n",
    "    num_workers=0)\n",
    "\n",
    "train_dataloader, test_dataloader, class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954d8e7-8350-46e9-b949-f2df5759c509",
   "metadata": {},
   "source": [
    "Remember that we were working with a manual implementation of the transforms for the pretrained model. You might encounter this style with other resources so it's best to just be aware of this type of technique. \n",
    "\n",
    "Not only that but the fact that this transform is manually created means that there are infinite possibilities to work with. You can include data augmentation techniques to the transform pipleline if you think that would help. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf770cf-76c4-4281-b15a-3afd8201eac4",
   "metadata": {},
   "source": [
    "**Creating Transform For Pretrainde Model - Auto Creation**\n",
    "\n",
    "You don't necessarily have to make the transforms manually by yourself. PyTorch includes an automatic transform creation feature. \n",
    "\n",
    "Whenever you setup a model from *torchvision.models* and then select a pretrained model's weights you'd like to use, the code would look like this:\n",
    "\n",
    "*weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT*\n",
    "\n",
    " Unpacking this for a bit:\n",
    "\n",
    "* *EfficientNet_B0_Weights* is the model architecture weights that we'd like to grab and there are many different architecture to use.\n",
    "\n",
    "* *DEFAULT* means that you just grab the best available weights - the best performing one's for ImageNet - You can specify different options such as *IMAGENET_V1* or *IMAGENET_V2* and usually the higher version means the better but if you want to always grab the latest one then *DEFAULT* should be the norm.\n",
    "\n",
    "Let's put this into code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ae6bb3-1148-416f-9c10-a1e9a0f43a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet_B0_Weights.IMAGENET1K_V1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9a8ec-41e5-454f-932f-e39480d79cf7",
   "metadata": {},
   "source": [
    "Once we have the weights of the model, we can access the transforms() method which will give us the data transforms that were used to train *EfficientNet_B0_Weights* on ImageNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd38340-813f-475d-b586-2cf5f3f5a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c8a44-cb36-43ab-a2f8-4b69e1b5291d",
   "metadata": {},
   "source": [
    "See how *auto_transforms* is very similiar to *manual_transforms* with some slight differences but for the most part, they still work the same. It's just that *auto_transforms* came directly from the model architecture that we picked meanwhile *manual_transforms* is something that we had to make from scratch.\n",
    "\n",
    "You can see that with using this method of just grabbing the transforms directly from the weights of the pretrained model with *weights.transforms()*, you're already ensuring that you're using the same data transforms as it used when it was training.\n",
    "\n",
    "But of course, you lose the customization options with this method. Let's try making the Datasets and DataLoaders again but this time, we'll use the *auto_transforms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f86f5bf-06f9-41cb-964c-b63d25b02d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1bca2e04710>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1bca2e04860>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader, class_list = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=auto_transforms,\n",
    "    batch_size=32,\n",
    "    num_workers=0)\n",
    "\n",
    "train_dataloader, test_dataloader, class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740303ab-a470-4122-89bd-0593a87e075d",
   "metadata": {},
   "source": [
    "**Getting Pretrained Models**\n",
    "\n",
    "We're done with making our data ready so it's time to actually work with a pretrained model. We've been building neural networks before from scratch and while that's a really good way to get the grasp of neural networks, it's not really efficient if you want to make a model that is actually giving good results\n",
    "\n",
    "That's why we're working with *Transfer Learning* since the main idea - again is to **take good performing models that is similiar to our problem and then customize that to suit our own case**.\n",
    "\n",
    "Because we are working with a computer vision problem, we'll find a pretrained classification model in *torchvision.models*\n",
    "\n",
    "Take a look at the different architectures available and look around.\n",
    "\n",
    "You'll see examples such as:\n",
    "\n",
    "* **ResNet** - *torchvision.models.resnet18()* | *torchvision.models.resnet50()*\n",
    "* **VGG** - *torchvision.models.vgg16()*\n",
    "* **EfficientNet** - *torchvision.models.efficientnet_b0()*\n",
    "* **VisionTransformer** - *torchvision.models.vit_b_16()*\n",
    "* **ConvNeXt** - *torchvision.models.convnext_tiny()*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf6140-021b-432b-b48c-636eb3626e40",
   "metadata": {},
   "source": [
    "**Which Pretrained Model To Use?**\n",
    "\n",
    "With so many options, it's quite hard to choose. What's the difference between X and Y? What's the benefits of doing X over Y? and etc. So many questions and so little answers. \n",
    "\n",
    "Basically, it always comes down to 'it depends'. It depends on the problem that you're trying to solve and the device that you're working with. \n",
    "\n",
    "The general ruse is that the higher number in the model name means that the performance is better such as *efficientnet_b7()* performs a significantly better than *efficientnet_b1()* and performs better than *efficientnet_b0()*. \n",
    "\n",
    "BUT the caveat is that the higher the number means that the model is LARGER. \n",
    "\n",
    "So it's not like you can just go ahead and pick the best performing model because your device might be the limiting part. \n",
    "\n",
    "There is the reality that **some models are just too big for certain devices**.\n",
    "\n",
    "If your device can't output the computation power needed for the model to run then you're going to suffer in speed. So it all comes down to this:\n",
    "\n",
    "**Performance VS Speed VS Size Tradeofff**\n",
    "\n",
    "Just try around with the different models to see if which one suits you best. For now, we'll be using *efficientnet_b0* as our pretrained model. Remember, it's always best to experiment, experiment, experiment! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20cc0c-3e9d-4cd0-9299-1c398c20a342",
   "metadata": {},
   "source": [
    "**Setting Up Pretrained Model**\n",
    "\n",
    "The model that we are going to use for this chapter would be *torchvision.models.efficientnet_b0()*. If you want to learn more about the architecture then you can check out the paper - [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946).\n",
    "\n",
    "There are usually papers associated for the different pretrained models that you can get from the web so if you want to look deeper into these models then you have the option to do so by checking out the papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c0184-9479-4312-a3a5-eecc5261247e",
   "metadata": {},
   "source": [
    "![Display](images/07-effnet-b0-feature-extractor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ae531-beb5-496a-ad1a-a5d3460ee823",
   "metadata": {},
   "source": [
    "It's relatively easy to setup *EfficientNet_B0* pretrained ImageNet weights using the same code as was used to create the transforms.\n",
    "\n",
    "*weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT* \n",
    "\n",
    "Default means the best available weights for ImageNet. \n",
    "\n",
    "This means that the model has already been trained on millions of images and already has a good representation of image data. So it's suffice to say that it already has the necessary basic patterns to identify common images.\n",
    "\n",
    "The PyTorch version of this pretrained model achieves around 77.7% accuracy for ImageNet's 1000 classes. \n",
    "\n",
    "So let's put this into code and set it to the appropriate device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3615c757-b7bf-4a8e-a91e-bbe52cbec6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7db30-747b-491f-9fc3-36519e227501",
   "metadata": {},
   "source": [
    "PyTorch versions before v0.13 use this code:\n",
    "\n",
    "*model = torchvision.models.efficientnet_b0(pretrained=True).to(device)*\n",
    "\n",
    "but using that with later versions would give you a warning stating that the parameter pretrained is deprecated and will be removed in 0.15. \n",
    "\n",
    "It's better to be informed about this because you might encounter it when working with older versions of PyTorch.\n",
    "\n",
    "Let's try printing the model and dissect what we'll get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b71e75b-8985-4b94-a7cf-e046ad2927ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1eea00-bf21-4770-aa94-7b57710a1d23",
   "metadata": {},
   "source": [
    "![Display](images/07-v2-effnetb0-model-print-out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db4b61-be40-4221-8894-cd4b5ddcbd90",
   "metadata": {},
   "source": [
    "That's a lot of layers. Makes our TinyVGG look like a pebble in comparison. This is exacty why transfer learning is one of the best ways to start working on problems with the best results possible because you are using models that were crafted by professionals and expert engineers that have been doing this for a much longer time.\n",
    "\n",
    "Since there's so many layers involved, we can just split this into three main parts:\n",
    "\n",
    "1. *features* - This is just a collection of convolution features alongside various different activation layers for the sole purpose of learning patterns of the vision data. This section is referrred to as the **feature extractor**\n",
    "\n",
    "2. *avgpool* - This takes the average of the output of the feature layers before and then turns that into a feature vector. This is akin to *MaxPool2d* that we used before in TinyVGG.\n",
    "\n",
    "3. *classifier* - This turns the feature vector into a vector with the same number of dimensions as the required output classes. Because *efficientnet_b0* is pretrained on ImageNet which has 1000 classes then the output feature for it is also 1000 by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b081e-b2ff-465d-9fec-c899299723cc",
   "metadata": {},
   "source": [
    "**Getting Model SUmmary From - *torchinfo.summary()***\n",
    "\n",
    "Remember that we can use *torchinfo*'s *summary()* method to learn more about how the input data passes through the model itself and what are the changes that are happening throughout the process. \n",
    "\n",
    "Because we are checking how the input goes through the model, it goes without saying that we're going to need something to input first and then track that. \n",
    "\n",
    "So we'll pass in the following:\n",
    "\n",
    "* *model* - the model that we are taking the summary from\n",
    "  \n",
    "* *input_size* - the shape of the data that we are passing through the model. In the case of *efficientnet_b0*, the input size is [32,3,224,224] referring to [batch_size, color_channels, height, width]. Though other types of *efficientnet_bX* have different input sizes.\n",
    "\n",
    "* *col_names* - the information columns that we want the method to output from the model.\n",
    "\n",
    "* *col_width* - how wide the information columns would be to display the output from the model.\n",
    "\n",
    "* *row_settings* - what features to show in a row.\n",
    "\n",
    "**NOTE:** Moden models can handle input images of varying sizes because of *torch.nn.AdaptiveAvgPool2d()*. This is a layer that adaptively adjusts the output_size of a given input as required. Try this out with passing different input size images to summary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6559dbf-56d0-4ea5-b831-eea5333f84db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     15,350               True\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     31,290               True\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     37,130               True\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    126,004              True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      262,492              True\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      717,232              True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 1000]           --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 1000]           1,281,000            True\n",
       "============================================================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 12.35\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.35\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 3492.77\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078491d-67e3-4b95-a2cf-7d480124eb94",
   "metadata": {},
   "source": [
    "![Display](images/07-torchinfo-summary-unfrozen-layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5693e-4304-45d1-a934-75616dedb206",
   "metadata": {},
   "source": [
    "That's a pretty large model! Imagine how bigger it is if we tried the higher versions. We can see how the model changes the various inputs and outputs shapes as the image goes through the model.\n",
    "\n",
    "In addition there are other total parameters (pretrained weights) to recognize different patters in the data.\n",
    "\n",
    "If you want to compare this to our previous model - **TinyVGG only had 8,083 parameters** while **efficientnet_b0 has 5,288,548 parameters** that's an increase of **654x**. With that big of a change would this finally result better performance for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b1f41-3968-4e7b-8eb0-829a00044cf2",
   "metadata": {},
   "source": [
    "**Freezing Base Model + Changing Output Layer**\n",
    "\n",
    "The process of transfer learning is simple - freeze some of the base layers of a pretrained model (usually the features section) and then adjust the output layers (also called head/classifier layers) for your specific usecase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faebf4d3-21f7-4f46-b272-12102145a16c",
   "metadata": {},
   "source": [
    "![Display](images/07-v2-effnet-changing-the-classifier-head.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374cbcf-8326-46d3-958b-2cedb8b70e9a",
   "metadata": {},
   "source": [
    "Remember that the original mode had to deal with 1000 output classes because it was trained on ImageNet's dataset. Wherein we only have 3 output classes which is the pizza, steak, sushi. We only need 3 output features so we change that. The rest wouldn't need to be changed so we 'freeze' all the layers/parameters in the features section of the *efficientnet_b0* model. \n",
    "\n",
    "To expand further on the concept of 'freezing' this just means that we keep them as they were when they were trained. We don't change tha patterns that it learned during its training before and keep them how they are. Meaning we leverage the patterns and weights that it learned during it's training and just apply that to our images. We use the patters from ImageNet and apply them to our pizza, steak, sushi. \n",
    "\n",
    "We can freeze the layers/parameters in the features section by setting the attribute *requires_grad=False*. Remember that this attribute means that PyTorch deosn't track gradient updates meaning that they won't be changed by the optimizer during training. \n",
    "\n",
    "So if we apply *requires_grad=False* we don't change anything so --> untrainable and frozen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85aec585-7c28-45df-9180-08ed7b6f31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e00ee2-b8c2-46aa-984f-366f59de5b8f",
   "metadata": {},
   "source": [
    "Feature extractors are fully frozen! \n",
    "\n",
    "Let's start adjusting the output layer for the classifier of the pretrained model. We can do this by creating a new series of layers.\n",
    "\n",
    "Currently the classifier layer of the model is as shown:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "075af55d-42c8-44cc-b309-fcc0795afaa3",
   "metadata": {},
   "source": [
    "(classifier): Sequential(\n",
    "    (0): Dropout(p=0.2, inplace=True)\n",
    "    (1): Linear(in_features=1280, out_features=1000, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb34cb-d957-4037-b89c-9ef914c6c573",
   "metadata": {},
   "source": [
    "We can keep the *Dropout* layer using *torch.nn.Dropout(p=0.2, inplace=True)*\n",
    "\n",
    "Dropout layers are a means of regularization meaning that it is a method to prevent overfitting. It works by randomly removing connections between two neural network layers with a probability of *p*. For example, in the case above, since *p=0.2* then that means there is a 20% chance that a connection between neural network layers will be removed at random for each pass. \n",
    "\n",
    "This prevents overfitting because it makes sure that the connections that remain are able to learn features to compensate for the connections that were removed. These help in making the *features* generalized! \n",
    "\n",
    "We'll keep the *in_features=1280* as the same for the *Linear* output layer because that is the output of the model after the features extraction so there's not much to change there. But for the *out_features* we'll be reducing the length from 1000 classes to the length of [pizza, steak, sushi] so that's just down to 3. \n",
    "\n",
    "The new *classifier* should also be on the same device as the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b8ba8b-a168-459a-a71c-e01ad179e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the length of the class names\n",
    "output_shape = len(class_list)\n",
    "\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True), \n",
    "    torch.nn.Linear(in_features=1280, \n",
    "                    out_features=output_shape, # same number of output units as our number of classes\n",
    "                    bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1923926b-ce9c-4f88-89c9-bd3d79a3cb0a",
   "metadata": {},
   "source": [
    "Let's take a look at the model again with torchinfo summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af3b54b4-0608-4d84-b505-9320f19410bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "176ca8ee-6934-40b8-b4bb-e30c0b28b8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (Units.GIGABYTES): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202ca75-db30-45e1-a61b-2402b50d7d7c",
   "metadata": {},
   "source": [
    "![Display](images/07-torchinfo-summary-frozen-layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4572c-35a7-4d4d-b9c9-3a761f5ab9b7",
   "metadata": {},
   "source": [
    "Seems like there's a couple of differences involved here. Let's take a look at some of these:\n",
    "\n",
    "1. *Trainable Column* - You can notice that base layers - feature extractors are all marked with **False** for their trainable columns. This is because we set their attribute *required_grad=False*. Because of that, these layers won't be updated anymore for future training.\n",
    "\n",
    "2. *Output Shape of Classifier* - The *classifier* portion of the model which is the last part now has a different output shape. Instead of [32, 1000] it's now [32, 3]. It also has a value of **True** for it's trainable column. That means that the parameters in these layers will be changed during training. Basically, we are using the *features* part of the model to feed our *classifier* part a base representation of an image then the *classsifer* layer will learn how to base these representations with the associated class list that we have.\n",
    "\n",
    "3. *Less Trainable Parameters* - Because we set the *features* extraction portion of the model to *requires_grad=False* then that means there is a significantly less number of parameters that won't need to be trained. We started out with 5,288,548 trainable parameters but because of us freezing the entire features extraction, we are now down to 3,843 trainable parameters which is even less than the original TinyVGG model that we made. These trainable parameters only come from the last two layers that we have in the *classifier* which are the Dropout and Linear layer.\n",
    "\n",
    "**Note:** The more trainable parameters means the more computational power is required. So that means it's going to take longer to train a model that has a larger number of trainable parameters. Freezing the base / features layer means that we should be able to train quickly because we only have a very small number of parameters to work with. This is one of the biggest benefits of transfer learning. Reducing the need for computation power while still leveraging the results of a very good model. This gives even regular people the chance to work with a good model even if they don't have the necessary hardware to make the models in the first place. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9159723-79c2-4f40-8e97-d2f98f25e2d1",
   "metadata": {},
   "source": [
    "**Train Model**\n",
    "\n",
    "Now that we have our data ready to use and our pretrained model semi-frozen with the only parts remaining is the classifier, let's try doing transfer learning in practice. \n",
    "\n",
    "We're going to work with the usual steps. First, choose an optimizer and a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b65e66-f676-41bb-b972-8a77dc44fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7b46a-e46b-46dd-9439-e2adf336bf2c",
   "metadata": {},
   "source": [
    "Now that's done, we're ready to start training the model with the *train()* function from *engine.py*. Let's observe how long it would take for the model to train for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf93b53-abd2-4d3e-b14e-f4fea334c56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f38bc6d18443fbb81adf928bd7dada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.9844 | Train Accuracy: 0.5792 | Test Loss: 0.6784 | Test Accuracy: 0.9284\n",
      "Epoch: 2 | Train Loss: 0.7014 | Train Accuracy: 0.8354 | Test Loss: 0.5423 | Test Accuracy: 0.9437\n",
      "Epoch: 3 | Train Loss: 0.5974 | Train Accuracy: 0.8229 | Test Loss: 0.4638 | Test Accuracy: 0.9159\n",
      "Epoch: 4 | Train Loss: 0.4568 | Train Accuracy: 0.9062 | Test Loss: 0.4114 | Test Accuracy: 0.9187\n",
      "Epoch: 5 | Train Loss: 0.4417 | Train Accuracy: 0.8896 | Test Loss: 0.3907 | Test Accuracy: 0.9165\n",
      "Epoch: 6 | Train Loss: 0.4350 | Train Accuracy: 0.8667 | Test Loss: 0.3578 | Test Accuracy: 0.9159\n",
      "Epoch: 7 | Train Loss: 0.4218 | Train Accuracy: 0.8375 | Test Loss: 0.3242 | Test Accuracy: 0.9159\n",
      "Epoch: 8 | Train Loss: 0.4181 | Train Accuracy: 0.8562 | Test Loss: 0.3465 | Test Accuracy: 0.8733\n",
      "Epoch: 9 | Train Loss: 0.3371 | Train Accuracy: 0.8792 | Test Loss: 0.3015 | Test Accuracy: 0.9347\n",
      "Total Train Time: 48.784 Seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=9\n",
    ")\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total Train Time: {end_time - start_time:.3f} Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a179a-eece-4881-a57e-97dbdd1eec7a",
   "metadata": {},
   "source": [
    "Even though the model is very large as compared to TinyVGG, it was able to train fast and achieve incredible results as compared to TinyVGG. We were suffering around 40% to 50% in the previous model results but with pretrained models - *efficientnet_b0*, we were able to achieve 85% to 90% accuracy on the test dataset. That's close to double than the previous results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b976f1e-2bca-4e8f-92cc-4dfa19749b18",
   "metadata": {},
   "source": [
    "**Evaluating Model By Plotting Loss Curves**\n",
    "\n",
    "Because our model seems to performing well, let's try plotting the loss curves and see how the model trains for each epoch. Let's use the *plot_loss_curves* from the 03-Chapter's *helper_functions.py* script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42450df4-2223-4e7c-88e1-69465bd54fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper_functions.plot_loss_curves(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933115fd-9962-4f7e-b2ff-5b59c32e6ed4",
   "metadata": {},
   "source": [
    "Those loss curves are exactly what we want them to be. The loss going down down down on the train and test sets while the accuracy goes up up up for both as well! \n",
    "\n",
    "That's the power of *transfer learning*. You get good results for your problem leveraging the power and the effort that others have already done. Standing on the shoulders of giants and that's a good thing because for some, they just don't have the necessary resources that the people who trained these models had access to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa23c5-2bd2-47b8-9cbf-634cc9a196db",
   "metadata": {},
   "source": [
    "**Making Predictions From Test Set**\n",
    "\n",
    "We've seen that the model performs great quantitatively but let's make sure that it also performs great qualitatively. We can do that just by making predictions with it from the test set and then plotting them.\n",
    "\n",
    "It's always great to see the model do work with live images and then visualize how it does these. \n",
    "\n",
    "Remember, that we need the images to be transformed to be compatible with what the model was trained on. This means that we have to do make sure of the following consistencies:\n",
    "\n",
    "* Same Shape\n",
    "* Same Datatype\n",
    "* Same Device\n",
    "* Same Transforms\n",
    "\n",
    "So let's make the function that can do all that. We'll call this function *pred_and_plot_image()* which will do the ofllowing:\n",
    "\n",
    "1. Take in a trained model, list of class names, a filepath to the target image, image size, transform, and device.\n",
    "2. Open image with *PIL.Image.open()*\n",
    "3. Create the necessary transform for the image - this will default to the one that we manually created earlier -> *manual_transform* or be automated with *weights.transfroms()*\n",
    "4. Ensure that the model is on the target device.\n",
    "5. Turn on *model.eval()* so that layers such as *nn.Dropout()* in the classifier would be turned off because we aren't training anymore.\n",
    "6. Transform the target image with the transform in step 3 and add an extra batch dimension with *torch.unsqueeze(dim=0)* so that we can achieve [batch_size, color_channels, height, width].\n",
    "7. Make prediction on the image by sending it through the model and also making sure that the image is on the same device\n",
    "8. Convert the model logits into prediction probabilities with *torch.softmax(dim=1)*\n",
    "9. Convert the prediction probabilities into prediction labels with *torch.argmax(dim=1)*\n",
    "10. Plot the image with *matplotlib* and set the title to the prediction label and prediction probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "700eb74f-7844-4de8-8862-519f057f00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_plot_image(\n",
    "    model: torch.nn.Module,\n",
    "    class_list: List[str],\n",
    "    target_image: str,\n",
    "    image_size: Tuple[int,int] = (224,224),\n",
    "    transform: torchvision.transforms = None,\n",
    "    device: torch.device = device\n",
    "):\n",
    "    image = Image.open(target_image)\n",
    "    if transform:\n",
    "        transformed_image = transform(image)\n",
    "    else: \n",
    "        transformed_image = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        transformed_image = transformed_image.unsqueeze(dim=0).to(device)\n",
    "        logits = model(transformed_image)\n",
    "        \n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    labels = torch.argmax(probabilities, dim=1),\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_list[labels]} | Prob: {probabilities.max():.3f}\")\n",
    "    plt.axis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721d245-3930-457b-889c-bb853f05820f",
   "metadata": {},
   "source": [
    "That's a function that meets everything that we need. Let's test it out by making some predictions on a few random images from the test set.\n",
    "\n",
    "Let's grab all the images from the test set by putting them into a list with all the test image paths with *list(Path(test_dir).glob(\"asterisk/asterisk.jpg\"))*. Remember that the asterisks in the *glob* function indicates that it will match anything that matches the pattern so basically, we're saying that it will grab everything that is a *.jpg* which is all of our images.\n",
    "\n",
    "Then since we have all the paths for each of the images in the test set, we'll just randomly select one of them with Python's *random.sample(population, k)* method. *population* is the sequence of the sample and *k* is the number of samples that we'll be taking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3b02262-68f2-47ed-b6af-4396463b411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plot_img = 3\n",
    "test_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "test_image_path_sample = random.sample(population=test_image_path_list, k=num_plot_img)\n",
    "\n",
    "for image_path in test_image_path_simple:\n",
    "    pred_plot_image(model=model,\n",
    "                   class_list=class_list,\n",
    "                   target_image=image_path,\n",
    "                   image_size=(224,224),\n",
    "                   transforms=auto_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6b872-1e20-4f02-815d-7350fb611e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
