{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1d7f7d-dc59-4ddb-a0f6-9f5cff0550ac",
   "metadata": {},
   "source": [
    "# PyTorch Experiment Tracking #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bbaaf9-8b11-47cb-80a0-5ebb894de37c",
   "metadata": {},
   "source": [
    "We've trained and created a couple of models already from basic linear neural networks to convolutional networks such as TinyGG. So far, we've been just keeping tracking of them through Python dictionaries and also by comparing them on the metric print outs during training. \n",
    "\n",
    "Now, that's all well and good but what if we want to run a couple of different models at once?\n",
    "\n",
    "**Experiment Tracking** is exatly how we do that. \n",
    "\n",
    "Experiment tracking is an important aspect and is one of the integral parts of machine learning. In this chapter, we're going to answer just one question - **How do you track your machine learning experiments?**\n",
    "\n",
    "But before we do that, let's ask the simple question first. \n",
    "\n",
    "**What is Experiment Tracking?**\n",
    "\n",
    "You might've noticed already but we're doing a lot of experiments when it comes machine learning simply because there are a lot of different variables involved that you can change. From the hyperparameters, models, data, and many more. \n",
    "\n",
    "Because of this, we need something to properly track the results of these many different experiments. That is why experiment tracking exists and why it is so imporant because it enables us to check and compare our findings. We get to know what works and what doesn't fast. \n",
    "\n",
    "This saves us time and effort which can be better used on other areas. \n",
    "\n",
    "**Why Track Experiments?**\n",
    "\n",
    "Before, we were running only a few models and we weren't doing a lot of changing with each model that we make so our previous process of using print outs and sending the results to a simple dictionary was a good enough solution. BUT we always reitirated the motto 'experiment experiment experiment' so eventually, as you get better with dealing with models, you're going to get curious. \n",
    "\n",
    "With that, you'll eventually be dealing with many different variations of potential solutions to your problems so you'll want something to record these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037ef48-7e07-4d6a-bde7-64b754e93478",
   "metadata": {},
   "source": [
    "![Display](images/08-experiment-tracking-can-get-out-of-hand.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97557362-4a56-400d-be0a-988a4b00d7d5",
   "metadata": {},
   "source": [
    "Let's take a look at a few ways you can track the results of your machine learning experiments\n",
    "\n",
    "**Result Tracking Solutions**\n",
    "\n",
    "* *Python Dict, CSV files, Print outs* - **PRO:** Easy to setup, runs in pure python | **CON:** Hard to keep track with large number of experiments, does not scale conveniently| **COST:** FREE\n",
    "* *TensorBoard* - **PRO:** Extensions built directly into PyTorch, widely recognized and used, easily scales with experiments| **CON:** Not so intuitive and friendly user-experience compared to other options| **COST:** FREE\n",
    "* *Weights & Biases Experiment Tracking* - **PRO:** Better user experience, can share experiment to the public, can track a wide range of items | **CON:** Requires reference materials outside of PyTorch | **COST:** FREE FOR PERSONAL USE\n",
    "* *MLFlow* - **PRO:**  Open-source, flexible and many integrations | **CON:** Can be hard to setup | **COST:** FREE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a29163-9631-4c44-92f5-9527ba400722",
   "metadata": {},
   "source": [
    "![Display](images/08-different-places-to-track-experiments.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98392e2-fe8c-4235-9e64-6b89284b4f58",
   "metadata": {},
   "source": [
    "**Chapter Coverage**\n",
    "\n",
    "Because the section covers experiment tracking, it goes without saying that we're going to do a lot of different modelling experiments with  varying levels of data, model size, and training time. Keeping with consistency, we're still trying to improve on FoodVision Mini\n",
    "\n",
    "While there are many options to choose for experiment tracking, this chapter will only focus with TensorBoard because of it's tight integration with PyTorch and widespread use. But overall, the principles stay the same for all other platforms for experiment tracking.\n",
    "\n",
    "1. **Getting Setup** - We'll download/transfer the same files that we used earlier to make data setup and training easier.\n",
    "2. **Get Data** - Utilize the same data of pizza, steak, and sushi for image classification to improve FoodVision Mini Model's results.\n",
    "3. **Create Datasets & DataLoaders** - Refer to *data_setup.py* for the function that can make the Dataset and DataLoader from the train and test directories of pizza, steak, sushi.\n",
    "4. **Get & Customize Pretrained Model** - Pick a pretrained model from PyTorch's *torchvision.models* library and then customize that pretrained model to fit our own needs.\n",
    "5. **Train Model & Track Results** - We will start to train the model and see how to track the results of a single model with TensorBoard.\n",
    "6. **View Model Results In TensorBoard** - The way we viewed loss curves before was through a helper function. This time, we'll be using TensorBoard's own way of visualizing the loss curve.\n",
    "7. **Creating Helper Functions to Track Experiments** - In addition to this, we will also create a helper function for us to save our model's experimenting results.\n",
    "8. **Developing Series of Modelling Experiments** - Previously, we did experiments one by one. We set up one model and trained it. This time, we'll create some code to run multiple exeriments at once with different modes, amounts of data, and training time.\n",
    "9. **Viewing Modelling Experiments in TensorBoard** - Overall, at this stage of the chapter there should be around eight modelling experiments running consecutively. We'll take a look at all the results for each model in TensorBoard.\n",
    "10. **Loading Best Model & Creating Predictions** - Once we've picked out the model that has the best results, we'll use it practically and visualize the these predictions to see it in action. Visualize! Visualize! Visualize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738e228-8f25-4396-9551-eb78e141c106",
   "metadata": {},
   "source": [
    "**Getting Setup**\n",
    "\n",
    "Before we get started, we'll need the all the modules. Again, we'll be using the *data_setup.py* and *engine.py* from the modularity chapter. We will also import *torchinfo* for visualizing the sumarries of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cfec877-bdb5-4192-ba61-4eebdef29cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "889976b4-e2b1-43d5-8cea-8b35e1b8195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scripts import data_setup, utils, predict\n",
    "from scripts.engine import train_step, test_step\n",
    "from scripts import engine\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b789f9e2-dc18-41af-8567-0328bdf83a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8bc3f1-71e6-4404-84fc-84ea1017d2db",
   "metadata": {},
   "source": [
    "**Create Helper Function To Generate Seeds**\n",
    "\n",
    "We've always been setting seeds manually before so it was a bit tedious. Let's just turn it into a function so that everything is a lot easier. Create a function named *set_seeds()* that we can just call anytime we need to create a seed. Set the default seed to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a7648ec-777f-4599-a7d8-a1b65ec3808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed:int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a584c29-d0a8-46cc-aef2-4af278ff505d",
   "metadata": {},
   "source": [
    "**Get Data**\n",
    "\n",
    "Since we're trying to improve the results from FoodVision Mini, we'll still use the same dataset as before - pizza, steak, sushi. We've already seen how powerful pretrained models are when used with our custom dataset but that was just one of many configurations that we can use. There are so many different pretrained models out there that we can try and many varying optimizers and hyperparameters to change. \n",
    "\n",
    "That's why we're still working with the same dataset. With that said, let's download the data again for this chapter. We'll still be working with a lot of similiar code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06fcfeb2-89bb-4e5e-bffd-294c4887dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(\n",
    "    src: str,\n",
    "    dest: str,\n",
    "    remove_source: bool = True) -> Path:\n",
    "    \n",
    "    data_path = Path('data')\n",
    "    image_path = data_path/dest\n",
    "\n",
    "    if image_path.is_dir():\n",
    "        print(f\"Directory {image_path} Already Exists! Cancelling ...\")\n",
    "    else:\n",
    "        print(f\"Directory {image_path} Not Found! Creating ...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "    target_file = Path(src).name\n",
    "    print(target_file)\n",
    "    \n",
    "    with open(data_path/target_file, \"wb\") as f:\n",
    "        request = requests.get(src)\n",
    "        print(f\"[INFO] Downloading {target_file} from {src} ...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    with zipfile.ZipFile(data_path/target_file, \"r\") as zf: \n",
    "        print(f\"[INFO] Unzipping {target_file} ...\")\n",
    "        zf.extractall(image_path)\n",
    "\n",
    "    if remove_source:\n",
    "        os.remove(data_path/target_file)\n",
    "\n",
    "    return image_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c0ae14f-b3db-4dc0-94b8-f0efe9c0f1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data\\pizza_steak_sushi Already Exists! Cancelling ...\n",
      "pizza_steak_sushi_20_percent.zip\n",
      "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip ...\n",
      "[INFO] Unzipping pizza_steak_sushi_20_percent.zip ...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = download_data(src='https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip', dest='pizza_steak_sushi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b199d44-0db6-4663-95d0-6e6f920f980f",
   "metadata": {},
   "source": [
    "**Creating Datasets & DataLoaders**\n",
    "\n",
    "Time to turn our data to Datasets and DataLoaders. Use the *create_dataloaders()* function from *data_setup.py*. At the same time, manually create transforms with *torchvision.transforms*. After this, create an automated transform from a pretrained *torchvision* model.\n",
    "\n",
    "Remember the benefits of each - for manually creating transforms, you get access to unlimited flexibility because you can add in extra data augmentation transforms but at the cost of having to suffer from potential performance degredation because the transforms don't exactly match the pretrained model's transform. \n",
    "\n",
    "Typically, the way to avoid this performance degredation is by normalizing the images in ImageNet format. Why just ImageNet format? It's because that is the dataset where all pretrained *torchvision.models* are trained on. These normalize values are provided in documentation of the models in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c674c4-cfbb-46a9-9233-be7aa5f10317",
   "metadata": {},
   "source": [
    "**Manual Transform Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab2ca172-a946-4ea8-ad5b-dce921cbffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "manual_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dd1d9c5-88df-409c-b62e-d62c482e730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1bd1af8b3e0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1bd1af8bda0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = dataset_path/'train'\n",
    "test_dir = dataset_path/'test'\n",
    "\n",
    "train_dataloader, test_dataloader, class_list = data_setup.create_dataloaders(train_dir=train_dir, \n",
    "                                                                              test_dir=test_dir, \n",
    "                                                                              transforms=manual_transforms,\n",
    "                                                                              batch_size=32,\n",
    "                                                                              num_workers=0\n",
    "                                                                             )\n",
    "\n",
    "train_dataloader, test_dataloader, class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672d40c-7011-4c0e-98d2-2d5cc90b4abc",
   "metadata": {},
   "source": [
    "**Auto Transform Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ede98f3d-587a-43cb-9287-76efcc0735f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7aa2c5e4-3d80-4c62-9f1d-6ede5f74b1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_weights = weights.transforms()\n",
    "auto_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe675728-9096-4c54-9d91-08dad66d1216",
   "metadata": {},
   "source": [
    "**Getting Pretrained Layers, Freezing Base Layers, Changing Classifier Head**\n",
    "\n",
    "Before we start runinng multiple modelling experiments at once, we'll try just running one. We have our data ready so let's start working with our pretrained models. Choose one and then freeze the base layers so that we can get a feature extractor model.\n",
    "\n",
    "Remember that feature extractor models are different from fine-tuned models. The difference is that feature extraction does not change much in the base layers and only changes the classifier heads. While fine-tuned involves changing certain base layers or all of it. \n",
    "\n",
    "In this case, we're only going for a feature extractor model. Just like before, freeze the base layers and change the classifier head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91aec699-4eab-4bba-9693-24b2dce0d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     15,350               True\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     31,290               True\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     37,130               True\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    126,004              True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      262,492              True\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      717,232              True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 1000]           --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 1000]           1,281,000            True\n",
       "============================================================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 12.35\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.35\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 3492.77\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "823cc0cc-46fd-427c-8696-2e7cefb03b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(1280, len(class_list), bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6c70658-cd7f-4859-bb60-971ac2b2e29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (Units.GIGABYTES): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c06741-791b-404a-a997-6fa1cebfcd7a",
   "metadata": {},
   "source": [
    "**Train & Track Results**\n",
    "\n",
    "We've got the data and model ready. Time to get started on training. Let's assign the loss functions and optimizer. Same as usual, choose the *torch.nn.CrossEntropyLoss* for the loss function and for optimizer, experiment around with *torch.optim.SGD* or *torch.optim.Adam*. Assign the learning rate to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97dfe87d-d725-4948-b6f0-07962a9cdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e161046-0dbe-45fb-b9ac-73cafbf72016",
   "metadata": {},
   "source": [
    "**Adjust Train() Function To Track Results With SummaryWriter()**\n",
    "\n",
    "Here starts the new concepts and ideas. We've been tracking the results of our *train()* function with multiple Python dictionaries - one for each model. It goes without saying that this process doesn't scale easily when you're dealing with more than one experiment.\n",
    "\n",
    "Introducing PyTorch's *torch.utils.tensorboard.SummaryWriter()* class that saves various parts of the model's training progress to file. \n",
    "\n",
    "*SummaryWriter()* saves information about the model to a file set by the *log_dir* parameter. The default location for *log_dir* is *run/CURRENT_DATETIME_HOSTNAME* of which *HOSTNAME* is the name of your computer and the associated datetime when the model was trained.\n",
    "\n",
    "You can always change where the experiment results are sent. The filename can be changed to anything you want. The outputs of the *SummaryWriter()* class are all saved in *TensorBoarad* format. \n",
    "\n",
    "TensorBoard is a part of the TensorFlow deep learning library. TensorFlow might be something you've heard before because it is one of the direct competitors of PyTorch. Luckily, we can always work with PyTorch and a part of TensorFlow - TensorBoard. \n",
    "\n",
    "Let's start working with *SummaryWriter()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3960c3b-6b17-40fa-801f-3019df707b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42f1a1-9d80-4a10-af8d-80c59c455128",
   "metadata": {},
   "source": [
    "Because we'll be changing up the method we use to track the results, naturally, our previous function for training models in *engine.py* wouldn't work without some adjustments to the code. Now, we could make an entirely new train function but we'll opt to changing certain aspects only to save time and just be more efficient. \n",
    "\n",
    "Now, what are we going to change? We will be adding the feature for the *train()* function to log the model's training and test loss + accuracy values much like as to what we were doing before but this time with TensorBoard.\n",
    "\n",
    "We'll do this with *writers.add_scalars(main_tag, tag_scalar_dict)*. What does these two parameters do exactly?\n",
    "\n",
    "* *main_tag* (string) - this is the name of the scalar that is being tracked such as *'accuracy'* or *'loss'*\n",
    "* *tag_scalar_dict* (dict) - this is the dictionary of values being tracked such as *{'train_loss: 0.3454'}*\n",
    "\n",
    "Remember that loss and accuracy are scalars, that's why the function is called *add_scalars()*. \n",
    "\n",
    "Once we're done with tracking values that we want, we call *writer.close()* so that the *writer* class would stop looking for values to track. We don't need to remake everything. We can just simply use the same *train_step* and *test_step* from *engine.py* while the only function that we need to work with is *train()*.\n",
    "\n",
    "Take note that you are able to track information on the model almost anywhere in code but it is most often that experiments are tracked while a model is training. The *torch.utils.tensorboard.SummaryWriter()* class does have additional methods to track things in the model/data. Example of this is *add_graph()* of which tracks the computation graph of the model. There are many more to check out, visit the *SummaryWriter* documentation to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad2f0a99-68ff-4353-aff9-00c3eb360d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device\n",
    ") -> Dict [str, List]:\n",
    "\n",
    "    # Creating empty results dictionary\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Looping through train and test steps for number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Printing out the outputs\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"Train Loss {train_loss:.4f} | \"\n",
    "            f\"Train Accuracy {train_acc:.4f} | \"\n",
    "            f\"Test Loss {test_loss:.4f} | \"\n",
    "            f\"Test Accuracy {test_acc:.4f} | \"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "        ### NEW !! - Experiment Tracking \n",
    "\n",
    "        # Adding loss results to SummaryWriter\n",
    "        writer.add_scalars(\n",
    "            main_tag='Loss',\n",
    "            tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                             \"test_loss\": test_loss},\n",
    "            global_step=epoch\n",
    "        )\n",
    "\n",
    "        # Adding accuracy results to SummaryWriter\n",
    "        writer.add_scalars(\n",
    "            main_tag='Accuracy',\n",
    "            tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                             \"test_acc\": test_acc},\n",
    "\n",
    "            global_step=epoch\n",
    "        )\n",
    "\n",
    "        # Track PyTorch Model Architecture\n",
    "        writer.add_graph(model=model,\n",
    "                          input_to_model=torch.randn(32,3,256,256).to(device))\n",
    "\n",
    "    writer.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef931816-d63f-49d8-9b59-8c657c70e6be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278d89abcbd849f4b3bf16ca79258f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss 0.9918 | Train Accuracy 0.5125 | Test Loss 0.7034 | Test Accuracy 0.8419 | \n",
      "Epoch: 2 | Train Loss 0.6824 | Train Accuracy 0.8292 | Test Loss 0.5289 | Test Accuracy 0.9032 | \n",
      "Epoch: 3 | Train Loss 0.5313 | Train Accuracy 0.8938 | Test Loss 0.4380 | Test Accuracy 0.9121 | \n",
      "Epoch: 4 | Train Loss 0.4628 | Train Accuracy 0.8750 | Test Loss 0.3827 | Test Accuracy 0.9211 | \n",
      "Epoch: 5 | Train Loss 0.4011 | Train Accuracy 0.9083 | Test Loss 0.3437 | Test Accuracy 0.9255 | \n",
      "Epoch: 6 | Train Loss 0.3671 | Train Accuracy 0.9000 | Test Loss 0.3124 | Test Accuracy 0.9255 | \n",
      "Epoch: 7 | Train Loss 0.3253 | Train Accuracy 0.9167 | Test Loss 0.2999 | Test Accuracy 0.9300 | \n",
      "Epoch: 8 | Train Loss 0.2837 | Train Accuracy 0.9458 | Test Loss 0.2802 | Test Accuracy 0.9344 | \n",
      "Epoch: 9 | Train Loss 0.2937 | Train Accuracy 0.9271 | Test Loss 0.2651 | Test Accuracy 0.9344 | \n",
      "Epoch: 10 | Train Loss 0.2666 | Train Accuracy 0.9313 | Test Loss 0.2583 | Test Accuracy 0.9344 | \n"
     ]
    }
   ],
   "source": [
    "set_seeds(42)\n",
    "results = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c220fc-a325-4b5c-8e89-325994a198a5",
   "metadata": {},
   "source": [
    "Since the *train()* function is now updated to use the *SummaryWriter()* instance in tracking the model's results. Let's try running it for 5 epochs and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e2af90f-7b58-498e-9537-1aba1da8550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "resnet = models.resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ceea5fcc-26aa-4bb5-9f70-fcc538acc804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet.fc = nn.Linear(in_features=512, out_features=len(class_list), bias=True)\n",
    "\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b29fed2-84d1-4f0d-b713-9d80f31332a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ResNet (ResNet)                          [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Conv2d (conv1)                         [32, 3, 224, 224]    [32, 64, 112, 112]   (9,408)              False\n",
       "├─BatchNorm2d (bn1)                      [32, 64, 112, 112]   [32, 64, 112, 112]   (128)                False\n",
       "├─ReLU (relu)                            [32, 64, 112, 112]   [32, 64, 112, 112]   --                   --\n",
       "├─MaxPool2d (maxpool)                    [32, 64, 112, 112]   [32, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer1)                    [32, 64, 56, 56]     [32, 64, 56, 56]     --                   False\n",
       "│    └─BasicBlock (0)                    [32, 64, 56, 56]     [32, 64, 56, 56]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    └─BasicBlock (1)                    [32, 64, 56, 56]     [32, 64, 56, 56]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer2)                    [32, 64, 56, 56]     [32, 128, 28, 28]    --                   False\n",
       "│    └─BasicBlock (0)                    [32, 64, 56, 56]     [32, 128, 28, 28]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 128, 28, 28]    (73,728)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─Sequential (downsample)      [32, 64, 56, 56]     [32, 128, 28, 28]    (8,448)              False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    └─BasicBlock (1)                    [32, 128, 28, 28]    [32, 128, 28, 28]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "├─Sequential (layer3)                    [32, 128, 28, 28]    [32, 256, 14, 14]    --                   False\n",
       "│    └─BasicBlock (0)                    [32, 128, 28, 28]    [32, 256, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 28, 28]    [32, 256, 14, 14]    (294,912)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─Sequential (downsample)      [32, 128, 28, 28]    [32, 256, 14, 14]    (33,280)             False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    └─BasicBlock (1)                    [32, 256, 14, 14]    [32, 256, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "├─Sequential (layer4)                    [32, 256, 14, 14]    [32, 512, 7, 7]      --                   False\n",
       "│    └─BasicBlock (0)                    [32, 256, 14, 14]    [32, 512, 7, 7]      --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 14, 14]    [32, 512, 7, 7]      (1,179,648)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      (2,359,296)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
       "│    │    └─Sequential (downsample)      [32, 256, 14, 14]    [32, 512, 7, 7]      (132,096)            False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    └─BasicBlock (1)                    [32, 512, 7, 7]      [32, 512, 7, 7]      --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 7, 7]      [32, 512, 7, 7]      (2,359,296)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      (2,359,296)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [32, 512, 7, 7]      [32, 512, 1, 1]      --                   --\n",
       "├─Linear (fc)                            [32, 512]            [32, 3]              1,539                True\n",
       "========================================================================================================================\n",
       "Total params: 11,178,051\n",
       "Trainable params: 1,539\n",
       "Non-trainable params: 11,176,512\n",
       "Total mult-adds (Units.GIGABYTES): 58.03\n",
       "========================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 1271.66\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 1335.64\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=resnet,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33b88fc7-810e-46ae-8245-fd99a1dd727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72cee13b-b493-4ce7-a317-e1163c66a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68cd807577a4cfe9dc633b5a62d6e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss 1.0156 | Train Accuracy 0.4729 | Test Loss 0.7787 | Test Accuracy 0.7077 | \n",
      "Epoch: 2 | Train Loss 0.6995 | Train Accuracy 0.7646 | Test Loss 0.5414 | Test Accuracy 0.8943 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Looping through train and test steps for number of epochs\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m---> 21\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(\n\u001b[0;32m     30\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     31\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[0;32m     32\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m     33\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Printing out the outputs\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Jupyter\\torchFun\\08-Experiment\\scripts\\engine.py:16\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     14\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:247\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = train(\n",
    "    model=resnet,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23564f5d-8ba4-429f-922f-514b68cb94b8",
   "metadata": {},
   "source": [
    "Everything might seem the same. The records are similiar but there is a key difference in that behind the scenes, the *writer* instance has created a *runs/* directory of which the model's results are stored.  \n",
    "\n",
    "An example of the save location would look like: \n",
    "\n",
    "runs/Jun24_03-35-30_josh\n",
    "\n",
    "Remember that the default format is runs/CURRENT_DATETIME_HOSTNAME. \n",
    "\n",
    "Now, going back to our previos method of tracking results in a dictionary. Let's take a look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9970f7-b876-4165-b372-25ac09a3725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4e627-cbaa-42ee-8b5f-35cc1f890539",
   "metadata": {},
   "source": [
    "This looks very inconvenient. While there surely is a way that we can make this dictionary look more appealing but luckily, we don't have to worry much about that because we already have utilized TensorBoard. But, what does that actually look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e72c1d-19b0-4501-843e-c927a2c04c22",
   "metadata": {},
   "source": [
    "**View Model Results In TensorBoard**\n",
    "\n",
    "The *SummarWriter* class stored the model's results in a directory called 'runs/' in TensorBoard format by default. Connect this with TensorBoard is a visualization program to view and inspect information on models and their data and we get ---- another way to visualize, visualize, visualize!\n",
    "\n",
    "\n",
    "There are multiple ways you can check out TensorBoard: \n",
    "\n",
    "**VS Code - Notebooks / Python Scripts:** - Launching \"Python: Launch TensorBoard\" in Command Palette\n",
    "**Jupyter / Collab Notebooks:** - Make sure TensorBoard is installed, load it with *%load_ext tensorboard* and then view the results with *%tesnorboard --logdir DIR_WITH_LOGS*.\n",
    "\n",
    "What's great about TensorBoard is that you can upload the experiment results to *tensorboard.dev* to share them publicly with other people.\n",
    "\n",
    "Try running the following code in Google Colab / Jupyter Notebook to start an interactive TensorBoard session to view TensorBoard files in the runs/ directory\n",
    "\n",
    "* *%load_ext tensorboard* - this loads TensorBoard\n",
    "* *%tensorboard --logdir runs* - this indicates that TensorBoard will use the *runs/* directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590513a-559b-418e-b279-e05eea05a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs --host=127.0.0.1 --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362efc72-6e72-4513-be96-61947f64dd04",
   "metadata": {},
   "source": [
    "**Create Helper Function For Building *SummaryWriter()* Instances**\n",
    "\n",
    "We don't necessarily need to put the *SummaryWriter()* constructor in the *train()* function. We can make this more modular by putting it into a seperate function and just calling it in *train()*. \n",
    "\n",
    "So, let's make a helper function that can takes in an argument that specifies the name of the directory that it is going to create to store the results of an experiment. Basically, since we want to run multiple experiments, each has to have their own directory for their results and that's the idea of this helper function.\n",
    "\n",
    "We'll be tracking the following things:\n",
    "\n",
    "1. **Experiemnt Date & Timestamp** - When was the experiment conducted ?\n",
    "2. **Experiment Name** - What is the name for the experiment?\n",
    "3. **Model Name** - What was the name of the model used?\n",
    "4. **Extra** - Anything else to add?\n",
    "\n",
    "Just like working with manual transforms, you can have plenty of flexibility with what you want to track. That's why there's an *extra* section for you to have the option of tracking more info. \n",
    "\n",
    "Create a helper function called *create_writer()* which produces a *SummaryWriter()* instance which sends the output to a custom *log_dir*.\n",
    "\n",
    "The main idea is that the directories would be assembled into something akin to this:\n",
    "\n",
    "*runs/YYYY-MM-DD/experiment_name/model_name/extra*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112d4ff-5e4c-4a8e-9024-512cb5a8a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer(experiment_name: str,\n",
    "                 model_name: str,\n",
    "                 extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "\n",
    "    # Get timestamp of the current date\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    if extra:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "\n",
    "    print(f\"[INFO] Created SummaryWriter, Saving To: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968131e-3bd0-4604-9b58-65fae519bfc4",
   "metadata": {},
   "source": [
    "Let's try out our new function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3736a9-8a8b-47ed-b22a-14161a8f3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                              model_name=\"efficientnet_b0\",\n",
    "                              extra=\"10_epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04f994-155a-404c-bdef-976ae18e2ea9",
   "metadata": {},
   "source": [
    "**Update Train() Function To Include *Writer* Parameter**\n",
    "\n",
    "Since our *create_writer* function is working fine, let's integrate that with the *train()* function. We'll give the *train()* function the ability to create a seperate writer instance each time it is called. What this does is that if we're running different experiments, calling *train()* multiple times to run each experiment, would mean that it will create a unique writer that logs the results for that experiment alone. \n",
    "\n",
    "Basically -> one experiment = one writer = one log directory per experiment\n",
    "\n",
    "The changes that we'll be making is to add a *writer* parameter to *train()* and then also check if there is an existing *writer*, if there is then we'll track the information there on that already existing one, else we'll make a new one. That way we don't create unecessary *writer* instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12059b-e282-4a56-bcf1-79730318558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    writer: torch.utils.tensorboard.writer.SummaryWriter\n",
    ") -> Dict[str, List]:\n",
    "\n",
    "    results = {\n",
    "              \"train_loss\": [],\n",
    "              \"train_acc\": [],\n",
    "              \"test_loss\": [],\n",
    "              \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        results['train_loss'].append(train_loss)\n",
    "        results['train_acc'].append(train_acc)\n",
    "        results['test_loss'].append(test_loss)\n",
    "        results['test_acc'].append(test_acc)\n",
    "\n",
    "        print(f\"Epochs: {epoch+1} | \"\n",
    "               f\"Train Loss: {train_loss:.4f} | \"\n",
    "               f\"Train Accuracy: {train_acc:.4f} | \"\n",
    "               f\"Test Loss: {test_loss:.4f} | \"\n",
    "               f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        if writer:\n",
    "            writer.add_scalars(main_tag=\"Loss\",\n",
    "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                              \"test_loss\": test_loss},\n",
    "                               global_step=epoch\n",
    "            )\n",
    "\n",
    "            writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                              \"test_acc\": test_acc},\n",
    "                               global_step=epoch\n",
    "            )\n",
    "\n",
    "            writer.close()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143a8dd-fdb4-4f75-91ef-1a6101a34348",
   "metadata": {},
   "source": [
    "**Running Multiple Modelling Experiments**\n",
    "\n",
    "Now that we have TensorBoard ready to use with our *train()* function, we're technically ready to start a series of modelling experiments. Before, we've been running one experiment and then inspect the outputs one by one. Let's see if we can run multiple experiments and look at their results in one go.\n",
    "\n",
    "**Which Experiments To Run?**\n",
    "\n",
    "This is always the big ol question that many ponder around when deciding what to do with machine learning. \n",
    "\n",
    "That's because there's literally a lot of things that you can switch around. The freedom of having to choose what you want is both exciting and maddening. Imagine being in a grocery store and you want a can of soda but there's 100 different brands to choose from. That's overload!\n",
    "\n",
    "Luckily, in our case we can just experiment, experiment, experiment. Try as many things as you want as long as you're not constrained by the time and resource that is available to you. \n",
    "\n",
    "Just to glance at a few things that you can experiment around with:\n",
    "\n",
    "* Number of epochs\n",
    "* Number of hidden Units/layers\n",
    "* Amount of data\n",
    "* Learning rate\n",
    "* Application of data augmentations\n",
    "* Changing model architectures\n",
    "\n",
    "Each of these hyperparameters also involve many options to choose from but with consistent experimentation you'll eventually get an *intuition* of the specific things that might have considerable effect on your model. \n",
    "\n",
    "Of course, there's always no guarantee. It's always part science and magic. \n",
    "\n",
    "But there is a recipe for success. That range of 'success' is quite up to debate but there is one guarantee there is - the bigger your model means more learnable parameters and the more data that you have means more opportunities to learn. Mix these two together and you will get better performance. \n",
    "\n",
    "Since we're still starting out with machine learning, it's much better to start from small and scale it up from there. \n",
    "\n",
    "Ideally we want our experiments to run from a few seconds to a few minutes. It shouldn't take longer than that. \n",
    "\n",
    "The faster we finish our experiments means that we get more opportunity to see what doesn't work and then do the things that does work. \n",
    "\n",
    "**What Experiments To Run Now?**\n",
    "\n",
    "We want to improve our model powering FoodVision Mini without it getting too big. The ideal model we want would have a test accuracy of 90%+ and also doesn't take too long to train and perform inference on. \n",
    "\n",
    "Since we have so many options, let's just simplify it to these three combinations:\n",
    "\n",
    "1. Increasing the amount of data from 10% to 20%.\n",
    "2. Trying a different model and comparing the two.\n",
    "3. Testing different training times - 5 epochs vs 10 epochs.\n",
    "\n",
    "All in all that's 8 different experiments to run. \n",
    "\n",
    "We start with:\n",
    "\n",
    "1. 10% Data - efficientnet_b0 - 5\n",
    "2. 10% Data - efficientnet_b2 - 5\n",
    "3. 10% Data - efficientnet_b0 - 10\n",
    "4. 10% Data - efficientnet_b2 - 10\n",
    "5. 20% Data - efficientnet_b0 - 5\n",
    "6. 20% Data - efficientnet_b2 - 5\n",
    "7. 20% Data - efficientnet_b0 - 10\n",
    "8. 20% Data - efficientnet_b2 - 10\n",
    "\n",
    "Notice the scaling. We started with an experiment with the floor parameters with 10% data, a lower version of efficientnet and only 5 epochs while our last experiment has the ceiling parameters with 20% data, a higher version of efficient net and 10 epochs.\n",
    "\n",
    "We slowly increase the datasize, model version, and number of epochs. At the end of the series, the last experiment would have essentially doubled all its parameters from the start experiment. \n",
    "\n",
    "**Note**: There truly is no limit to the number of experiments you can take but we have to start somewhere. It's important to note that we're only touching a very small amount of options that we have. Not to mention that we're only using 10%-20% of the original data in Food101 Dataset. If the model is working well then maybe we can expand that further and consider other classes in Food101. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706dba1-8faa-4185-8c11-b26d893783bf",
   "metadata": {},
   "source": [
    "**Downloading Different Datasets**\n",
    "\n",
    "Since we're trying to run different experiments, there's one thing to prep before we start and that's to make sure that we have the datasets we need to work with. We need to make two seperate datasets that indicate one is 10% of the data and the other 20%. While we did make one earlier, we'll redo that again just to make everything a bit clearer.\n",
    "\n",
    "Both will use the same testing dataset for consistency. Specifically, we're just goint to use the 10% testing set. \n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52fad7-c2d9-4b6e-a169-3c9bf7962c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_10_percent_path = data_setup.get_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\", \n",
    "                                           target=\"data_10_percent\")\n",
    "\n",
    "data_20_percent_path = data_setup.get_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\", \n",
    "                                           target=\"data_20_percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba35b6c-5da5-4ad0-ac82-e99779f79d79",
   "metadata": {},
   "source": [
    "**Setting Up Train/Test Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309be4c-c27c-48aa-be59-cf9bbb34de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_10_percent = data_10_percent_path/'train' \n",
    "train_dir_20_percent = data_20_percent_path/'train'\n",
    "\n",
    "test_dataset = data_10_percent_path/'test'\n",
    "\n",
    "print(f\"Training Directory 10% - {train_dir_10_percent}\")\n",
    "print(f\"Training Directory 20% - {train_dir_20_percent}\")\n",
    "print(f\"Testing Directory 10% - {test_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf4816-523e-4091-a620-c9394ed8c216",
   "metadata": {},
   "source": [
    "**Transform Datasets & Create DataLoaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ae4f7-64d0-4ca1-a2af-c45ba9159cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                 std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "simple_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf1f2b-6ae2-434c-a966-b8cfad490d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_10_dataloader, test_dataloader, class_list = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir_10_percent,\n",
    "    test_dir=test_dataset,\n",
    "    transforms=simple_transforms,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0  \n",
    ")\n",
    "\n",
    "train_20_dataloader, test_dataloader, class_list = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dataset,\n",
    "    transforms=simple_transforms,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training: {len(train_10_dataloader)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training: {len(train_20_dataloader)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing dataloader: {len(test_dataloader)}\")\n",
    "print(f\"Number of classes: {len(class_list)} | Class names: {class_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707d36d-c5f5-462d-b3f3-84afb058d1f7",
   "metadata": {},
   "source": [
    "**Build Feature Extractor Models**\n",
    "\n",
    "Time to build the models. We're going to build two obviously:\n",
    "\n",
    "1. *torchvision.models.efficientnet_b0()* + pretrained backbone + customized classifier head\n",
    "2. *torchvision.models.efficientnet_b2()* + pretrained backbone + customized classifier head\n",
    "\n",
    "There's nothing new in this segment. We'll basically freeze the base layers and then update the classifier head and add in the change for our outputs to fit the number of classes that we have. \n",
    "\n",
    "Remember! While these two models are similiar in the sense that they're both the same architecture, they're still not exactly the same because *effnetb2* has a different number of layers and parameters. \n",
    "\n",
    "The first thing that you should do when working with new models is to always check how they're built. Always inspect the input and output shapes to make sure that you have the appropriate data transforms to fit in the model. \n",
    "\n",
    "Let's create the models and their associated weights then take a look at their summaries from *torchinfo.summary()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb52f40-2d9d-45d1-9228-18f71d3e230f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "effnetb0_weights = models.EfficientNet_B0_Weights.DEFAULT\n",
    "effnetb0_model = models.efficientnet_b0(weights=effnetb0_weights)\n",
    "\n",
    "effnetb2_weights = models.EfficientNet_B2_Weights.DEFAULT\n",
    "effnetb2_model = models.efficientnet_b2(weights=effnetb2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baceea1-993b-4130-813b-29977d880fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=effnetb0_model,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b177e-d5c8-4d17-8601-c978d914a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=effnetb2_model,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d78694-9674-42a0-838b-57e1f24cc1f5",
   "metadata": {},
   "source": [
    "Notice how *effnetb2* has almost double the amount of trainable parameters compared to *effnetb0*. The input and output shapes of some layers inside have also changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d75ca-e19d-4b70-b838-6ad0db200e85",
   "metadata": {},
   "source": [
    "Remember how we setup the classifier head and freezed the base layer before? We had to manually do that. That'll be very tedious once we start working with multiple experiments. So this time, we'll create a helper function to do all that so we can just call it instead of having to repeat the process again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136786c1-623b-430d-8380-8b5cb1f67886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the same number of out features so we'll set it as a global variable\n",
    "\n",
    "OUT_FEATURES = len(class_list)\n",
    "\n",
    "def create_effnetb0():\n",
    "\n",
    "    weights = models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = models.efficientnet_b0(weights=effnetb0_weights)\n",
    "    \n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    set_seeds()\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(1280, OUT_FEATURES, bias=True)\n",
    "    )\n",
    "\n",
    "    model.name = \"effnetb0\"\n",
    "    print(f\"[INFO] Created Model - {model.name}\")\n",
    "    return model\n",
    "\n",
    "def create_effnetb2():\n",
    "    \n",
    "    weights = models.EfficientNet_B2_Weights.DEFAULT\n",
    "    model = models.efficientnet_b2(weights=effnetb2_weights)\n",
    "\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    set_seeds()\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(1408, OUT_FEATURES, bias=True)\n",
    "    )\n",
    "\n",
    "    model.name = \"effnetb2\"\n",
    "    print(f\"[INFO] Created Model - {model.name}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348234ed-25d8-4671-abfb-9c279a2b66a7",
   "metadata": {},
   "source": [
    "Looking good! We can now make multiple models pretty easily with these helper functions. Let's try calling them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e0a71-d271-4345-a6b6-3c442fb1285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb0 = create_effnetb0().to(device)\n",
    "effnetb2 = create_effnetb2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54efd513-5776-48e9-89dd-1441d93ae9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=effnetb0,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d2356-035e-491c-89d5-2430c42a5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=effnetb2,\n",
    "        input_size=(32,3,224,224), # ensure that this is input_size and not input_shape\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a935b52-2288-44b0-a034-13e816577436",
   "metadata": {},
   "source": [
    "Example the following values and compare for both *effnetb0* and *effnetb2* - Total Parameters | Trainable Parametes. Make sure to also examine the models before they were frozen and after. \n",
    "\n",
    "Overall, we can see that the total parameters for both are almost double. Meaning that *effnetb2* has double the learning opportunities. But at the end of the day, the classifier heads are pretty similiar. Will these extra parameters make a difference in our loss and accuracy results?\n",
    "\n",
    "The only way to find out is to run both!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671f23c-209c-4ea4-b699-4a274428271c",
   "metadata": {},
   "source": [
    "**Create Experiments & Setting Up Training Code**\n",
    "\n",
    "We'll need to format these things into lists and dicts if we want to work with them on a series so let's get started with the following:\n",
    "\n",
    "1. Create a list of the number of epochs that we want to use *[5,10]*.\n",
    "2. Create a list of the models that we want to run experiments on *[\"effnetb0\", \"effnetb2\"]*.\n",
    "3. Create a dictionary for the different training DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4e376-28ee-40bf-a5c5-061dacf2c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = [5,10]\n",
    "model_list = [\"effnetb0\", \"effnetb2\"]\n",
    "train_dataloaders = {\"data_10_percent\": train_10_dataloader,\n",
    "                     \"data_20_percent\": train_20_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a246e42-05fc-4487-8745-c6fc26afcf91",
   "metadata": {},
   "source": [
    "Now that we have created our lists and dictionary for the models and their associated epochs, we can start writing the code that iterates through each of the options and work with the different combinations. \n",
    "\n",
    "In addition, we will also save the model at the end of each experiment so we can load the best model and make predictions with it.\n",
    "\n",
    "Let's run through the steps in making this iterating function - \n",
    "\n",
    "1. Set the random seeds so that we can have reproducable experiments.\n",
    "2. Keep track of the experiment numbers for print outs.\n",
    "3. Loop through the *train_dataloaders* dictionary items for each of the different training DataLoaders.\n",
    "4. Loop through the epochs.\n",
    "5. Loop through the different models.\n",
    "6. Print out the current experiment configuration so we can know where we are.\n",
    "7. Check the target model and create an instance of it - either *effnetb0* or *effnetb2*.\n",
    "8. Choose the loss function and optimizer for the experiment.\n",
    "9. Train the model with *train* and pass the required details to the *writer* parameter.\n",
    "10. Save the trained model with the chosen file name to the directory specified with *save_model()* from *utils.py*\n",
    "\n",
    "We will also use *%%time* so that we can track how long all of the experiments took to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9aa3a-d499-4b8b-861c-b77814b65dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11545f96-79e9-4484-bbf1-26ffab80ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782bad97-fe86-47ca-8022-d371b46e0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "set_seeds()\n",
    "\n",
    "experiment_track = 0\n",
    "# We need to set the train_dataloaders.item() because we want to iterate through the key-value pairs and assign them to \n",
    "# individual variables, in this case, dataloader_name for key and train_dataloader for value.\n",
    "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
    "    for epochs in num_epochs:\n",
    "        for model_name in model_list:\n",
    "            experiment_track += 1 \n",
    "            print(f\"[INFO] - EXPERIMENT #{experiment_track}\")\n",
    "            print(f\"[INFO] Experiment Configuration - DataLoader: {dataloader_name} | Epochs: {epochs} | Model: {model_name}\")\n",
    "            if model_name == \"effnetb0\":\n",
    "                model_instance = create_effnetb0().to(device)\n",
    "            else:\n",
    "                model_instance = create_effnetb2().to(device)\n",
    "\n",
    "            loss_fn=torch.nn.CrossEntropyLoss()\n",
    "            optimizer=torch.optim.Adam(model_instance.parameters(), lr=0.001)\n",
    "\n",
    "            results = train(\n",
    "                model=model_instance,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                epochs=epochs,\n",
    "                device=device,\n",
    "                writer=create_writer(experiment_name=dataloader_name, \n",
    "                                     model_name=model_name, \n",
    "                                     extra=f\"{epochs}_epochs\")\n",
    "            )\n",
    "            save_filepath = f\"08_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
    "            utils.save_model(model=model_instance,\n",
    "                      target_dir=\"models\",\n",
    "                      model_name=save_filepath)\n",
    "            print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab26ea3-9060-4195-9926-c7ba3f09d193",
   "metadata": {},
   "source": [
    "**Inspecting Results In TensorBoard**\n",
    "\n",
    "Ain't that exciting? We just trained eight models with different hyperparameters in one single sweep. Let's take a look at the results for each one in TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3922e4-bfff-4869-9545-c22b2160fddb",
   "metadata": {},
   "source": [
    "![Display](images/08-tensorboard-series-experiment-results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef47e0d-f32d-47b4-bdb8-47b9b5960141",
   "metadata": {},
   "source": [
    "Looking at the results, we can see that the models which achieved the lowest loss rate is *effnetb0* with 10 epochs. There doesn't seem to be a difference in the dataset because both 10% and 20% are tied for 1st place. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c06843-7b90-4df5-aeea-d8cc20cc0a15",
   "metadata": {},
   "source": [
    "**Loading Best Model + Creating Predictions**\n",
    "\n",
    "Seems like we have two options to choose from with our best model. Let's take the one that has the following configuration:\n",
    "\n",
    "* *Effnetb2* which has double the parameters\n",
    "* 20% training data\n",
    "* and 10 epochs\n",
    "\n",
    "Basically, the model that used much more data and computation was the one that performed the best. That's not to say that the other models didn't perform good. They all gave out some promising results. One even achieved a pretty good result at half the time it took for our best performing model to finish. \n",
    "\n",
    "From the perspective of the results, it seems like the a major factor is the number of epochs involved in training. You could always run more experiments to test these results and see more about the key items influencing the results. \n",
    "\n",
    "For now, let's just import the best performing model that was saved to the models folder. It's time to *visualize, visualize, visualize*\n",
    "\n",
    "As always, we can just create a new instance of that certain model and just load the *state_dict* to that new instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5605db-ddf4-4b21-b8ad-73d5ad2ed0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"models/08_effnetb2_data_20_percent_10_epochs.pth\"\n",
    "best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4c14d-9f11-431f-9d38-d43cee9c5e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = create_effnetb2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ef566-c420-4943-95a7-5a6c250d6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747936fa-4ec3-4578-b110-e96894a0585f",
   "metadata": {},
   "source": [
    "We took the weights from the path in our models, instantiated a new effnet model and then just loaded the weights into it. This method is the best practice to take when loading models. But there's something we have to do first before we start predicting on this model.\n",
    "\n",
    "We have to first check the filesize. Why is that important? It's because we have to consider whether or not the model will load quickly. If it's too large then it will be hard to deploy. That is why we have to make sure that filesize is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90259d-e945-4336-a505-7a696f83e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb2_model_size = Path(best_model_path).stat().st_size // (1024*1024)\n",
    "# .stat() grabs multiple details (including file size) from the file and returns an object and then we access .st_size\n",
    "# which is the file size in bytes. We convert this into MB by floor dividing with (1024*1024)\n",
    "print(f\"EfficientNetB2 Feature Extractor Model Size: {effnetb2_model_size} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a4a88-35be-410b-9ce6-3fde086faa9c",
   "metadata": {},
   "source": [
    "So the best size for our model is 29 MB. Is that a good number? We'll see later once we deploy it.\n",
    "\n",
    "Let's make some predictions with it. We import the *predict.py* from *Going Modular* and then use the *predict_image* function. We'll use images from the 20% pizza, steak, sushi testing dataset. We will randomly select a subset of these filepaths and then pass this to the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ddf9e-0039-4bb4-9fca-0bbf89053871",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebd764-e598-456d-860e-bb7c4c422f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "num_images_plot = 3\n",
    "test_image_path_list = list(test_dir.glob(\"*/*.jpg\"))\n",
    "test_rand_sample = random.sample(test_image_path_list, 3)\n",
    "\n",
    "for image in test_rand_sample:\n",
    "    print(image)\n",
    "    predict.predict_image(\n",
    "        model=best_model,\n",
    "        image_path=image,\n",
    "        transform=simple_transforms,\n",
    "        class_list=class_list,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0841e0-f900-47b4-8d7d-f5f7ea48fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "best_model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X,y in tqdm(test_dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        pred = best_model(X)\n",
    "        pred_probs = torch.softmax(pred, dim=1)\n",
    "        pred_labels = torch.argmax(pred_probs, dim=1)\n",
    "        test_preds.append(pred_labels)\n",
    "\n",
    "# We do a list comprehension on test_preds to transfer the device to cpu because if we keep it on cuda then it'll be hard to look at the \n",
    "# formation of the values because there would be device=''cuda:0' section\n",
    "test_preds = [tensor.cpu() for tensor in test_preds]\n",
    "print(f\"Before Cat: {test_preds}\\n\")\n",
    "# We apply concat because the tensors are seperated into batches and we want all of the values in one dimension.\n",
    "test_preds = torch.cat(test_preds).cpu()\n",
    "print(f\"After Cat: {test_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9f04b-8743-403b-b75d-b23c0e8872d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_truth = torch.cat([y for X, y in test_dataloader])\n",
    "test_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194619e0-5e69-49d0-844f-b28efc3c3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = ConfusionMatrix(num_classes=len(class_list), task='multiclass')\n",
    "confmat_tensor = confmat(preds=test_preds,\n",
    "                        target=test_truth)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_list,\n",
    "    figsize=(10,7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272bae4-06ff-4e7d-acfe-79aaf2fce8f4",
   "metadata": {},
   "source": [
    "Notice how our model now has a high confidence on its predictions compared to our previous model. In addition, if we check our confusion matrix, it's coming out very accurate with all it's predictions with just a very small margin of error. \n",
    "\n",
    "That's fine because model's aren't perfect. \n",
    "\n",
    "One thing is for sure is that we were able to get the best model now because it is very sure with it's correct prediction. \n",
    "\n",
    "Let's try predicting with a custom image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d32618-4bf1-4d31-a964-7a432d538186",
   "metadata": {},
   "source": [
    "**Predicting Custom Image With Best Model**\n",
    "\n",
    "Let's try using the same old test custom image before and just compare that. Use the same function that we used before and experiment to see what the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f421f-a7e3-42bc-b4cd-560b196ff6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_path = Path('custom/image-3.jpg')\n",
    "\n",
    "predict.predict_image(\n",
    "    model=best_model,\n",
    "    image_path=custom_image_path,\n",
    "    transform=simple_transforms,\n",
    "    class_list=class_list,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e96d9-a7f8-47a3-b373-ba51a74ad051",
   "metadata": {},
   "source": [
    "Seems like this model performs really well when it comes to identifying pizza but it depends. It can be beaten by *effnet0* when working with steaks on some certain images. There isn't really a guaranteed result as to which model is better but if that's the question then you can simply just take a look at the metrics and generally, the one with the lowest loss and the highest accuracy is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220e892-1a92-4eff-aab9-ac9eda3908f2",
   "metadata": {},
   "source": [
    "**Main Takeaways**\n",
    "\n",
    "We've successfully completed the major parts of how to work with PyTorch. We now know how to work with Datasets, DataLoaders, and how to make data ready for training/testing. We can pick a pretrained model and then use it. We also created different helper functions to make the entire process easier. Not to mention that we managed to create an improved version of FoodVision Mini alongside creating a series of experiments and tracking/viewing their results in one go.\n",
    "\n",
    "Let's summarize the key points again:\n",
    "\n",
    "1. Always *\"experiment, experiment, experiment\"*. Experiments always bring experience and you could always use more of that.\n",
    "2. Make sure that experiments at the start should be kept at a minimum for the duration that they run. Start small and scale up.\n",
    "3. The faster you get your experiments done, the faster you'll be able to identify how to work the problem.\n",
    "4. Once you found a probable solution, scale up the process. See how it works on a bigger picture.\n",
    "5. Taking the time to build an environment for experimenting might take some time but the benefits of a faster/flexible work process will  make it worth it at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3e639-829f-4d99-87c9-0cba77839bde",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdd3d9-a279-40b1-8bee-273d96c3ef12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
